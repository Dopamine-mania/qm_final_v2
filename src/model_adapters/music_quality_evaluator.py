#!/usr/bin/env python3
"""
éŸ³ä¹è´¨é‡è¯„ä¼°æ¨¡å— - è¯„ä¼°ç”ŸæˆéŸ³ä¹çš„æ²»ç–—æ•ˆæœå’ŒæŠ€æœ¯è´¨é‡

ç†è®ºåŸºç¡€ï¼š
1. Music Information Retrieval (MIR) Metrics:
   - Spectral Centroid: éŸ³è‰²äº®åº¦
   - Zero Crossing Rate: å™ªå£°æ£€æµ‹
   - MFCC: éŸ³è‰²ç‰¹å¾
   - Tempo Estimation: èŠ‚å¥ç¨³å®šæ€§

2. Therapeutic Music Assessment (2024):
   - "Quantitative Assessment of Music Therapy" - Journal of Music Therapy
   - åŸºäºæƒ…ç»ªä¸€è‡´æ€§ã€èŠ‚å¥ç¨³å®šæ€§ã€éŸ³é‡åŠ¨æ€çš„è¯„ä¼°æ¡†æ¶

3. Audio Quality Metrics:
   - SNR (Signal-to-Noise Ratio)
   - THD (Total Harmonic Distortion) 
   - Dynamic Range

ä½œè€…ï¼šå¿ƒå¢ƒæµè½¬å›¢é˜Ÿ
æ—¥æœŸï¼š2024
"""

import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import warnings

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

@dataclass
class QualityMetrics:
    """éŸ³ä¹è´¨é‡è¯„ä¼°ç»“æœ"""
    # æŠ€æœ¯è´¨é‡æŒ‡æ ‡
    signal_to_noise_ratio: float     # ä¿¡å™ªæ¯”
    dynamic_range: float             # åŠ¨æ€èŒƒå›´
    spectral_centroid_mean: float    # å¹³å‡é¢‘è°±è´¨å¿ƒ
    zero_crossing_rate: float        # è¿‡é›¶ç‡
    
    # æ²»ç–—æ•ˆæœæŒ‡æ ‡
    tempo_stability: float           # èŠ‚å¥ç¨³å®šæ€§
    volume_consistency: float        # éŸ³é‡ä¸€è‡´æ€§
    emotional_coherence: float       # æƒ…ç»ªä¸€è‡´æ€§
    therapeutic_suitability: float   # æ²»ç–—é€‚ç”¨æ€§
    
    # ç»¼åˆè¯„åˆ†
    technical_score: float           # æŠ€æœ¯è´¨é‡è¯„åˆ† (0-1)
    therapeutic_score: float         # æ²»ç–—æ•ˆæœè¯„åˆ† (0-1)
    overall_score: float            # ç»¼åˆè¯„åˆ† (0-1)
    
    # å»ºè®®å’Œè­¦å‘Š
    recommendations: List[str]       # æ”¹è¿›å»ºè®®
    warnings: List[str]             # è´¨é‡è­¦å‘Š

class MusicQualityEvaluator:
    """
    éŸ³ä¹è´¨é‡è¯„ä¼°å™¨
    
    è¯„ä¼°ç»´åº¦ï¼š
    1. æŠ€æœ¯è´¨é‡ï¼šä¿¡å™ªæ¯”ã€åŠ¨æ€èŒƒå›´ã€é¢‘è°±åˆ†æ
    2. æ²»ç–—æ•ˆæœï¼šèŠ‚å¥ç¨³å®šæ€§ã€æƒ…ç»ªä¸€è‡´æ€§ã€ç¡çœ é€‚ç”¨æ€§
    3. ç”¨æˆ·ä½“éªŒï¼šéŸ³é‡ä¸€è‡´æ€§ã€å¬è§‰èˆ’é€‚åº¦
    """
    
    # æ²»ç–—éŸ³ä¹çš„è´¨é‡æ ‡å‡†ï¼ˆåŸºäºéŸ³ä¹æ²»ç–—ç ”ç©¶ï¼‰
    THERAPEUTIC_STANDARDS = {
        'tempo_stability_threshold': 0.95,      # èŠ‚å¥ç¨³å®šæ€§é˜ˆå€¼
        'volume_consistency_threshold': 0.90,   # éŸ³é‡ä¸€è‡´æ€§é˜ˆå€¼
        'snr_minimum': 20,                      # æœ€å°ä¿¡å™ªæ¯” (dB)
        'dynamic_range_optimal': (12, 30),     # æœ€ä¼˜åŠ¨æ€èŒƒå›´ (dB)
        'spectral_centroid_sleep_max': 2000,   # ç¡çœ éŸ³ä¹æœ€å¤§é¢‘è°±è´¨å¿ƒ (Hz)
        'zero_crossing_rate_max': 0.1          # æœ€å¤§è¿‡é›¶ç‡ï¼ˆå™ªå£°æ§åˆ¶ï¼‰
    }
    
    def __init__(self, sample_rate: int = 32000):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
        
        # æ£€æŸ¥ä¾èµ–åº“
        self.librosa_available = self._check_librosa()
        
    def _check_librosa(self) -> bool:
        """æ£€æŸ¥librosaåº“æ˜¯å¦å¯ç”¨"""
        try:
            import librosa
            self.librosa = librosa
            return True
        except ImportError:
            logger.warning("librosaåº“æœªå®‰è£…ï¼ŒæŸäº›é«˜çº§åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
            logger.warning("å»ºè®®å®‰è£…ï¼špip install librosa")
            return False
    
    def evaluate_music_quality(self, 
                             audio_data: np.ndarray, 
                             metadata: Dict,
                             therapy_context: Optional[Dict] = None) -> QualityMetrics:
        """
        å…¨é¢è¯„ä¼°éŸ³ä¹è´¨é‡
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            metadata: ç”Ÿæˆå…ƒæ•°æ®
            therapy_context: æ²»ç–—ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            QualityMetrics: è¯¦ç»†çš„è´¨é‡è¯„ä¼°ç»“æœ
        """
        logger.info("ğŸ” å¼€å§‹éŸ³ä¹è´¨é‡è¯„ä¼°...")
        
        # 1. æŠ€æœ¯è´¨é‡åˆ†æ
        technical_metrics = self._analyze_technical_quality(audio_data)
        
        # 2. æ²»ç–—æ•ˆæœåˆ†æ
        therapeutic_metrics = self._analyze_therapeutic_effectiveness(
            audio_data, metadata, therapy_context
        )
        
        # 3. ç»¼åˆè¯„åˆ†è®¡ç®—
        scores = self._calculate_composite_scores(technical_metrics, therapeutic_metrics)
        
        # 4. ç”Ÿæˆå»ºè®®å’Œè­¦å‘Š
        recommendations, warnings = self._generate_recommendations(
            technical_metrics, therapeutic_metrics, metadata
        )
        
        # 5. æ„å»ºè¯„ä¼°ç»“æœ
        quality_metrics = QualityMetrics(
            # æŠ€æœ¯è´¨é‡
            signal_to_noise_ratio=technical_metrics['snr'],
            dynamic_range=technical_metrics['dynamic_range'],
            spectral_centroid_mean=technical_metrics['spectral_centroid_mean'],
            zero_crossing_rate=technical_metrics['zero_crossing_rate'],
            
            # æ²»ç–—æ•ˆæœ
            tempo_stability=therapeutic_metrics['tempo_stability'],
            volume_consistency=therapeutic_metrics['volume_consistency'],
            emotional_coherence=therapeutic_metrics['emotional_coherence'],
            therapeutic_suitability=therapeutic_metrics['therapeutic_suitability'],
            
            # ç»¼åˆè¯„åˆ†
            technical_score=scores['technical_score'],
            therapeutic_score=scores['therapeutic_score'],
            overall_score=scores['overall_score'],
            
            # å»ºè®®å’Œè­¦å‘Š
            recommendations=recommendations,
            warnings=warnings
        )
        
        self._log_evaluation_results(quality_metrics)
        
        return quality_metrics
    
    def _analyze_technical_quality(self, audio_data: np.ndarray) -> Dict:
        """åˆ†ææŠ€æœ¯è´¨é‡æŒ‡æ ‡"""
        
        # 1. ä¿¡å™ªæ¯”ä¼°ç®—ï¼ˆç®€åŒ–å®ç°ï¼‰
        signal_power = np.mean(audio_data ** 2)
        noise_estimate = np.mean(np.abs(np.diff(audio_data))) * 0.1  # ç®€åŒ–å™ªå£°ä¼°è®¡
        snr = 10 * np.log10(signal_power / (noise_estimate + 1e-10))
        
        # 2. åŠ¨æ€èŒƒå›´
        max_amplitude = np.max(np.abs(audio_data))
        min_amplitude = np.min(np.abs(audio_data[np.abs(audio_data) > 0.001]))
        dynamic_range = 20 * np.log10(max_amplitude / (min_amplitude + 1e-10))
        
        # 3. è¿‡é›¶ç‡
        zero_crossings = np.sum(np.diff(np.sign(audio_data)) != 0)
        zero_crossing_rate = zero_crossings / len(audio_data)
        
        # 4. é¢‘è°±è´¨å¿ƒï¼ˆå¦‚æœlibrosaå¯ç”¨ï¼‰
        if self.librosa_available:
            try:
                spectral_centroid = self.librosa.feature.spectral_centroid(
                    y=audio_data, sr=self.sample_rate
                )[0]
                spectral_centroid_mean = np.mean(spectral_centroid)
            except Exception as e:
                logger.warning(f"é¢‘è°±è´¨å¿ƒè®¡ç®—å¤±è´¥: {e}")
                spectral_centroid_mean = 1000  # é»˜è®¤å€¼
        else:
            # ç®€åŒ–çš„é¢‘è°±è´¨å¿ƒä¼°ç®—
            fft = np.abs(np.fft.fft(audio_data))
            freqs = np.fft.fftfreq(len(audio_data), 1/self.sample_rate)
            spectral_centroid_mean = np.sum(freqs[:len(freqs)//2] * fft[:len(fft)//2]) / np.sum(fft[:len(fft)//2])
        
        return {
            'snr': snr,
            'dynamic_range': dynamic_range,
            'spectral_centroid_mean': abs(spectral_centroid_mean),
            'zero_crossing_rate': zero_crossing_rate
        }
    
    def _analyze_therapeutic_effectiveness(self, 
                                         audio_data: np.ndarray, 
                                         metadata: Dict,
                                         therapy_context: Optional[Dict]) -> Dict:
        """åˆ†ææ²»ç–—æ•ˆæœæŒ‡æ ‡"""
        
        # 1. èŠ‚å¥ç¨³å®šæ€§åˆ†æ
        tempo_stability = self._analyze_tempo_stability(audio_data)
        
        # 2. éŸ³é‡ä¸€è‡´æ€§
        volume_consistency = self._analyze_volume_consistency(audio_data)
        
        # 3. æƒ…ç»ªä¸€è‡´æ€§ï¼ˆåŸºäºå…ƒæ•°æ®ï¼‰
        emotional_coherence = self._analyze_emotional_coherence(metadata, therapy_context)
        
        # 4. æ²»ç–—é€‚ç”¨æ€§è¯„ä¼°
        therapeutic_suitability = self._assess_therapeutic_suitability(
            audio_data, metadata, therapy_context
        )
        
        return {
            'tempo_stability': tempo_stability,
            'volume_consistency': volume_consistency,
            'emotional_coherence': emotional_coherence,
            'therapeutic_suitability': therapeutic_suitability
        }
    
    def _analyze_tempo_stability(self, audio_data: np.ndarray) -> float:
        """åˆ†æèŠ‚å¥ç¨³å®šæ€§"""
        if not self.librosa_available:
            # ç®€åŒ–å®ç°ï¼šåŸºäºèƒ½é‡å˜åŒ–ä¼°ç®—
            window_size = self.sample_rate // 4  # 0.25ç§’çª—å£
            energy_windows = []
            
            for i in range(0, len(audio_data) - window_size, window_size):
                window = audio_data[i:i + window_size]
                energy = np.mean(window ** 2)
                energy_windows.append(energy)
            
            if len(energy_windows) < 2:
                return 0.5
            
            # è®¡ç®—èƒ½é‡å˜åŒ–çš„ç¨³å®šæ€§
            energy_variance = np.var(energy_windows)
            energy_mean = np.mean(energy_windows)
            stability = 1.0 / (1.0 + energy_variance / (energy_mean + 1e-10))
            
            return min(stability, 1.0)
        
        try:
            # ä½¿ç”¨librosaè¿›è¡ŒèŠ‚æ‹æ£€æµ‹
            tempo, beats = self.librosa.beat.beat_track(
                y=audio_data, sr=self.sample_rate
            )
            
            if len(beats) < 4:
                return 0.5  # èŠ‚æ‹å¤ªå°‘ï¼Œæ— æ³•è¯„ä¼°
            
            # è®¡ç®—èŠ‚æ‹é—´éš”çš„ç¨³å®šæ€§
            beat_intervals = np.diff(beats) / self.sample_rate
            if len(beat_intervals) == 0:
                return 0.5
            
            interval_variance = np.var(beat_intervals)
            interval_mean = np.mean(beat_intervals)
            
            # ç¨³å®šæ€§è¯„åˆ†ï¼šæ–¹å·®è¶Šå°è¶Šç¨³å®š
            stability = 1.0 / (1.0 + interval_variance / (interval_mean + 1e-10))
            return min(stability, 1.0)
            
        except Exception as e:
            logger.warning(f"èŠ‚å¥ç¨³å®šæ€§åˆ†æå¤±è´¥: {e}")
            return 0.5
    
    def _analyze_volume_consistency(self, audio_data: np.ndarray) -> float:
        """åˆ†æéŸ³é‡ä¸€è‡´æ€§"""
        # åˆ†æRMSèƒ½é‡çš„ä¸€è‡´æ€§
        window_size = self.sample_rate  # 1ç§’çª—å£
        rms_values = []
        
        for i in range(0, len(audio_data) - window_size + 1, window_size // 2):
            window = audio_data[i:i + window_size]
            rms = np.sqrt(np.mean(window ** 2))
            rms_values.append(rms)
        
        if len(rms_values) < 2:
            return 1.0
        
        # è®¡ç®—RMSå€¼çš„å˜å¼‚ç³»æ•°
        rms_mean = np.mean(rms_values)
        rms_std = np.std(rms_values)
        
        if rms_mean == 0:
            return 0.0
        
        coefficient_of_variation = rms_std / rms_mean
        
        # ä¸€è‡´æ€§è¯„åˆ†ï¼šå˜å¼‚ç³»æ•°è¶Šå°è¶Šä¸€è‡´
        consistency = 1.0 / (1.0 + coefficient_of_variation * 10)
        return min(consistency, 1.0)
    
    def _analyze_emotional_coherence(self, 
                                   metadata: Dict, 
                                   therapy_context: Optional[Dict]) -> float:
        """åˆ†ææƒ…ç»ªä¸€è‡´æ€§"""
        if not metadata or 'emotion_state' not in metadata:
            return 0.5
        
        emotion_state = metadata['emotion_state']
        target_emotion = emotion_state.get('primary_emotion', 'neutral')
        
        # åŸºäºpromptåˆ†ææƒ…ç»ªä¸€è‡´æ€§
        prompt = metadata.get('prompt', '').lower()
        
        # æƒ…ç»ªå…³é”®è¯åŒ¹é…åº¦
        emotion_keywords = {
            'anger': ['aggressive', 'powerful', 'intense', 'rock', 'metal'],
            'fear': ['dark', 'tense', 'mysterious', 'ambient'],
            'sadness': ['melancholic', 'slow', 'blues', 'emotional'],
            'joy': ['uplifting', 'energetic', 'bright', 'major'],
            'neutral': ['calm', 'peaceful', 'ambient', 'relaxing']
        }
        
        target_keywords = emotion_keywords.get(target_emotion, emotion_keywords['neutral'])
        matches = sum(1 for keyword in target_keywords if keyword in prompt)
        
        coherence = matches / len(target_keywords) if target_keywords else 0.5
        return min(coherence, 1.0)
    
    def _assess_therapeutic_suitability(self, 
                                      audio_data: np.ndarray,
                                      metadata: Dict,
                                      therapy_context: Optional[Dict]) -> float:
        """è¯„ä¼°æ²»ç–—é€‚ç”¨æ€§"""
        suitability_factors = []
        
        # 1. BPMé€‚ç”¨æ€§ï¼ˆé’ˆå¯¹ç¡çœ æ²»ç–—ï¼‰
        bpm_target = metadata.get('bpm_target', 70)
        if 40 <= bpm_target <= 100:  # æ²»ç–—éŸ³ä¹çš„ç†æƒ³BPMèŒƒå›´
            bpm_suitability = 1.0
        elif 30 <= bpm_target <= 120:  # å¯æ¥å—èŒƒå›´
            bpm_suitability = 0.7
        else:
            bpm_suitability = 0.3
        
        suitability_factors.append(bpm_suitability)
        
        # 2. é¢‘è°±é€‚ç”¨æ€§ï¼ˆç¡çœ éŸ³ä¹åº”é¿å…è¿‡é«˜é¢‘ç‡ï¼‰
        if hasattr(self, 'spectral_centroid_mean'):
            spectral_centroid = self.spectral_centroid_mean
        else:
            # ç®€åŒ–çš„é¢‘è°±è´¨å¿ƒè®¡ç®—
            fft = np.abs(np.fft.fft(audio_data))
            freqs = np.fft.fftfreq(len(audio_data), 1/self.sample_rate)
            spectral_centroid = np.sum(freqs[:len(freqs)//2] * fft[:len(fft)//2]) / np.sum(fft[:len(fft)//2])
        
        if spectral_centroid < 1000:  # ä½é¢‘ä¸ºä¸»ï¼Œé€‚åˆç¡çœ 
            spectral_suitability = 1.0
        elif spectral_centroid < 2000:  # ä¸­é¢‘ï¼Œè¾ƒé€‚åˆ
            spectral_suitability = 0.8
        else:  # é«˜é¢‘ï¼Œä¸å¤ªé€‚åˆç¡çœ 
            spectral_suitability = 0.4
        
        suitability_factors.append(spectral_suitability)
        
        # 3. åŠ¨æ€èŒƒå›´é€‚ç”¨æ€§ï¼ˆç¡çœ éŸ³ä¹ä¸åº”æœ‰å‰§çƒˆçš„éŸ³é‡å˜åŒ–ï¼‰
        max_amplitude = np.max(np.abs(audio_data))
        amplitude_changes = np.abs(np.diff(audio_data))
        max_change = np.max(amplitude_changes) if len(amplitude_changes) > 0 else 0
        
        if max_change / (max_amplitude + 1e-10) < 0.1:  # å˜åŒ–æ¸©å’Œ
            dynamic_suitability = 1.0
        elif max_change / (max_amplitude + 1e-10) < 0.3:  # å˜åŒ–é€‚ä¸­
            dynamic_suitability = 0.7
        else:  # å˜åŒ–å‰§çƒˆ
            dynamic_suitability = 0.3
        
        suitability_factors.append(dynamic_suitability)
        
        # 4. æ—¶é•¿é€‚ç”¨æ€§
        duration = len(audio_data) / self.sample_rate
        target_duration = metadata.get('duration', 60)
        
        duration_ratio = duration / target_duration if target_duration > 0 else 1
        if 0.9 <= duration_ratio <= 1.1:  # æ—¶é•¿è¯¯å·®åœ¨10%ä»¥å†…
            duration_suitability = 1.0
        elif 0.8 <= duration_ratio <= 1.2:  # æ—¶é•¿è¯¯å·®åœ¨20%ä»¥å†…
            duration_suitability = 0.8
        else:
            duration_suitability = 0.5
        
        suitability_factors.append(duration_suitability)
        
        # ç»¼åˆé€‚ç”¨æ€§è¯„åˆ†
        overall_suitability = np.mean(suitability_factors)
        return overall_suitability
    
    def _calculate_composite_scores(self, 
                                  technical_metrics: Dict, 
                                  therapeutic_metrics: Dict) -> Dict:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        
        # 1. æŠ€æœ¯è´¨é‡è¯„åˆ†
        tech_factors = []
        
        # SNRè¯„åˆ†
        snr = technical_metrics['snr']
        if snr >= 30:
            snr_score = 1.0
        elif snr >= 20:
            snr_score = 0.8
        elif snr >= 10:
            snr_score = 0.6
        else:
            snr_score = 0.3
        tech_factors.append(snr_score)
        
        # åŠ¨æ€èŒƒå›´è¯„åˆ†
        dr = technical_metrics['dynamic_range']
        optimal_range = self.THERAPEUTIC_STANDARDS['dynamic_range_optimal']
        if optimal_range[0] <= dr <= optimal_range[1]:
            dr_score = 1.0
        elif 8 <= dr <= 40:  # å¯æ¥å—èŒƒå›´
            dr_score = 0.7
        else:
            dr_score = 0.4
        tech_factors.append(dr_score)
        
        # è¿‡é›¶ç‡è¯„åˆ†ï¼ˆå™ªå£°æ§åˆ¶ï¼‰
        zcr = technical_metrics['zero_crossing_rate']
        max_zcr = self.THERAPEUTIC_STANDARDS['zero_crossing_rate_max']
        if zcr <= max_zcr:
            zcr_score = 1.0
        elif zcr <= max_zcr * 2:
            zcr_score = 0.6
        else:
            zcr_score = 0.2
        tech_factors.append(zcr_score)
        
        technical_score = np.mean(tech_factors)
        
        # 2. æ²»ç–—æ•ˆæœè¯„åˆ†
        therapeutic_score = np.mean([
            therapeutic_metrics['tempo_stability'],
            therapeutic_metrics['volume_consistency'],
            therapeutic_metrics['emotional_coherence'],
            therapeutic_metrics['therapeutic_suitability']
        ])
        
        # 3. ç»¼åˆè¯„åˆ†ï¼ˆæŠ€æœ¯è´¨é‡æƒé‡0.3ï¼Œæ²»ç–—æ•ˆæœæƒé‡0.7ï¼‰
        overall_score = 0.3 * technical_score + 0.7 * therapeutic_score
        
        return {
            'technical_score': technical_score,
            'therapeutic_score': therapeutic_score,
            'overall_score': overall_score
        }
    
    def _generate_recommendations(self, 
                                technical_metrics: Dict, 
                                therapeutic_metrics: Dict,
                                metadata: Dict) -> Tuple[List[str], List[str]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®å’Œè´¨é‡è­¦å‘Š"""
        recommendations = []
        warnings = []
        
        # æŠ€æœ¯è´¨é‡å»ºè®®
        if technical_metrics['snr'] < 20:
            warnings.append("ä¿¡å™ªæ¯”è¿‡ä½ï¼Œå¯èƒ½å½±å“éŸ³é¢‘è´¨é‡")
            recommendations.append("è°ƒæ•´ç”Ÿæˆå‚æ•°ä»¥å‡å°‘å™ªå£°")
        
        if technical_metrics['dynamic_range'] < 10:
            recommendations.append("å¢åŠ åŠ¨æ€èŒƒå›´ä»¥æå‡éŸ³ä¹è¡¨ç°åŠ›")
        elif technical_metrics['dynamic_range'] > 35:
            warnings.append("åŠ¨æ€èŒƒå›´è¿‡å¤§ï¼Œå¯èƒ½å½±å“ç¡çœ æ²»ç–—æ•ˆæœ")
            recommendations.append("é™ä½éŸ³é‡å˜åŒ–å¹…åº¦")
        
        if technical_metrics['zero_crossing_rate'] > 0.1:
            warnings.append("æ£€æµ‹åˆ°è¾ƒé«˜çš„å™ªå£°æ°´å¹³")
            recommendations.append("ä½¿ç”¨ä½é€šæ»¤æ³¢å™¨å‡å°‘é«˜é¢‘å™ªå£°")
        
        # æ²»ç–—æ•ˆæœå»ºè®®
        if therapeutic_metrics['tempo_stability'] < 0.8:
            warnings.append("èŠ‚å¥ç¨³å®šæ€§ä¸è¶³")
            recommendations.append("è°ƒæ•´promptä»¥è·å¾—æ›´ç¨³å®šçš„èŠ‚å¥")
        
        if therapeutic_metrics['volume_consistency'] < 0.7:
            warnings.append("éŸ³é‡å˜åŒ–è¿‡å¤§")
            recommendations.append("åº”ç”¨éŸ³é‡è§„èŒƒåŒ–å¤„ç†")
        
        if therapeutic_metrics['emotional_coherence'] < 0.6:
            recommendations.append("ä¼˜åŒ–promptä»¥æé«˜æƒ…ç»ªä¸€è‡´æ€§")
        
        if therapeutic_metrics['therapeutic_suitability'] < 0.7:
            warnings.append("æ²»ç–—é€‚ç”¨æ€§è¯„åˆ†è¾ƒä½")
            recommendations.append("æ£€æŸ¥BPMè®¾ç½®å’Œé¢‘è°±åˆ†å¸ƒ")
        
        # å…ƒæ•°æ®ç›¸å…³å»ºè®®
        bpm_target = metadata.get('bpm_target', 70)
        if bpm_target > 100:
            warnings.append(f"BPM ({bpm_target}) è¿‡é«˜ï¼Œä¸é€‚åˆç¡çœ æ²»ç–—")
            recommendations.append("å°†BPMé™ä½è‡³60-80èŒƒå›´")
        elif bpm_target < 40:
            warnings.append(f"BPM ({bpm_target}) è¿‡ä½ï¼Œå¯èƒ½è¿‡äºå•è°ƒ")
            recommendations.append("å°†BPMè°ƒæ•´è‡³50-70èŒƒå›´")
        
        return recommendations, warnings
    
    def _log_evaluation_results(self, metrics: QualityMetrics):
        """è®°å½•è¯„ä¼°ç»“æœ"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š [éŸ³ä¹è´¨é‡è¯„ä¼° v1.0] è¯„ä¼°å®Œæˆ:")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ”§ æŠ€æœ¯è´¨é‡è¯„åˆ†: {metrics.technical_score:.2f}/1.0")
        logger.info(f"  - ä¿¡å™ªæ¯”: {metrics.signal_to_noise_ratio:.1f} dB")
        logger.info(f"  - åŠ¨æ€èŒƒå›´: {metrics.dynamic_range:.1f} dB")
        logger.info(f"  - é¢‘è°±è´¨å¿ƒ: {metrics.spectral_centroid_mean:.0f} Hz")
        logger.info(f"  - è¿‡é›¶ç‡: {metrics.zero_crossing_rate:.3f}")
        
        logger.info(f"\nğŸ’Š æ²»ç–—æ•ˆæœè¯„åˆ†: {metrics.therapeutic_score:.2f}/1.0")
        logger.info(f"  - èŠ‚å¥ç¨³å®šæ€§: {metrics.tempo_stability:.2f}")
        logger.info(f"  - éŸ³é‡ä¸€è‡´æ€§: {metrics.volume_consistency:.2f}")
        logger.info(f"  - æƒ…ç»ªä¸€è‡´æ€§: {metrics.emotional_coherence:.2f}")
        logger.info(f"  - æ²»ç–—é€‚ç”¨æ€§: {metrics.therapeutic_suitability:.2f}")
        
        logger.info(f"\nğŸŒŸ ç»¼åˆè¯„åˆ†: {metrics.overall_score:.2f}/1.0")
        
        if metrics.warnings:
            logger.info(f"\nâš ï¸ è´¨é‡è­¦å‘Š:")
            for warning in metrics.warnings:
                logger.info(f"  â€¢ {warning}")
        
        if metrics.recommendations:
            logger.info(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in metrics.recommendations:
                logger.info(f"  â€¢ {rec}")
        
        logger.info(f"{'='*60}")


# å·¥å‚å‡½æ•°
def create_music_quality_evaluator(sample_rate: int = 32000) -> MusicQualityEvaluator:
    """
    åˆ›å»ºéŸ³ä¹è´¨é‡è¯„ä¼°å™¨å®ä¾‹
    
    Args:
        sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
        
    Returns:
        MusicQualityEvaluatorå®ä¾‹
    """
    return MusicQualityEvaluator(sample_rate=sample_rate)