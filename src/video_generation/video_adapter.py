#!/usr/bin/env python3
"""
è§†é¢‘ç”Ÿæˆé€‚é…å™¨ - å°†æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨é›†æˆåˆ°å¿ƒå¢ƒæµè½¬ç³»ç»Ÿ

è®¾è®¡æ¨¡å¼ï¼šé€‚é…å™¨æ¨¡å¼
ç›®çš„ï¼šæ— ç¼é›†æˆæ–°çš„è§†é¢‘ç”ŸæˆåŠŸèƒ½åˆ°ç°æœ‰ç³»ç»Ÿ

ä½œè€…ï¼šå¿ƒå¢ƒæµè½¬å›¢é˜Ÿ
æ—¥æœŸï¼š2024
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union
import numpy as np

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.video_generation.therapeutic_video_generator import (
    TherapeuticVideoGenerator, VideoConfig, create_therapeutic_video_generator
)

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class VideoGenerationAdapter:
    """
    è§†é¢‘ç”Ÿæˆé€‚é…å™¨
    
    å°†æ–°çš„æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨é€‚é…åˆ°ç°æœ‰çš„MoodFlowAppç³»ç»Ÿ
    ä¿æŒå‘åå…¼å®¹æ€§ï¼ŒåŒæ—¶æä¾›å¢å¼ºåŠŸèƒ½
    """
    
    def __init__(self, 
                 use_therapeutic_generator: bool = True,
                 width: int = 1280,
                 height: int = 720,
                 fps: int = 30,
                 quality: str = "medium"):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            use_therapeutic_generator: æ˜¯å¦ä½¿ç”¨æ–°çš„æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨
            width: è§†é¢‘å®½åº¦
            height: è§†é¢‘é«˜åº¦
            fps: å¸§ç‡
            quality: è´¨é‡è®¾ç½®
        """
        self.use_therapeutic = use_therapeutic_generator
        self.width = width
        self.height = height
        self.fps = fps
        self.quality = quality
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        if self.use_therapeutic:
            try:
                self.generator = create_therapeutic_video_generator(
                    width=width, height=height, fps=fps, quality=quality
                )
                logger.info("âœ… æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.generator = None
                self.use_therapeutic = False
        else:
            self.generator = None
            
        # å›é€€åˆ°åŸå§‹ç”Ÿæˆå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        self.fallback_generator = None
    
    def generate_stage_videos_enhanced(self, 
                                     stages: List[Dict], 
                                     session_name: str,
                                     output_dir: Path,
                                     create_full_videos: bool = False,
                                     music_data: Optional[Dict] = None) -> List[str]:
        """
        å¢å¼ºçš„é˜¶æ®µè§†é¢‘ç”Ÿæˆ
        
        Args:
            stages: æ²»ç–—é˜¶æ®µåˆ—è¡¨
            session_name: ä¼šè¯åç§°
            output_dir: è¾“å‡ºç›®å½•
            create_full_videos: æ˜¯å¦ç”Ÿæˆå®Œæ•´è§†é¢‘
            music_data: éŸ³ä¹åŒæ­¥æ•°æ®
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not self.use_therapeutic or not self.generator:
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            return self._fallback_generate(stages, session_name, output_dir, create_full_videos)
        
        logger.info(f"ğŸ¬ [æ²»ç–—è§†é¢‘ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆ {len(stages)} ä¸ªé˜¶æ®µçš„è§†é¢‘")
        
        video_files = []
        
        for i, stage in enumerate(stages):
            stage_name = stage['stage'].value if hasattr(stage['stage'], 'value') else str(stage['stage'])
            stage_duration = stage['duration'] * 60  # åˆ†é’Ÿè½¬ç§’
            
            # ä»éŸ³ä¹æ•°æ®æå–BPM
            stage_bpm = None
            if music_data and 'bpms' in music_data:
                stage_bpm = music_data['bpms'].get(i, 60)
            
            logger.info(f"  é˜¶æ®µ{i+1}: {stage_name}")
            logger.info(f"    æ—¶é•¿: {stage_duration}ç§’")
            if stage_bpm:
                logger.info(f"    BPM: {stage_bpm}")
            
            # åˆ›å»ºé˜¶æ®µè¾“å‡ºç›®å½•
            stage_dir = output_dir / f"{session_name}_stage_{i+1}"
            stage_dir.mkdir(exist_ok=True)
            
            if create_full_videos:
                # ç”Ÿæˆå®Œæ•´è§†é¢‘
                video_path = stage_dir / f"stage_{i+1}_video.mp4"
                
                try:
                    self.generator.generate_therapy_video(
                        stage_name=stage_name,
                        duration_seconds=stage_duration,
                        music_bpm=stage_bpm,
                        output_path=str(video_path)
                    )
                    video_files.append(str(video_path))
                    logger.info(f"    âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_path.name}")
                    
                except Exception as e:
                    logger.error(f"    âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
                    # ç”Ÿæˆé¢„è§ˆå›¾ä½œä¸ºå¤‡ä»½
                    preview_path = self._generate_preview_fallback(
                        stage_name, stage_dir, i
                    )
                    if preview_path:
                        video_files.append(preview_path)
            else:
                # åªç”Ÿæˆé¢„è§ˆå›¾
                preview_path = self._generate_preview_enhanced(
                    stage_name, stage_duration, stage_bpm, stage_dir, i
                )
                if preview_path:
                    video_files.append(preview_path)
        
        return video_files
    
    def _generate_preview_enhanced(self, 
                                 stage_name: str,
                                 duration: float,
                                 bpm: Optional[int],
                                 output_dir: Path,
                                 stage_index: int) -> Optional[str]:
        """ç”Ÿæˆå¢å¼ºçš„é¢„è§ˆå›¾"""
        try:
            # ç”Ÿæˆé¢„è§ˆå¸§
            frames = self.generator.generate_therapy_video(
                stage_name=stage_name,
                duration_seconds=duration,
                music_bpm=bpm,
                output_path=None  # è¿”å›å¸§åˆ—è¡¨
            )
            
            if frames and len(frames) > 0:
                # ä¿å­˜ç¬¬ä¸€å¸§ä½œä¸ºé¢„è§ˆ
                preview_file = output_dir / "preview.png"
                
                # é€‰æ‹©ä¸­é—´å¸§ï¼ˆé€šå¸¸æ›´æœ‰ä»£è¡¨æ€§ï¼‰
                preview_frame = frames[len(frames)//2]
                
                # ä½¿ç”¨ç”Ÿæˆå™¨çš„ä¿å­˜æ–¹æ³•ï¼ˆå·²å¤„ç†cv2å¯ç”¨æ€§ï¼‰
                self.generator._save_frame_as_image(preview_frame, str(preview_file))
                
                logger.info(f"    âœ… é¢„è§ˆå›¾ç”ŸæˆæˆåŠŸ: {preview_file.name}")
                return str(preview_file)
            
        except Exception as e:
            logger.error(f"é¢„è§ˆç”Ÿæˆå¤±è´¥: {e}")
        
        return None
    
    def _generate_preview_fallback(self, stage_name: str, output_dir: Path, stage_index: int) -> Optional[str]:
        """ç”Ÿæˆç®€å•çš„å¤‡ä»½é¢„è§ˆå›¾"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.patches as patches
            
            fig, ax = plt.subplots(figsize=(8, 4.5))
            
            # èƒŒæ™¯é¢œè‰²ï¼ˆæ ¹æ®é˜¶æ®µï¼‰
            colors = {
                "åŒæ­¥åŒ–": "#4682B4",  # é’¢è“è‰²
                "å¼•å¯¼åŒ–": "#9370DB",  # ä¸­ç´«è‰²
                "å·©å›ºåŒ–": "#191970"   # åˆå¤œè“
            }
            bg_color = colors.get(stage_name, "#4169E1")
            
            ax.set_facecolor(bg_color)
            fig.patch.set_facecolor(bg_color)
            
            # æ·»åŠ åœ†å½¢å…ƒç´ 
            circle = patches.Circle((0.5, 0.5), 0.3, 
                                  facecolor='white', 
                                  alpha=0.2,
                                  transform=ax.transAxes)
            ax.add_patch(circle)
            
            # æ·»åŠ é˜¶æ®µæ–‡å­—
            ax.text(0.5, 0.5, stage_name, 
                   transform=ax.transAxes,
                   ha='center', va='center',
                   fontsize=24, color='white',
                   alpha=0.8)
            
            ax.set_xlim(0, 1)
            ax.set_ylim(0, 1)
            ax.axis('off')
            
            preview_file = output_dir / "preview.png"
            plt.savefig(preview_file, dpi=150, bbox_inches='tight', 
                       facecolor=bg_color, edgecolor='none')
            plt.close()
            
            return str(preview_file)
            
        except Exception as e:
            logger.error(f"å¤‡ä»½é¢„è§ˆç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def _fallback_generate(self, stages: List[Dict], session_name: str, 
                         output_dir: Path, create_full_videos: bool) -> List[str]:
        """å›é€€åˆ°åŸå§‹ç”Ÿæˆæ–¹æ³•"""
        logger.warning("ä½¿ç”¨åŸå§‹è§†é¢‘ç”Ÿæˆæ–¹æ³•")
        
        video_files = []
        
        # è¿™é‡Œå¯ä»¥è°ƒç”¨åŸå§‹çš„SleepVideoGenerator
        # æˆ–è€…ç”Ÿæˆç®€å•çš„å ä½å›¾ç‰‡
        for i, stage in enumerate(stages):
            stage_dir = output_dir / f"{session_name}_stage_{i+1}"
            stage_dir.mkdir(exist_ok=True)
            
            preview_path = self._generate_preview_fallback(
                stage['stage'].value if hasattr(stage['stage'], 'value') else str(stage['stage']),
                stage_dir, i
            )
            
            if preview_path:
                video_files.append(preview_path)
        
        return video_files
    
    def generate_complete_therapy_video(self,
                                      stages: List[Dict],
                                      session_name: str,
                                      output_path: str,
                                      music_sync_data: Optional[Dict] = None) -> Optional[str]:
        """
        ç”Ÿæˆå®Œæ•´çš„æ²»ç–—è§†é¢‘
        
        Args:
            stages: é˜¶æ®µåˆ—è¡¨
            session_name: ä¼šè¯åç§°
            output_path: è¾“å‡ºè·¯å¾„
            music_sync_data: éŸ³ä¹åŒæ­¥æ•°æ®
            
        Returns:
            è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–None
        """
        if not self.use_therapeutic or not self.generator:
            logger.warning("æ²»ç–—è§†é¢‘ç”Ÿæˆå™¨ä¸å¯ç”¨")
            return None
        
        try:
            logger.info("ğŸ¬ ç”Ÿæˆå®Œæ•´æ²»ç–—è§†é¢‘...")
            
            # ä½¿ç”¨æ–°çš„ç”Ÿæˆå™¨åˆ›å»ºå®Œæ•´è§†é¢‘
            video_path = self.generator.generate_complete_therapy_video(
                stages=stages,
                output_path=output_path,
                music_sync_data=music_sync_data
            )
            
            return video_path
            
        except Exception as e:
            logger.error(f"å®Œæ•´è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def get_generator_info(self) -> Dict:
        """è·å–ç”Ÿæˆå™¨ä¿¡æ¯"""
        if self.use_therapeutic and self.generator:
            return {
                "type": "therapeutic",
                "status": "active",
                "resolution": f"{self.width}x{self.height}",
                "fps": self.fps,
                "quality": self.quality,
                "features": [
                    "ä¸‰é˜¶æ®µæ²»ç–—è§†è§‰",
                    "éŸ³ä¹èŠ‚å¥åŒæ­¥",
                    "æ²»ç–—è‰²å½©æ–¹æ¡ˆ",
                    "å‘¼å¸å¼•å¯¼åŠ¨ç”»",
                    "åŒè€³è§†è§‰èŠ‚æ‹"
                ]
            }
        else:
            return {
                "type": "fallback",
                "status": "limited",
                "features": ["åŸºç¡€é¢„è§ˆå›¾ç”Ÿæˆ"]
            }


# ä¾¿æ·é›†æˆå‡½æ•°
def integrate_video_generation(mood_flow_app_instance, config: Optional[Dict] = None):
    """
    å°†è§†é¢‘ç”ŸæˆåŠŸèƒ½é›†æˆåˆ°MoodFlowApp
    
    Args:
        mood_flow_app_instance: MoodFlowAppå®ä¾‹
        config: é…ç½®é€‰é¡¹
    """
    # é»˜è®¤é…ç½®
    if config is None:
        config = {
            'use_therapeutic_generator': True,
            'width': 1280,
            'height': 720,
            'fps': 30,
            'quality': 'medium'
        }
    
    # åˆ›å»ºé€‚é…å™¨
    adapter = VideoGenerationAdapter(**config)
    
    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_generate_videos = mood_flow_app_instance.generate_stage_videos
    
    # å¢å¼ºçš„è§†é¢‘ç”Ÿæˆæ–¹æ³•
    def enhanced_generate_videos(stages, session_name, create_full_videos=False):
        # æ”¶é›†éŸ³ä¹æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        music_data = None
        if hasattr(mood_flow_app_instance, 'current_session'):
            music_data = {
                'bpms': []
            }
            # æå–æ¯ä¸ªé˜¶æ®µçš„BPM
            for stage in stages:
                emotion = stage['emotion']
                bpm = mood_flow_app_instance.music_model.calc_bpm(emotion.arousal)
                music_data['bpms'].append(bpm)
        
        # ä½¿ç”¨é€‚é…å™¨ç”Ÿæˆè§†é¢‘
        return adapter.generate_stage_videos_enhanced(
            stages=stages,
            session_name=session_name,
            output_dir=mood_flow_app_instance.output_dir,
            create_full_videos=create_full_videos,
            music_data=music_data
        )
    
    # æ›¿æ¢æ–¹æ³•
    mood_flow_app_instance.generate_stage_videos = enhanced_generate_videos
    
    # æ·»åŠ å®Œæ•´è§†é¢‘ç”ŸæˆåŠŸèƒ½
    mood_flow_app_instance.generate_complete_video = lambda stages, session_name, output_path, music_sync: \
        adapter.generate_complete_therapy_video(stages, session_name, output_path, music_sync)
    
    # æ·»åŠ è§†é¢‘ç”Ÿæˆå™¨ä¿¡æ¯æŸ¥è¯¢
    mood_flow_app_instance.get_video_generator_info = adapter.get_generator_info
    
    logger.info("âœ… è§†é¢‘ç”ŸæˆåŠŸèƒ½é›†æˆå®Œæˆ")
    
    return adapter