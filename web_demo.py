#!/usr/bin/env python3
"""
ã€Šå¿ƒå¢ƒæµè½¬ã€‹Webæ¼”ç¤ºç•Œé¢
ä½¿ç”¨Gradioåˆ›å»ºç®€å•çš„ç½‘é¡µç•Œé¢
"""

import gradio as gr
import numpy as np
import json
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import time
import os

# å¯¼å…¥æ ¸å¿ƒåŠŸèƒ½
try:
    from mood_flow_app import MoodFlowApp, TherapySession
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("æ­£åœ¨å°è¯•åŠ¨æ€å¯¼å…¥...")
    import importlib.util
    spec = importlib.util.spec_from_file_location("mood_flow_app", "mood_flow_app.py")
    mood_flow_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mood_flow_module)
    MoodFlowApp = mood_flow_module.MoodFlowApp
    TherapySession = mood_flow_module.TherapySession

class WebDemo:
    def __init__(self, use_enhanced_modules: bool = False):
        """
        åˆå§‹åŒ–Webæ¼”ç¤ºç•Œé¢
        
        Args:
            use_enhanced_modules: æ˜¯å¦ä½¿ç”¨ç†è®ºé©±åŠ¨çš„å¢å¼ºæ¨¡å—
        """
        self.app = MoodFlowApp(use_enhanced_modules=use_enhanced_modules)
        self.current_session = None
        # è®¾ç½®matplotlibä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼Œé¿å…å­—ä½“è­¦å‘Š
        import matplotlib.font_manager as fm
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # é€‰æ‹©å¯ç”¨çš„å­—ä½“ï¼Œä¼˜å…ˆä½¿ç”¨å¸¸è§å­—ä½“
        preferred_fonts = ['DejaVu Sans', 'Helvetica', 'Arial', 'Liberation Sans', 'sans-serif']
        selected_font = 'sans-serif'
        
        for font in preferred_fonts:
            if font in available_fonts or font == 'sans-serif':
                selected_font = font
                break
        
        plt.rcParams['font.family'] = selected_font
        plt.rcParams['axes.unicode_minus'] = False
    
    def safe_progress_update(self, progress, value, desc=""):
        """å®‰å…¨åœ°æ›´æ–°è¿›åº¦æ¡ï¼Œé¿å…Gradioç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜"""
        try:
            if progress is not None:
                progress(value, desc=desc)
        except Exception as e:
            # å¿½ç•¥è¿›åº¦æ¡æ›´æ–°é”™è¯¯ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
            print(f"è¿›åº¦æ¡æ›´æ–°è­¦å‘Š: {str(e)}")
            pass
        
    def process_voice_input(self, audio_file):
        """å¤„ç†è¯­éŸ³è¾“å…¥è½¬æ¢ä¸ºæ–‡å­—"""
        if audio_file is None:
            return "", "è¯·å½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
        
        try:
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°å’Œæ ¼å¼
            file_path = Path(audio_file)
            if not file_path.exists() or file_path.stat().st_size == 0:
                return "", "âŒ éŸ³é¢‘æ–‡ä»¶æ— æ•ˆæˆ–ä¸ºç©º"
            
            # ç®€åŒ–ç‰ˆè¯­éŸ³å¤„ç†ï¼šç›®å‰ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬
            # åœ¨å®é™…éƒ¨ç½²æ—¶å¯ä»¥é›†æˆä¸“ä¸šçš„è¯­éŸ³è¯†åˆ«æœåŠ¡
            sample_texts = [
                "ä»Šå¤©å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œèººåœ¨åºŠä¸Šç¿»æ¥è¦†å»ç¡ä¸ç€ï¼Œæ€»æ˜¯æƒ³ç€æ˜å¤©çš„ä¼šè®®",
                "æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°ç„¦è™‘ï¼Œæ™šä¸Šå¾ˆéš¾å…¥ç¡ï¼Œå³ä½¿ç¡ç€äº†ä¹Ÿå®¹æ˜“é†’",
                "å¿ƒæƒ…æœ‰äº›ä½è½ï¼Œæ„Ÿè§‰å¾ˆç–²æƒ«ä½†å°±æ˜¯ç¡ä¸ç€ï¼Œå¯¹ä»€ä¹ˆéƒ½æä¸èµ·å…´è¶£",
                "æœ‰ç‚¹å…´å¥‹ç¡ä¸ç€ï¼Œè„‘å­é‡Œæƒ³ç€å¾ˆå¤šäº‹æƒ…ï¼Œè¶Šæƒ³è¶Šæ¸…é†’",
                "èº«å¿ƒä¿±ç–²ï¼Œä½†èººä¸‹åå¤§è„‘è¿˜æ˜¯å¾ˆæ´»è·ƒï¼Œæ€»æ˜¯èƒ¡æ€ä¹±æƒ³"
            ]
            
            import random
            import hashlib
            
            # åŸºäºæ–‡ä»¶å†…å®¹ç”Ÿæˆä¸€è‡´çš„ç¤ºä¾‹æ–‡æœ¬
            with open(audio_file, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            
            # ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œé€‰æ‹©ç¤ºä¾‹æ–‡æœ¬ï¼Œç¡®ä¿åŒä¸€æ–‡ä»¶è¿”å›ç›¸åŒç»“æœ
            text_index = int(file_hash[:8], 16) % len(sample_texts)
            selected_text = sample_texts[text_index]
            
            return selected_text, f"ğŸ¤ è¯­éŸ³å·²å¤„ç† (æ¼”ç¤ºæ¨¡å¼): {selected_text}"
                
        except Exception as e:
            return "", f"âŒ è¯­éŸ³å¤„ç†å‡ºé”™: {str(e)}"
    
    def process_input(self, text_input, audio_input, emotion_type=None, demo_mode=True, playback_mode="ğŸµ ä»…éŸ³ä¹", progress=gr.Progress()):
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆæ²»ç–—æ–¹æ¡ˆ"""
        # å¤„ç†è¯­éŸ³è¾“å…¥
        voice_text = ""
        voice_status = ""
        if audio_input is not None:
            voice_text, voice_status = self.process_voice_input(audio_input)
            if voice_text:
                text_input = voice_text if not text_input else f"{text_input} {voice_text}"
        
        if not text_input and emotion_type:
            # å¦‚æœæ²¡æœ‰æ–‡å­—è¾“å…¥ï¼Œä½¿ç”¨é¢„è®¾æƒ…ç»ª
            emotion_templates = {
                "ç„¦è™‘": "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒé‡Œæ€»æ˜¯ä¸å®‰ï¼Œæ‹…å¿ƒå¾ˆå¤šäº‹æƒ…",
                "å‹åŠ›": "å·¥ä½œå‹åŠ›å¤ªå¤§äº†ï¼Œæ„Ÿè§‰å–˜ä¸è¿‡æ°”æ¥",
                "å¤±çœ ": "èººåœ¨åºŠä¸Šç¿»æ¥è¦†å»å°±æ˜¯ç¡ä¸ç€",
                "æŠ‘éƒ": "å¿ƒæƒ…å¾ˆä½è½ï¼Œä»€ä¹ˆéƒ½ä¸æƒ³åš",
                "ç–²æƒ«": "èº«å¿ƒä¿±ç–²ï¼Œä½†å°±æ˜¯æ— æ³•å…¥ç¡"
            }
            text_input = emotion_templates.get(emotion_type, "æˆ‘ç¡ä¸ç€")
        
        if not text_input:
            error_msg = "è¯·é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼æä¾›è¾“å…¥:\nâ€¢ åœ¨æ–‡å­—æ¡†ä¸­æè¿°æ‚¨çš„æ„Ÿå—\nâ€¢ å½•åˆ¶è¯­éŸ³æè¿°\nâ€¢ é€‰æ‹©é¢„è®¾æƒ…ç»ªç±»å‹"
            if voice_status:
                error_msg = f"{voice_status}\n\n{error_msg}"
            return None, None, None, None, None, None, None, gr.Row(visible=False), error_msg
        
        try:
            # æ ¹æ®æ¨¡å¼è®¾ç½®æ—¶é•¿
            duration = 5 if demo_mode else 20
            self.safe_progress_update(progress, 0.1, "Starting emotion analysis...")
            
            # æ ¹æ®æ’­æ”¾æ¨¡å¼å†³å®šæ˜¯å¦ç”Ÿæˆå®Œæ•´è§†é¢‘
            create_videos = (playback_mode == "ğŸµ+ğŸ¬ éŸ³ç”»ç»“åˆ")
            
            # è¿è¡Œæ²»ç–—ä¼šè¯
            session = self.app.run_therapy_session(text_input, duration=duration, create_full_videos=create_videos, progress_callback=progress)
            self.current_session = session
            
            self.safe_progress_update(progress, 0.9, "Finalizing outputs...")
            
            # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶
            report_image = session.music_file.replace("_therapy_music.wav", "_report.png")
            
            # æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(report_image):
                print(f"âš ï¸ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_image}")
                # æ‰‹åŠ¨è§¦å‘æŠ¥å‘Šç”Ÿæˆ
                report_image = self.app.create_visualization(session)
            
            # è§†è§‰å¼•å¯¼é¢„è§ˆ - æŸ¥æ‰¾PNGé¢„è§ˆå›¾è€Œä¸æ˜¯MP4è§†é¢‘
            video_output = None
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - è§†é¢‘æ–‡ä»¶åˆ—è¡¨: {session.video_files}")
            if session.video_files and len(session.video_files) > 0:
                # å¯»æ‰¾PNGé¢„è§ˆå›¾ï¼Œè€Œä¸æ˜¯MP4è§†é¢‘
                for video_file in session.video_files:
                    if video_file.endswith('.png'):  # åªå¤„ç†PNGå›¾ç‰‡
                        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - æ£€æŸ¥å›¾ç‰‡é¢„è§ˆè·¯å¾„: {video_file}")
                        if os.path.exists(video_file):
                            video_output = video_file
                            print(f"âœ… å›¾ç‰‡é¢„è§ˆæ–‡ä»¶å­˜åœ¨: {video_file}")
                            break
                        else:
                            print(f"âš ï¸ å›¾ç‰‡é¢„è§ˆæ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
                
                # å¦‚æœæ‰¾ä¸åˆ°PNGæ–‡ä»¶ï¼Œå°è¯•ä»MP4åŒç›®å½•æ‰¾preview.png
                if not video_output and session.video_files:
                    first_video_dir = os.path.dirname(session.video_files[0])
                    preview_path = os.path.join(first_video_dir, "preview.png")
                    print(f"ğŸ” å°è¯•æŸ¥æ‰¾é¢„è§ˆå›¾: {preview_path}")
                    if os.path.exists(preview_path):
                        video_output = preview_path
                        print(f"âœ… æ‰¾åˆ°é¢„è§ˆå›¾: {preview_path}")
                    else:
                        print(f"âš ï¸ é¢„è§ˆå›¾ä¸å­˜åœ¨: {preview_path}")
                        # åˆ—å‡ºç›®å½•å†…å®¹
                        try:
                            if os.path.exists(first_video_dir):
                                files = os.listdir(first_video_dir)
                                print(f"ğŸ” ç›®å½• {first_video_dir} å†…å®¹: {files}")
                        except Exception as e:
                            print(f"âš ï¸ æ— æ³•åˆ—å‡ºç›®å½•å†…å®¹: {e}")
            else:
                print("âš ï¸ æ²¡æœ‰ç”Ÿæˆè§†é¢‘æ–‡ä»¶")
            
            # æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - æŠ¥å‘Šæ–‡ä»¶è·¯å¾„: {report_image}")
            if os.path.exists(report_image):
                print(f"âœ… æŠ¥å‘Šæ–‡ä»¶å­˜åœ¨: {report_image}")
            else:
                print(f"âš ï¸ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_image}")
            
            # æ ¹æ®æ’­æ”¾æ¨¡å¼å¤„ç†è¾“å‡º
            if playback_mode == "ğŸµ ä»…éŸ³ä¹":
                combined_output = session.music_file
            else:  # ğŸµ+ğŸ¬ éŸ³ç”»ç»“åˆ
                # éŸ³ç”»ç»“åˆæ¨¡å¼ï¼Œå¦‚æœæœ‰åˆå¹¶è§†é¢‘åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨éŸ³é¢‘
                if hasattr(session, 'combined_video') and session.combined_video:
                    combined_output = session.combined_video
                else:
                    combined_output = session.music_file
            
            # ç”ŸæˆçŠ¶æ€ä¿¡æ¯
            mode_text = "Demo (5 min)" if demo_mode else "Full (20 min)"
            playback_text = "Audio Only" if playback_mode == "ğŸµ ä»…éŸ³ä¹" else "Audio + Video"
            status_parts = [f"âœ… Therapy plan generated! ({mode_text}, {playback_text})"]
            if voice_status:
                status_parts.append(f"\nğŸ¤ {voice_status}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éŸ³ç”»ç»“åˆæ–‡ä»¶
            has_combined_video = hasattr(session, 'combined_video') and session.combined_video
            output_file_info = ""
            if has_combined_video:
                output_file_info = f"â€¢ ğŸ¬+ğŸµ Combined Video: {Path(session.combined_video).name}\nâ€¢ ğŸµ Audio Only: {Path(session.music_file).name}"
            else:
                output_file_info = f"â€¢ ğŸµ Music: {Path(session.music_file).name}"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¯¦ç»†æƒ…ç»ªä¿¡æ¯ï¼ˆå¢å¼ºæ¨¡å—ï¼‰
            detailed_emotion_info = ""
            if hasattr(self.app, 'get_detailed_emotion_info'):
                detailed_info = self.app.get_detailed_emotion_info(session.detected_emotion)
                if detailed_info:
                    detailed_emotion_info = f"""

ğŸ§  Fine-grained Emotion Analysis:
â€¢ Primary: {detailed_info['primary_emotion_cn']} ({detailed_info['primary_emotion']})
â€¢ Confidence: {detailed_info['confidence']:.1%}
â€¢ Intensity: {detailed_info['intensity']:.1%}"""
            
            status = f"""
{status_parts[0]}{status_parts[1] if len(status_parts) > 1 else ''}

ğŸ“Š Detected Emotion:
â€¢ Valence: {session.detected_emotion.valence:.2f}
â€¢ Arousal: {session.detected_emotion.arousal:.2f}{detailed_emotion_info}

ğŸµ Music Therapy:
â€¢ Total Duration: {sum(s['duration'] for s in session.iso_stages)} minutes
â€¢ 3 Stages: {' â†’ '.join(s['stage'].value for s in session.iso_stages)}

ğŸ’¡ Usage Guide:
1. Find a quiet and comfortable environment
2. Dim the lights and relax your body
3. Put on headphones to listen to the music
4. Follow the visual guidance to adjust breathing

ğŸ“ Generated Files:
{output_file_info}
â€¢ ğŸ¬ Video Previews: {len(session.video_files)} stage previews
"""
            
            # æ ¹æ®æ’­æ”¾æ¨¡å¼å‡†å¤‡è¾“å‡º
            if playback_mode == "ğŸµ ä»…éŸ³ä¹":
                # ä»…éŸ³ä¹æ¨¡å¼
                audio_out = session.music_file
                audio_download_out = session.music_file
                video_player_out = None
                video_download_out = None
                video_row_visible = gr.Row(visible=False)
            else:  # ğŸµ+ğŸ¬ éŸ³ç”»ç»“åˆ
                # éŸ³ç”»ç»“åˆæ¨¡å¼
                if hasattr(session, 'combined_video') and session.combined_video:
                    audio_out = None  # ä¸æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
                    audio_download_out = session.music_file  # æä¾›éŸ³é¢‘ä¸‹è½½
                    video_player_out = session.combined_video  # æ˜¾ç¤ºè§†é¢‘æ’­æ”¾å™¨
                    video_download_out = session.combined_video
                    video_row_visible = gr.Row(visible=True)
                else:
                    # å¦‚æœæ²¡æœ‰ç”Ÿæˆåˆå¹¶è§†é¢‘ï¼Œå›é€€åˆ°éŸ³é¢‘æ¨¡å¼
                    audio_out = session.music_file
                    audio_download_out = session.music_file
                    video_player_out = None
                    video_download_out = None
                    video_row_visible = gr.Row(visible=False)
            
            self.safe_progress_update(progress, 1.0, "Complete!")
            return audio_out, audio_download_out, video_output, video_player_out, video_download_out, report_image, self.create_simple_visualization(), video_row_visible, status
            
        except Exception as e:
            import traceback
            # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°åç«¯ç»ˆç«¯
            print(f"\n{'='*60}")
            print("ğŸš¨ Webç•Œé¢å¤„ç†å‡ºé”™:")
            print(f"{'='*60}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            print(f"è¾“å…¥å‚æ•°:")
            print(f"  - text_input: {text_input}")
            print(f"  - audio_input: {audio_input}")
            print(f"  - emotion_type: {emotion_type}")
            print(f"  - demo_mode: {demo_mode}")
            print(f"  - playback_mode: {playback_mode}")
            print(f"\nå®Œæ•´é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            print(f"{'='*60}")
            
            # ç”Ÿæˆå‰ç«¯é”™è¯¯ä¿¡æ¯
            error_msg = f"âŒ å¤„ç†å‡ºé”™: {str(e)}\n\né”™è¯¯ç±»å‹: {type(e).__name__}"
            if voice_status:
                error_msg = f"{voice_status}\n\n{error_msg}"
            
            return None, None, None, None, None, None, None, gr.Row(visible=False), error_msg
    
    def create_simple_visualization(self):
        """åˆ›å»ºç®€å•çš„å¯è§†åŒ–"""
        try:
            if not self.current_session:
                print("âš ï¸ è­¦å‘Š: current_sessionä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºå¯è§†åŒ–")
                return None
            
            if not self.current_session.iso_stages:
                print("âš ï¸ è­¦å‘Š: iso_stagesä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºå¯è§†åŒ–")
                return None
            
            fig, ax = plt.subplots(figsize=(8, 6))
        
            # å®‰å…¨åœ°æ„å»ºæ•°æ®
            stages = ["Start"]
            valences = [self.current_session.detected_emotion.valence]
            arousals = [self.current_session.detected_emotion.arousal]
            times = [0]
            
            current_time = 0
            for stage in self.current_session.iso_stages:
                # è½¬æ¢é˜¶æ®µåä¸ºè‹±æ–‡
                stage_name = stage['stage'].value
                if 'åŒæ­¥åŒ–' in stage_name:
                    stage_en = 'Sync'
                elif 'å¼•å¯¼åŒ–' in stage_name:
                    stage_en = 'Guide'
                elif 'å·©å›ºåŒ–' in stage_name:
                    stage_en = 'Consolidate'
                else:
                    stage_en = stage_name
                
                stages.append(stage_en)
                valences.append(stage['emotion'].valence)
                arousals.append(stage['emotion'].arousal)
                current_time += stage['duration']
                times.append(current_time)
            
            # éªŒè¯æ•°æ®ä¸€è‡´æ€§
            if not (len(times) == len(valences) == len(arousals) == len(stages)):
                print(f"âš ï¸ æ•°æ®é•¿åº¦ä¸ä¸€è‡´: times={len(times)}, valences={len(valences)}, arousals={len(arousals)}, stages={len(stages)}")
                return None
            
            # ç»˜åˆ¶æ›²çº¿
            ax.plot(times, valences, 'b-o', linewidth=2, markersize=8, label='Valence')
            ax.plot(times, arousals, 'r-o', linewidth=2, markersize=8, label='Arousal')
            
            # æ·»åŠ é˜¶æ®µæ ‡æ³¨
            for i in range(1, len(times)):
                if i < len(stages):
                    ax.axvline(x=times[i], color='gray', linestyle='--', alpha=0.3)
                    ax.text(times[i]-0.5, 0.9, stages[i], rotation=45, fontsize=10)
            
            ax.set_xlabel('Time (minutes)')
            ax.set_ylabel('Emotion Value')
            ax.set_title('ISO 3-Stage Emotion Guidance Trajectory')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim(-1, 1)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            viz_path = Path("outputs/demo_sessions") / "current_visualization.png"
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            viz_path.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(viz_path)
            plt.close()
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¿å­˜
            if viz_path.exists():
                print(f"âœ… å¯è§†åŒ–å›¾è¡¨ä¿å­˜æˆåŠŸ: {viz_path}")
                return str(viz_path)
            else:
                print(f"âŒ å¯è§†åŒ–å›¾è¡¨ä¿å­˜å¤±è´¥: {viz_path}")
                return None
        
        except Exception as e:
            import traceback
            print(f"âš ï¸ å¯è§†åŒ–åˆ›å»ºå‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

def create_interface(use_enhanced_modules: bool = False):
    """
    åˆ›å»ºGradioç•Œé¢
    
    Args:
        use_enhanced_modules: æ˜¯å¦ä½¿ç”¨ç†è®ºé©±åŠ¨çš„å¢å¼ºæ¨¡å—
    """
    demo = WebDemo(use_enhanced_modules=use_enhanced_modules)
    
    with gr.Blocks(title="å¿ƒå¢ƒæµè½¬ - ç¡çœ æ²»ç–—ç³»ç»Ÿ", theme=gr.themes.Soft()) as interface:
        # æ˜¾ç¤ºå½“å‰è¿è¡Œæ¨¡å¼
        if demo.app.use_enhanced and hasattr(demo.app, 'enhancement_adapter'):
            enhancement_status = demo.app.get_enhancement_status() if hasattr(demo.app, 'get_enhancement_status') else {}
            status_text = "âœ… **å¢å¼ºæ¨¡å¼** (ç†è®ºé©±åŠ¨ä¼˜åŒ–)"
            
            # æ˜¾ç¤ºå„æ¨¡å—çŠ¶æ€
            module_status = []
            if enhancement_status.get('emotion_recognition', False):
                module_status.append("ğŸ§  ç»†ç²’åº¦æƒ…ç»ªè¯†åˆ«")
            if enhancement_status.get('therapy_planning', False):
                module_status.append("ğŸ“‹ ISOæ²»ç–—è§„åˆ’")
            if enhancement_status.get('music_mapping', False):
                module_status.append("ğŸµ ç²¾å‡†éŸ³ä¹æ˜ å°„")
            
            if module_status:
                status_text += f"\n\nå·²å¯ç”¨æ¨¡å—ï¼š{' | '.join(module_status)}"
        else:
            status_text = "ğŸ”§ **åŸºç¡€æ¨¡å¼**"
        
        gr.Markdown(f"""
        # ğŸŒ™ ã€Šå¿ƒå¢ƒæµè½¬ã€‹AIç¡çœ æ²»ç–—ç³»ç»Ÿ
        
        {status_text}
        
        åŸºäºISOä¸‰é˜¶æ®µåŸåˆ™å’Œæƒ…ç»ªè¯†åˆ«æŠ€æœ¯ï¼Œä¸ºæ‚¨ç”Ÿæˆä¸ªæ€§åŒ–çš„éŸ³è§†é¢‘ç¡çœ æ²»ç–—æ–¹æ¡ˆã€‚
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ è¾“å…¥æ‚¨çš„æ„Ÿå—")
                
                # é€‰é¡¹å¡ï¼šæ–‡å­—æˆ–è¯­éŸ³è¾“å…¥
                with gr.Tabs():
                    with gr.TabItem("ğŸ’¬ æ–‡å­—è¾“å…¥"):
                        text_input = gr.Textbox(
                            label="æè¿°æ‚¨çš„æ„Ÿå—",
                            placeholder="ä¾‹å¦‚ï¼šä»Šå¤©å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œèººåœ¨åºŠä¸Šç¿»æ¥è¦†å»ç¡ä¸ç€...",
                            lines=4
                        )
                    
                    with gr.TabItem("ğŸ¤ è¯­éŸ³è¾“å…¥"):
                        audio_input = gr.Audio(
                            label="å½•åˆ¶æˆ–ä¸Šä¼ è¯­éŸ³",
                            type="filepath",
                            format="wav"
                        )
                        gr.Markdown("ğŸ’¡ **æç¤º**: å½•åˆ¶åè¯·ç‚¹å‡»'ç”Ÿæˆæ²»ç–—æ–¹æ¡ˆ'æŒ‰é’®")
                
                gr.Markdown("### ğŸ¯ æˆ–å¿«é€Ÿé€‰æ‹©æƒ…ç»ª:")
                emotion_buttons = gr.Radio(
                    choices=["ç„¦è™‘", "å‹åŠ›", "å¤±çœ ", "æŠ‘éƒ", "ç–²æƒ«"],
                    label="é¢„è®¾æƒ…ç»ª",
                    value=None
                )
                
                gr.Markdown("### âš™ï¸ ç³»ç»Ÿè®¾ç½®:")
                with gr.Row():
                    demo_mode_toggle = gr.Checkbox(
                        label="æ¼”ç¤ºæ¨¡å¼ (5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ)",
                        value=True
                    )
                    
                playback_mode = gr.Radio(
                    choices=["ğŸµ ä»…éŸ³ä¹", "ğŸµ+ğŸ¬ éŸ³ç”»ç»“åˆ"],
                    label="æ’­æ”¾æ¨¡å¼",
                    value="ğŸµ ä»…éŸ³ä¹"
                )
                
                submit_btn = gr.Button("ğŸš€ ç”Ÿæˆæ²»ç–—æ–¹æ¡ˆ", variant="primary", size="lg")
                
                gr.Markdown("""
                ### ğŸ’¡ ä½¿ç”¨æŒ‡å—
                1. **è¾“å…¥æ–¹å¼**ï¼šé€‰æ‹©æ–‡å­—æˆ–è¯­éŸ³æè¿°
                2. **ç”Ÿæˆæ–¹æ¡ˆ**ï¼šç‚¹å‡»æŒ‰é’®å¼€å§‹å¤„ç†
                3. **è†å¬éŸ³ä¹**ï¼šæ’­æ”¾ä¸ªæ€§åŒ–æ²»ç–—éŸ³ä¹
                4. **è§‚çœ‹è§†é¢‘**ï¼šæŸ¥çœ‹é…å¥—çš„è§†è§‰å¼•å¯¼
                5. **æŸ¥çœ‹æŠ¥å‘Š**ï¼šäº†è§£æƒ…ç»ªåˆ†æå’Œæ²»ç–—è½¨è¿¹
                """)
                
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ¯ ä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆ")
                
                status_output = gr.Textbox(
                    label="ğŸ“‹ å¤„ç†çŠ¶æ€",
                    lines=12,
                    interactive=False
                )
                
                with gr.Row():
                    with gr.Column():
                        audio_output = gr.Audio(
                            label="ğŸµ æ²»ç–—éŸ³ä¹",
                            type="filepath",
                            autoplay=False
                        )
                        audio_download = gr.File(
                            label="ğŸ“¥ éŸ³é¢‘ä¸‹è½½",
                            type="filepath",
                            visible=False
                        )
                    
                    with gr.Column():
                        video_output = gr.Image(
                            label="ğŸ¬ è§†è§‰å¼•å¯¼é¢„è§ˆ",
                            type="filepath"
                        )
                
                # éŸ³ç”»ç»“åˆè§†é¢‘æ’­æ”¾å™¨ï¼ˆæ¡ä»¶æ˜¾ç¤ºï¼‰
                with gr.Row(visible=False) as video_player_row:
                    with gr.Column():
                        combined_video_player = gr.Video(
                            label="ğŸ¬+ğŸµ éŸ³ç”»ç»“åˆæ²»ç–—è§†é¢‘",
                            autoplay=False
                        )
                        combined_video_download = gr.File(
                            label="ğŸ“¥ å®Œæ•´è§†é¢‘ä¸‹è½½",
                            type="filepath"
                        )
                
                with gr.Row():
                    report_output = gr.Image(
                        label="ğŸ“Š è¯¦ç»†åˆ†ææŠ¥å‘Š",
                        type="filepath"
                    )
                    
                    viz_output = gr.Image(
                        label="ğŸ“ˆ æƒ…ç»ªè½¨è¿¹å›¾",
                        type="filepath"
                    )
        
        # ç¤ºä¾‹
        gr.Markdown("### ğŸŒŸ ç¤ºä¾‹åœºæ™¯")
        gr.Examples(
            examples=[
                ["æœ€è¿‘æ€»æ˜¯å¤±çœ ï¼Œä¸€èººä¸‹å°±å¼€å§‹èƒ¡æ€ä¹±æƒ³ï¼Œè¶Šæƒ³è¶Šæ¸…é†’"],
                ["å·¥ä½œå‹åŠ›å¤ªå¤§äº†ï¼Œæ¯å¤©éƒ½å¾ˆç„¦è™‘ï¼Œæ™šä¸Šæ ¹æœ¬ç¡ä¸å¥½"],
                ["å¿ƒæƒ…å¾ˆä½è½ï¼Œå¯¹ä»€ä¹ˆéƒ½æä¸èµ·å…´è¶£ï¼Œæ™šä¸Šä¹Ÿç¡ä¸ç€"],
                ["ä»Šå¤©å‘ç”Ÿäº†ä¸€äº›çƒ¦å¿ƒäº‹ï¼Œç°åœ¨å¾ˆç”Ÿæ°”ï¼Œå®Œå…¨æ²¡æœ‰ç¡æ„"],
                ["ç™½å¤©å¤ªç´¯äº†ï¼Œä½†èººåœ¨åºŠä¸Šåè€Œç¡ä¸ç€ï¼Œå¤§è„‘è¿˜æ˜¯å¾ˆæ´»è·ƒ"]
            ],
            inputs=text_input
        )
        
        # ç»‘å®šäº‹ä»¶
        submit_btn.click(
            fn=demo.process_input,
            inputs=[text_input, audio_input, emotion_buttons, demo_mode_toggle, playback_mode],
            outputs=[audio_output, audio_download, video_output, combined_video_player, combined_video_download, report_output, viz_output, video_player_row, status_output]
        )
        
    return interface

def find_free_port(start_port=7860, max_port=7900):
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    import socket
    for port in range(start_port, max_port):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('', port))
                return port
        except OSError:
            continue
    return None

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¿ƒå¢ƒæµè½¬ç¡çœ æ²»ç–—ç³»ç»ŸWebç•Œé¢')
    parser.add_argument('--enhanced', action='store_true', 
                       help='å¯ç”¨ç†è®ºé©±åŠ¨çš„å¢å¼ºæ¨¡å—ï¼ˆç»†ç²’åº¦æƒ…ç»ªè¯†åˆ«ã€ç²¾å‡†éŸ³ä¹æ˜ å°„ç­‰ï¼‰')
    parser.add_argument('--port', type=int, default=None,
                       help='æŒ‡å®šç«¯å£å·ï¼ˆé»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾7860-7900ï¼‰')
    parser.add_argument('--share', action='store_true', default=True,
                       help='åˆ›å»ºå…¬å…±åˆ†äº«é“¾æ¥ï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--no-browser', action='store_true',
                       help='ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨')
    
    args = parser.parse_args()
    
    print("å¯åŠ¨Webæ¼”ç¤ºç•Œé¢...")
    if args.enhanced:
        print("ğŸ“š ä½¿ç”¨ç†è®ºé©±åŠ¨çš„å¢å¼ºæ¨¡å—")
        print("  - ç»†ç²’åº¦æƒ…ç»ªè¯†åˆ«ï¼ˆ9ç§æƒ…ç»ªåˆ†ç±»ï¼‰")
        print("  - ISOåŸåˆ™æ²»ç–—è·¯å¾„è§„åˆ’")
        print("  - ç²¾å‡†éŸ³ä¹ç‰¹å¾æ˜ å°„")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path("outputs/demo_sessions").mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾å¯ç”¨ç«¯å£
    if args.port:
        port = args.port
        print(f"ğŸš€ ä½¿ç”¨æŒ‡å®šç«¯å£: {port}")
    else:
        port = find_free_port()
        if port is None:
            print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ (7860-7900)")
            print("è¯·æ‰‹åŠ¨ç»ˆæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹æˆ–æŒ‡å®šå…¶ä»–ç«¯å£")
            return
        print(f"ğŸš€ ä½¿ç”¨ç«¯å£: {port}")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    interface = create_interface(use_enhanced_modules=args.enhanced)
    
    # å¯åŠ¨æœåŠ¡
    interface.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=port,
        share=args.share,  # åˆ›å»ºå…¬å…±é“¾æ¥
        inbrowser=not args.no_browser,  # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
        show_error=True
    )

if __name__ == "__main__":
    main()