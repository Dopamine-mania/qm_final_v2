{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿåˆå§‹åŒ–\n",
    "\n",
    "æœ¬notebookç”¨äºåˆå§‹åŒ–å’ŒéªŒè¯\"å¿ƒå¢ƒæµè½¬\"ç¡å‰éŸ³ç”»ç–—æ„ˆç³»ç»Ÿçš„è¿è¡Œç¯å¢ƒã€‚\n",
    "\n",
    "## ğŸ¯ ç›®æ ‡\n",
    "- æ£€æµ‹JupyterHubç¯å¢ƒå’Œç¡¬ä»¶èµ„æº\n",
    "- éªŒè¯æ‰€éœ€ä¾èµ–åº“çš„å®‰è£…\n",
    "- é…ç½®ç³»ç»Ÿå‚æ•°å’Œè·¯å¾„\n",
    "- è¿›è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "\n",
    "## âš ï¸ é‡è¦æç¤º\n",
    "- é¦–æ¬¡è¿è¡Œæ­¤ç³»ç»Ÿæ—¶å¿…é¡»æ‰§è¡Œæ­¤notebook\n",
    "- ç¡®ä¿å…·æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ (40GB+)\n",
    "- æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒæ£€æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿç¯å¢ƒæ£€æµ‹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŸºç¡€ç¯å¢ƒä¿¡æ¯\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
    "print(f\"CPUæ¶æ„: {platform.machine()}\")\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"Pythonè·¯å¾„: {sys.executable}\")\n",
    "print(f\"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# ä¿®å¤Pythonè·¯å¾„å’Œé¡¹ç›®ç»“æ„é—®é¢˜\nimport sys\nimport os\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# æ™ºèƒ½æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•\ncurrent_dir = Path.cwd()\nif current_dir.name == 'notebooks':\n    # å¦‚æœåœ¨notebooksç›®å½•ä¸­è¿è¡Œ\n    PROJECT_ROOT = current_dir.parent\nelif (current_dir / 'notebooks').exists():\n    # å¦‚æœåœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ\n    PROJECT_ROOT = current_dir\nelse:\n    # å°è¯•å‘ä¸ŠæŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•\n    PROJECT_ROOT = current_dir\n    for parent in current_dir.parents:\n        if (parent / 'src').exists() and (parent / 'notebooks').exists():\n            PROJECT_ROOT = parent\n            break\n\nprint(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {current_dir}\")\nprint(f\"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}\")\n\n# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path\nproject_paths = [\n    str(PROJECT_ROOT),\n    str(PROJECT_ROOT / 'src'),\n    str(PROJECT_ROOT / 'research')\n]\n\nfor path in project_paths:\n    if path not in sys.path:\n        sys.path.insert(0, path)\n\nprint(\"ğŸ Pythonè·¯å¾„å·²æ›´æ–°:\")\nfor i, path in enumerate(project_paths):\n    print(f\"  [{i}] {path}\")\n\n# éªŒè¯é¡¹ç›®ç»“æ„å¹¶åˆ›å»ºç¼ºå¤±ç›®å½•\nrequired_structures = {\n    'src': ['core', 'models', 'therapy', 'optimization', 'evaluation'],\n    'research': ['theory'],\n    'notebooks': [],\n    'outputs': ['audio', 'video', 'logs', 'models', 'reports', 'cache'],\n    'configs': [],\n    'api': []\n}\n\nprint(\"\\nğŸ“ é¡¹ç›®ç»“æ„éªŒè¯ä¸ä¿®å¤:\")\nall_good = True\n\nfor main_dir, subdirs in required_structures.items():\n    main_path = PROJECT_ROOT / main_dir\n    if main_path.exists():\n        print(f\"âœ… {main_dir}/\")\n    else:\n        main_path.mkdir(parents=True, exist_ok=True)\n        print(f\"ğŸ”§ {main_dir}/ (å·²åˆ›å»º)\")\n        all_good = False\n    \n    # æ£€æŸ¥å­ç›®å½•\n    for subdir in subdirs:\n        sub_path = main_path / subdir\n        if sub_path.exists():\n            print(f\"âœ… {main_dir}/{subdir}/\")\n        else:\n            sub_path.mkdir(parents=True, exist_ok=True)\n            print(f\"ğŸ”§ {main_dir}/{subdir}/ (å·²åˆ›å»º)\")\n\n# è®¾ç½®ç¯å¢ƒå˜é‡\nos.environ['PROJECT_ROOT'] = str(PROJECT_ROOT)\ncache_dir = PROJECT_ROOT / 'outputs' / 'cache'\nos.environ['TRANSFORMERS_CACHE'] = str(cache_dir / 'transformers')\nos.environ['HF_HOME'] = str(cache_dir / 'huggingface')\n\nprint(f\"\\nâœ… é¡¹ç›®ç»“æ„éªŒè¯å®Œæˆ\")\nprint(f\"ğŸ“¦ ç¼“å­˜ç›®å½•: {cache_dir}\")\n\n# åˆ›å»ºå¿…è¦çš„__init__.pyæ–‡ä»¶\ninit_files = [\n    PROJECT_ROOT / 'src' / '__init__.py',\n    PROJECT_ROOT / 'src' / 'core' / '__init__.py',\n    PROJECT_ROOT / 'src' / 'models' / '__init__.py',\n    PROJECT_ROOT / 'src' / 'therapy' / '__init__.py',\n    PROJECT_ROOT / 'src' / 'optimization' / '__init__.py',\n    PROJECT_ROOT / 'src' / 'evaluation' / '__init__.py',\n    PROJECT_ROOT / 'research' / '__init__.py',\n    PROJECT_ROOT / 'research' / 'theory' / '__init__.py'\n]\n\nfor init_file in init_files:\n    if not init_file.exists():\n        init_file.touch()\n        print(f\"ğŸ”§ åˆ›å»º {init_file.relative_to(PROJECT_ROOT)}\")\n\nprint(\"ğŸ‰ Pythonç¯å¢ƒé…ç½®å®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¡¬ä»¶èµ„æºæ£€æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import gc\n",
    "\n",
    "print(\"\\nğŸ–¥ï¸ ç³»ç»Ÿèµ„æºæ£€æµ‹:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# CPUä¿¡æ¯\n",
    "cpu_count = psutil.cpu_count()\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "print(f\"CPUæ ¸å¿ƒæ•°: {cpu_count}\")\n",
    "if cpu_freq:\n",
    "    print(f\"CPUé¢‘ç‡: {cpu_freq.current:.2f} MHz\")\n",
    "\n",
    "# å†…å­˜ä¿¡æ¯\n",
    "memory = psutil.virtual_memory()\n",
    "memory_gb = memory.total / (1024**3)\n",
    "memory_available_gb = memory.available / (1024**3)\n",
    "print(f\"æ€»å†…å­˜: {memory_gb:.1f} GB\")\n",
    "print(f\"å¯ç”¨å†…å­˜: {memory_available_gb:.1f} GB\")\n",
    "print(f\"å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%\")\n",
    "\n",
    "# ç£ç›˜ä¿¡æ¯\n",
    "disk = psutil.disk_usage('/')\n",
    "disk_total_gb = disk.total / (1024**3)\n",
    "disk_free_gb = disk.free / (1024**3)\n",
    "print(f\"ç£ç›˜æ€»å®¹é‡: {disk_total_gb:.1f} GB\")\n",
    "print(f\"ç£ç›˜å¯ç”¨: {disk_free_gb:.1f} GB\")\n",
    "\n",
    "# èµ„æºå……è¶³æ€§è¯„ä¼°\n",
    "print(\"\\nğŸ“Š èµ„æºè¯„ä¼°:\")\n",
    "if memory_gb >= 32:\n",
    "    print(\"âœ… å†…å­˜å……è¶³ (>=32GB)\")\n",
    "elif memory_gb >= 16:\n",
    "    print(\"âš ï¸ å†…å­˜å¯ç”¨ä½†å¯èƒ½ä¸è¶³ (16-32GB)\")\n",
    "else:\n",
    "    print(\"âŒ å†…å­˜ä¸è¶³ (<16GB)\")\n",
    "\n",
    "if disk_free_gb >= 50:\n",
    "    print(\"âœ… ç£ç›˜ç©ºé—´å……è¶³ (>=50GB)\")\n",
    "elif disk_free_gb >= 20:\n",
    "    print(\"âš ï¸ ç£ç›˜ç©ºé—´ç´§å¼  (20-50GB)\")\n",
    "else:\n",
    "    print(\"âŒ ç£ç›˜ç©ºé—´ä¸è¶³ (<20GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUæ£€æµ‹\n",
    "print(\"\\nğŸ® GPUæ£€æµ‹:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"âœ… CUDAå¯ç”¨ï¼Œå‘ç° {gpu_count} ä¸ªGPU\")\n",
    "        print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        \n",
    "        for i in range(gpu_count):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            total_memory = props.total_memory / (1024**3)\n",
    "            allocated_memory = torch.cuda.memory_allocated(i) / (1024**3)\n",
    "            cached_memory = torch.cuda.memory_reserved(i) / (1024**3)\n",
    "            free_memory = total_memory - allocated_memory\n",
    "            \n",
    "            print(f\"\\nGPU {i}: {props.name}\")\n",
    "            print(f\"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}\")\n",
    "            print(f\"  æ€»æ˜¾å­˜: {total_memory:.1f} GB\")\n",
    "            print(f\"  å·²åˆ†é…: {allocated_memory:.2f} GB\")\n",
    "            print(f\"  å·²ç¼“å­˜: {cached_memory:.2f} GB\")\n",
    "            print(f\"  å¯ç”¨æ˜¾å­˜: {free_memory:.1f} GB\")\n",
    "            \n",
    "            # GPUè¯„ä¼°\n",
    "            if total_memory >= 80:\n",
    "                gpu_status = \"âœ… 80GB GPU - ä¼˜ç§€é…ç½®\"\n",
    "            elif total_memory >= 40:\n",
    "                gpu_status = \"âœ… 40GB GPU - æ¨èé…ç½®\"\n",
    "            elif total_memory >= 24:\n",
    "                gpu_status = \"âš ï¸ 24GB GPU - å¯ç”¨ä½†å—é™\"\n",
    "            elif total_memory >= 12:\n",
    "                gpu_status = \"âš ï¸ 12GB GPU - ä»…æ”¯æŒå°æ¨¡å‹\"\n",
    "            else:\n",
    "                gpu_status = \"âŒ <12GB GPU - ä¸å»ºè®®ä½¿ç”¨\"\n",
    "            \n",
    "            print(f\"  çŠ¶æ€: {gpu_status}\")\n",
    "    else:\n",
    "        print(\"âŒ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼\")\n",
    "        print(\"âš ï¸ è­¦å‘Š: CPUæ¨¡å¼ä¸‹æ€§èƒ½å°†æ˜¾è‘—é™ä½\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä¾èµ–åº“æ£€æµ‹å’Œå®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“¦ å…³é”®ä¾èµ–åº“æ£€æµ‹:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# æ ¸å¿ƒä¾èµ–åº“åˆ—è¡¨\n",
    "core_dependencies = {\n",
    "    'torch': '>=1.12.0',\n",
    "    'transformers': '>=4.20.0',\n",
    "    'diffusers': '>=0.20.0',\n",
    "    'numpy': '>=1.21.0',\n",
    "    'scipy': '>=1.8.0',\n",
    "    'librosa': '>=0.9.0',\n",
    "    'opencv-python': '>=4.5.0',\n",
    "    'pillow': '>=8.0.0',\n",
    "    'matplotlib': '>=3.5.0',\n",
    "    'seaborn': '>=0.11.0',\n",
    "    'plotly': '>=5.0.0',\n",
    "    'ipywidgets': '>=7.6.0',\n",
    "    'tqdm': '>=4.60.0',\n",
    "    'pyyaml': '>=5.4.0',\n",
    "    'psutil': '>=5.8.0'\n",
    "}\n",
    "\n",
    "missing_packages = []\n",
    "installed_packages = {}\n",
    "\n",
    "for package, min_version in core_dependencies.items():\n",
    "    try:\n",
    "        if package == 'opencv-python':\n",
    "            import cv2\n",
    "            version = cv2.__version__\n",
    "            package_name = 'cv2'\n",
    "        else:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'unknown')\n",
    "            package_name = package\n",
    "        \n",
    "        installed_packages[package] = version\n",
    "        print(f\"âœ… {package_name}: {version}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "        print(f\"âŒ {package}: æœªå®‰è£…\")\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸ ç¼ºå¤±ä¾èµ–åº“: {', '.join(missing_packages)}\")\n",
    "    print(\"è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:\")\n",
    "    print(f\"pip install {' '.join(missing_packages)}\")\n",
    "else:\n",
    "    print(\"\\nâœ… æ‰€æœ‰æ ¸å¿ƒä¾èµ–åº“å·²å®‰è£…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯é€‰ä¾èµ–åº“æ£€æµ‹ (ç”¨äºç‰¹å®šåŠŸèƒ½)\n",
    "print(\"\\nğŸ“¦ å¯é€‰ä¾èµ–åº“æ£€æµ‹:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "optional_dependencies = {\n",
    "    'audiocraft': 'MusicGenéŸ³ä¹ç”Ÿæˆ',\n",
    "    'accelerate': 'Hugging Faceæ¨¡å‹åŠ é€Ÿ',\n",
    "    'xformers': 'å†…å­˜ä¼˜åŒ– (æ¨è)',\n",
    "    'pynvml': 'GPUç›‘æ§',\n",
    "    'wandb': 'å®éªŒè·Ÿè¸ª (å¯é€‰)',\n",
    "    'tensorboard': 'TensorBoardæ—¥å¿—',\n",
    "    'jupyter_contrib_nbextensions': 'Jupyteræ‰©å±•',\n",
    "    'ipywidgets': 'Jupyteräº¤äº’ç»„ä»¶'\n",
    "}\n",
    "\n",
    "for package, description in optional_dependencies.items():\n",
    "    try:\n",
    "        module = __import__(package)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"âœ… {package}: {version} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"âšª {package}: æœªå®‰è£… - {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç³»ç»Ÿé…ç½®åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš™ï¸ ç³»ç»Ÿé…ç½®åˆå§‹åŒ–:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„\n",
    "output_dirs = [\n",
    "    'outputs',\n",
    "    'outputs/audio',\n",
    "    'outputs/video', \n",
    "    'outputs/logs',\n",
    "    'outputs/models',\n",
    "    'outputs/reports',\n",
    "    'outputs/cache'\n",
    "]\n",
    "\n",
    "for dir_name in output_dirs:\n",
    "    dir_path = PROJECT_ROOT / dir_name\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… åˆ›å»ºç›®å½•: {dir_path}\")\n",
    "\n",
    "# è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "cache_dir = PROJECT_ROOT / 'outputs' / 'cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = str(cache_dir / 'transformers')\n",
    "os.environ['HF_HOME'] = str(cache_dir / 'huggingface')\n",
    "print(f\"âœ… è®¾ç½®ç¼“å­˜ç›®å½•: {cache_dir}\")\n",
    "\n",
    "# åˆ›å»ºç³»ç»Ÿé…ç½®\n",
    "system_config = {\n",
    "    'project_root': str(PROJECT_ROOT),\n",
    "    'python_version': sys.version,\n",
    "    'platform': platform.platform(),\n",
    "    'initialization_time': datetime.now().isoformat(),\n",
    "    'gpu_available': torch.cuda.is_available() if 'torch' in locals() else False,\n",
    "    'gpu_count': torch.cuda.device_count() if 'torch' in locals() and torch.cuda.is_available() else 0,\n",
    "    'total_memory_gb': memory_gb,\n",
    "    'available_memory_gb': memory_available_gb,\n",
    "    'installed_packages': installed_packages,\n",
    "    'output_directories': [str(PROJECT_ROOT / d) for d in output_dirs]\n",
    "}\n",
    "\n",
    "# ä¿å­˜é…ç½®æ–‡ä»¶\n",
    "config_file = PROJECT_ROOT / 'outputs' / 'system_config.json'\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(system_config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… ç³»ç»Ÿé…ç½®å·²ä¿å­˜: {config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. åŸºç¡€åŠŸèƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nğŸ§ª åŸºç¡€åŠŸèƒ½æµ‹è¯•:\")\nprint(\"-\" * 40)\n\n# æµ‹è¯•ç†è®ºæ¨¡å—å¯¼å…¥ - æ›´å®‰å…¨çš„å¯¼å…¥æ–¹å¼\ntheory_modules_ok = False\ntry:\n    # å°è¯•å¯¼å…¥ç†è®ºæ¨¡å—\n    try:\n        from research.theory.iso_principle import ISOPrinciple, EmotionState\n        from research.theory.valence_arousal import ValenceArousalModel  \n        from research.theory.sleep_physiology import SleepPhysiologyModel\n        from research.theory.music_psychology import MusicPsychologyModel\n        print(\"âœ… ç†è®ºæ¨¡å—å¯¼å…¥æˆåŠŸ\")\n        \n        # å¿«é€ŸåŠŸèƒ½æµ‹è¯•\n        emotion_state = EmotionState(valence=-0.2, arousal=0.6, confidence=0.8)\n        iso_planner = ISOPrinciple()\n        va_model = ValenceArousalModel()\n        \n        print(f\"âœ… æƒ…ç»ªçŠ¶æ€åˆ›å»º: V={emotion_state.valence}, A={emotion_state.arousal}\")\n        print(\"âœ… ç†è®ºæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ\")\n        theory_modules_ok = True\n        \n    except ImportError as e:\n        # å¦‚æœç†è®ºæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºMockç‰ˆæœ¬\n        print(f\"âš ï¸  ç†è®ºæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n        print(\"ğŸ”§ åˆ›å»ºMockç†è®ºæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n        \n        # åˆ›å»ºä¸´æ—¶ç†è®ºæ¨¡å—ç›®å½•ç»“æ„\n        theory_dir = PROJECT_ROOT / 'research' / 'theory'\n        theory_dir.mkdir(parents=True, exist_ok=True)\n        \n        # åˆ›å»ºç®€åŒ–çš„ç†è®ºæ¨¡å—æ–‡ä»¶\n        mock_files = {\n            'iso_principle.py': '''\n\"\"\"ISOä¸‰é˜¶æ®µæ²»ç–—åŸåˆ™ - Mockç‰ˆæœ¬\"\"\"\nfrom dataclasses import dataclass\nfrom typing import Dict, List\nimport numpy as np\n\n@dataclass\nclass EmotionState:\n    valence: float  # -1åˆ°1ï¼Œè´Ÿå€¼è¡¨ç¤ºæ¶ˆææƒ…ç»ª\n    arousal: float  # 0åˆ°1ï¼Œè¡¨ç¤ºå”¤é†’ç¨‹åº¦\n    confidence: float = 0.8  # ç½®ä¿¡åº¦\n\nclass ISOPrinciple:\n    \"\"\"ISOä¸‰é˜¶æ®µæ²»ç–—åŸåˆ™\"\"\"\n    \n    def __init__(self):\n        self.stages = ['synchronization', 'guidance', 'consolidation']\n    \n    def plan_therapy_stages(self, current_emotion: EmotionState, target_emotion: EmotionState) -> List[Dict]:\n        \"\"\"è§„åˆ’æ²»ç–—é˜¶æ®µ\"\"\"\n        return [\n            {'stage': 'synchronization', 'duration': 30, 'target_valence': current_emotion.valence},\n            {'stage': 'guidance', 'duration': 60, 'target_valence': (current_emotion.valence + target_emotion.valence) / 2},\n            {'stage': 'consolidation', 'duration': 30, 'target_valence': target_emotion.valence}\n        ]\n''',\n            'valence_arousal.py': '''\n\"\"\"æƒ…ç»ªä»·å€¼-å”¤é†’æ¨¡å‹ - Mockç‰ˆæœ¬\"\"\"\nimport numpy as np\nfrom typing import Tuple\n\nclass ValenceArousalModel:\n    \"\"\"æƒ…ç»ªä»·å€¼-å”¤é†’äºŒç»´æ¨¡å‹\"\"\"\n    \n    def __init__(self):\n        self.emotion_map = {\n            'happy': (0.8, 0.7),\n            'calm': (0.5, 0.2),\n            'sad': (-0.6, 0.3),\n            'angry': (-0.3, 0.8),\n            'anxious': (-0.4, 0.9),\n            'peaceful': (0.7, 0.1)\n        }\n    \n    def get_emotion_coordinates(self, emotion: str) -> Tuple[float, float]:\n        \"\"\"è·å–æƒ…ç»ªåœ¨VAç©ºé—´ä¸­çš„åæ ‡\"\"\"\n        return self.emotion_map.get(emotion, (0.0, 0.5))\n    \n    def calculate_emotion_distance(self, emotion1: Tuple[float, float], emotion2: Tuple[float, float]) -> float:\n        \"\"\"è®¡ç®—ä¸¤ä¸ªæƒ…ç»ªçŠ¶æ€çš„è·ç¦»\"\"\"\n        return np.sqrt((emotion1[0] - emotion2[0])**2 + (emotion1[1] - emotion2[1])**2)\n''',\n            'sleep_physiology.py': '''\n\"\"\"ç¡çœ ç”Ÿç†å­¦æ¨¡å‹ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Dict, List\n\nclass SleepPhysiologyModel:\n    \"\"\"ç¡çœ ç”Ÿç†å­¦æ¨¡å‹\"\"\"\n    \n    def __init__(self):\n        self.sleep_stages = ['wake', 'n1', 'n2', 'n3', 'rem']\n        self.brainwave_frequencies = {\n            'delta': (0.5, 4),    # æ·±ç¡çœ \n            'theta': (4, 8),      # æµ…ç¡çœ ã€REM\n            'alpha': (8, 13),     # æ”¾æ¾çŠ¶æ€\n            'beta': (13, 30),     # æ¸…é†’çŠ¶æ€\n            'gamma': (30, 100)    # é«˜åº¦é›†ä¸­\n        }\n    \n    def get_optimal_frequency_for_sleep(self, target_stage: str) -> Dict:\n        \"\"\"è·å–æœ€é€‚åˆç¡çœ é˜¶æ®µçš„è„‘æ³¢é¢‘ç‡\"\"\"\n        if target_stage in ['n2', 'n3']:\n            return {'primary': 'delta', 'secondary': 'theta', 'range': (0.5, 8)}\n        elif target_stage == 'n1':\n            return {'primary': 'theta', 'secondary': 'alpha', 'range': (4, 13)}\n        else:\n            return {'primary': 'alpha', 'secondary': 'theta', 'range': (4, 13)}\n''',\n            'music_psychology.py': '''\n\"\"\"éŸ³ä¹å¿ƒç†å­¦æ¨¡å‹ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Dict, List, Tuple\n\nclass MusicPsychologyModel:\n    \"\"\"éŸ³ä¹å¿ƒç†å­¦æ¨¡å‹\"\"\"\n    \n    def __init__(self):\n        self.tempo_emotion_map = {\n            'very_slow': (40, 60, 'peaceful'),\n            'slow': (60, 80, 'calm'),\n            'moderate': (80, 120, 'neutral'),\n            'fast': (120, 160, 'energetic'),\n            'very_fast': (160, 200, 'exciting')\n        }\n        \n        self.key_emotion_map = {\n            'major': 'positive',\n            'minor': 'melancholic',\n            'dorian': 'contemplative',\n            'phrygian': 'mysterious'\n        }\n    \n    def recommend_musical_parameters(self, target_emotion: Tuple[float, float]) -> Dict:\n        \"\"\"æ ¹æ®ç›®æ ‡æƒ…ç»ªæ¨èéŸ³ä¹å‚æ•°\"\"\"\n        valence, arousal = target_emotion\n        \n        # æ ¹æ®å”¤é†’åº¦é€‰æ‹©èŠ‚æ‹\n        if arousal < 0.3:\n            tempo_range = (40, 70)\n            tempo_desc = 'very_slow'\n        elif arousal < 0.6:\n            tempo_range = (60, 90)\n            tempo_desc = 'slow'\n        else:\n            tempo_range = (80, 120)\n            tempo_desc = 'moderate'\n        \n        # æ ¹æ®æ•ˆä»·é€‰æ‹©è°ƒå¼\n        key_type = 'major' if valence > 0 else 'minor'\n        \n        return {\n            'tempo_bpm': tempo_range,\n            'tempo_description': tempo_desc,\n            'key_type': key_type,\n            'recommended_instruments': ['piano', 'strings', 'ambient'],\n            'dynamics': 'soft' if arousal < 0.5 else 'moderate'\n        }\n'''\n        }\n        \n        # å†™å…¥Mockæ–‡ä»¶\n        for filename, content in mock_files.items():\n            file_path = theory_dir / filename\n            if not file_path.exists():\n                with open(file_path, 'w', encoding='utf-8') as f:\n                    f.write(content)\n                print(f\"ğŸ”§ åˆ›å»º {filename}\")\n        \n        # åˆ›å»º__init__.py\n        init_file = theory_dir / '__init__.py'\n        if not init_file.exists():\n            init_file.touch()\n            print(\"ğŸ”§ åˆ›å»º __init__.py\")\n        \n        # é‡æ–°å°è¯•å¯¼å…¥\n        try:\n            # é‡æ–°åŠ è½½æ¨¡å—\n            import importlib\n            import sys\n            \n            # æ¸…ç†å¯èƒ½çš„ç¼“å­˜\n            modules_to_clear = [name for name in sys.modules.keys() if name.startswith('research.theory')]\n            for module_name in modules_to_clear:\n                del sys.modules[module_name]\n            \n            from research.theory.iso_principle import ISOPrinciple, EmotionState\n            from research.theory.valence_arousal import ValenceArousalModel\n            from research.theory.sleep_physiology import SleepPhysiologyModel\n            from research.theory.music_psychology import MusicPsychologyModel\n            \n            # æµ‹è¯•åŠŸèƒ½\n            emotion_state = EmotionState(valence=-0.2, arousal=0.6, confidence=0.8)\n            iso_planner = ISOPrinciple()\n            va_model = ValenceArousalModel()\n            \n            print(f\"âœ… Mockç†è®ºæ¨¡å—åˆ›å»ºå¹¶æµ‹è¯•æˆåŠŸ\")\n            print(f\"âœ… æƒ…ç»ªçŠ¶æ€: V={emotion_state.valence}, A={emotion_state.arousal}\")\n            theory_modules_ok = True\n            \n        except Exception as e2:\n            print(f\"âŒ Mockç†è®ºæ¨¡å—åˆ›å»ºå¤±è´¥: {e2}\")\n            theory_modules_ok = False\n        \nexcept Exception as e:\n    print(f\"âŒ ç†è®ºæ¨¡å—ä¸¥é‡é”™è¯¯: {e}\")\n    theory_modules_ok = False\n\nif not theory_modules_ok:\n    print(\"ğŸ’¡ æç¤º: ç†è®ºæ¨¡å—æµ‹è¯•å¤±è´¥ï¼Œä½†ç³»ç»Ÿä»å¯ç»§ç»­è¿è¡Œ\")\n    print(\"ğŸ“ å¯ä»¥æ‰‹åŠ¨æ£€æŸ¥ research/theory/ ç›®å½•ä¸­çš„æ–‡ä»¶\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# æµ‹è¯•æ¨¡å‹é€‚é…å™¨å¯¼å…¥ - å®‰å…¨å¯¼å…¥æ–¹å¼\nprint(\"\\nğŸ¤– æ¨¡å‹é€‚é…å™¨æµ‹è¯•:\")\nprint(\"-\" * 30)\n\nmodel_adapters_ok = False\ntry:\n    # å°è¯•å¯¼å…¥ç°æœ‰çš„æ¨¡å‹é€‚é…å™¨\n    try:\n        from src.models.base import BaseModelAdapter, ModelConfig, HardwareConfig\n        from src.models.registry import ModelRegistry  \n        from src.models.factory import ModelFactory\n        print(\"âœ… ç°æœ‰æ¨¡å‹é€‚é…å™¨å¯¼å…¥æˆåŠŸ\")\n        model_adapters_ok = True\n        \n    except ImportError as e:\n        print(f\"âš ï¸  ç°æœ‰æ¨¡å‹é€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}\")\n        print(\"ğŸ”§ åˆ›å»ºMockæ¨¡å‹é€‚é…å™¨...\")\n        \n        # åˆ›å»ºæ¨¡å‹é€‚é…å™¨ç›®å½•\n        models_dir = PROJECT_ROOT / 'src' / 'models'\n        models_dir.mkdir(parents=True, exist_ok=True)\n        \n        # åˆ›å»ºMockæ¨¡å‹é€‚é…å™¨æ–‡ä»¶\n        mock_model_files = {\n            'base.py': '''\n\"\"\"åŸºç¡€æ¨¡å‹é€‚é…å™¨ - Mockç‰ˆæœ¬\"\"\"\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, Optional\nimport torch\n\n@dataclass\nclass ModelConfig:\n    model_name: str\n    model_type: str\n    device: str = \"cpu\"\n    precision: str = \"float32\"\n    max_memory: Optional[str] = None\n\n@dataclass \nclass HardwareConfig:\n    device: str\n    gpu_memory_gb: float\n    cpu_cores: int\n    total_memory_gb: float\n\nclass BaseModelAdapter:\n    \"\"\"åŸºç¡€æ¨¡å‹é€‚é…å™¨\"\"\"\n    \n    def __init__(self, config: ModelConfig):\n        self.config = config\n        self.model = None\n        self.is_loaded = False\n    \n    def load_model(self):\n        \"\"\"åŠ è½½æ¨¡å‹ (Mock)\"\"\"\n        print(f\"ğŸ”„ MockåŠ è½½æ¨¡å‹: {self.config.model_name}\")\n        self.is_loaded = True\n        return True\n    \n    def unload_model(self):\n        \"\"\"å¸è½½æ¨¡å‹\"\"\"\n        if self.is_loaded:\n            self.model = None\n            self.is_loaded = False\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            print(f\"ğŸ—‘ï¸  æ¨¡å‹å·²å¸è½½: {self.config.model_name}\")\n    \n    def predict(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"æ¨¡å‹é¢„æµ‹ (Mock)\"\"\"\n        return {\"status\": \"mock_prediction\", \"confidence\": 0.85}\n''',\n            'registry.py': '''\n\"\"\"æ¨¡å‹æ³¨å†Œè¡¨ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Dict, List\nfrom .base import ModelConfig\n\nclass ModelRegistry:\n    \"\"\"æ¨¡å‹æ³¨å†Œè¡¨\"\"\"\n    \n    def __init__(self):\n        self.registered_models = {\n            'emotion_text': ModelConfig(\n                model_name='cardiffnlp/twitter-roberta-base-emotion',\n                model_type='text_emotion'\n            ),\n            'emotion_audio': ModelConfig(\n                model_name='facebook/wav2vec2-base-960h',\n                model_type='audio_emotion'  \n            ),\n            'music_generation': ModelConfig(\n                model_name='facebook/musicgen-small',\n                model_type='audio_generation'\n            ),\n            'video_generation': ModelConfig(\n                model_name='tencent/hunyuan-video',\n                model_type='video_generation'\n            )\n        }\n    \n    def get_model_config(self, model_name: str) -> ModelConfig:\n        \"\"\"è·å–æ¨¡å‹é…ç½®\"\"\"\n        return self.registered_models.get(model_name)\n    \n    def list_models(self) -> List[str]:\n        \"\"\"åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„æ¨¡å‹\"\"\"\n        return list(self.registered_models.keys())\n    \n    def get_models_by_type(self, model_type: str) -> List[str]:\n        \"\"\"æŒ‰ç±»å‹è·å–æ¨¡å‹\"\"\"\n        return [name for name, config in self.registered_models.items() \n                if config.model_type == model_type]\n''',\n            'factory.py': '''\n\"\"\"æ¨¡å‹å·¥å‚ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Optional\nfrom .base import BaseModelAdapter, ModelConfig, HardwareConfig\nfrom .registry import ModelRegistry\nimport torch\n\nclass ModelFactory:\n    \"\"\"æ¨¡å‹å·¥å‚\"\"\"\n    \n    def __init__(self):\n        self.registry = ModelRegistry()\n        self.hardware_config = self._detect_hardware()\n    \n    def _detect_hardware(self) -> HardwareConfig:\n        \"\"\"æ£€æµ‹ç¡¬ä»¶é…ç½®\"\"\"\n        if torch.cuda.is_available():\n            device = \"cuda\"\n            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n        else:\n            device = \"cpu\"\n            gpu_memory = 0.0\n        \n        return HardwareConfig(\n            device=device,\n            gpu_memory_gb=gpu_memory,\n            cpu_cores=torch.get_num_threads(),\n            total_memory_gb=16.0  # Mockå€¼\n        )\n    \n    def create_model_adapter(self, model_name: str, **kwargs) -> BaseModelAdapter:\n        \"\"\"åˆ›å»ºæ¨¡å‹é€‚é…å™¨\"\"\"\n        config = self.registry.get_model_config(model_name)\n        if not config:\n            raise ValueError(f\"Unknown model: {model_name}\")\n        \n        # æ ¹æ®ç¡¬ä»¶ä¼˜åŒ–é…ç½®\n        config.device = self.hardware_config.device\n        if self.hardware_config.gpu_memory_gb > 40:\n            config.precision = \"float16\"\n        else:\n            config.precision = \"float32\"\n        \n        return BaseModelAdapter(config)\n    \n    def get_recommended_models(self) -> Dict[str, str]:\n        \"\"\"è·å–æ¨èæ¨¡å‹é…ç½®\"\"\"\n        gpu_memory = self.hardware_config.gpu_memory_gb\n        \n        if gpu_memory >= 80:\n            profile = \"gpu_80gb\"\n        elif gpu_memory >= 40:\n            profile = \"gpu_40gb\"\n        elif gpu_memory >= 12:\n            profile = \"gpu_12gb\"\n        else:\n            profile = \"cpu_only\"\n        \n        return {\n            \"profile\": profile,\n            \"recommended\": {\n                \"emotion_text\": \"cardiffnlp/twitter-roberta-base-emotion\",\n                \"emotion_audio\": \"facebook/wav2vec2-base-960h\",\n                \"music_gen\": \"facebook/musicgen-small\" if profile != \"cpu_only\" else \"mock\",\n                \"video_gen\": \"mock\"  # æ€»æ˜¯ä½¿ç”¨mock\n            }\n        }\n'''\n        }\n        \n        # å†™å…¥Mockæ–‡ä»¶\n        for filename, content in mock_model_files.items():\n            file_path = models_dir / filename\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n            print(f\"ğŸ”§ åˆ›å»º {filename}\")\n        \n        # åˆ›å»º__init__.py\n        init_file = models_dir / '__init__.py'\n        with open(init_file, 'w', encoding='utf-8') as f:\n            f.write('\"\"\"æ¨¡å‹é€‚é…å™¨æ¨¡å—\"\"\"\\n')\n        \n        # é‡æ–°å¯¼å…¥\n        try:\n            import importlib\n            import sys\n            \n            # æ¸…ç†ç¼“å­˜\n            modules_to_clear = [name for name in sys.modules.keys() if name.startswith('src.models')]\n            for module_name in modules_to_clear:\n                del sys.modules[module_name]\n            \n            from src.models.base import BaseModelAdapter, ModelConfig, HardwareConfig\n            from src.models.registry import ModelRegistry\n            from src.models.factory import ModelFactory\n            \n            print(\"âœ… Mockæ¨¡å‹é€‚é…å™¨åˆ›å»ºå¹¶å¯¼å…¥æˆåŠŸ\")\n            model_adapters_ok = True\n            \n        except Exception as e2:\n            print(f\"âŒ Mockæ¨¡å‹é€‚é…å™¨åˆ›å»ºå¤±è´¥: {e2}\")\n    \n    # æµ‹è¯•æ¨¡å‹å·¥å‚åŠŸèƒ½\n    if model_adapters_ok:\n        try:\n            factory = ModelFactory()\n            recommendations = factory.get_recommended_models()\n            \n            print(f\"âœ… æ¨¡å‹å·¥å‚åˆå§‹åŒ–æˆåŠŸ\")\n            print(f\"ğŸ¯ ç¡¬ä»¶é…ç½®: {recommendations['profile']}\")\n            print(f\"ğŸ“ æ¨èæ¨¡å‹: {len(recommendations['recommended'])}ä¸ª\")\n            \n            # åˆ›å»ºç¡¬ä»¶é…ç½®\n            if torch.cuda.is_available():\n                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n                hardware_profile = recommendations['profile']\n                print(f\"ğŸ® GPUä¿¡æ¯: {gpu_memory:.1f}GB - {hardware_profile}\")\n            else:\n                print(\"ğŸ’» CPUæ¨¡å¼é…ç½®\")\n                \n        except Exception as e:\n            print(f\"âš ï¸  æ¨¡å‹å·¥å‚æµ‹è¯•è­¦å‘Š: {e}\")\n            \nexcept Exception as e:\n    print(f\"âŒ æ¨¡å‹é€‚é…å™¨ä¸¥é‡é”™è¯¯: {e}\")\n    model_adapters_ok = False\n\nif not model_adapters_ok:\n    print(\"ğŸ’¡ æç¤º: æ¨¡å‹é€‚é…å™¨æµ‹è¯•å¤±è´¥ï¼Œä½†ç³»ç»Ÿä»å¯ç»§ç»­è¿è¡Œ\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# æµ‹è¯•ç–—æ„ˆç³»ç»Ÿå¯¼å…¥ - å®‰å…¨å¯¼å…¥æ–¹å¼\nprint(\"\\nğŸ§˜ ç–—æ„ˆç³»ç»Ÿæµ‹è¯•:\")\nprint(\"-\" * 30)\n\ntherapy_system_ok = False\ntry:\n    # å°è¯•å¯¼å…¥ç°æœ‰çš„ç–—æ„ˆç³»ç»Ÿ\n    try:\n        from src.therapy.core import TherapyOrchestrator, TherapySession, EmotionTrajectoryPlanner\n        from src.therapy.stages import ISOStageManager\n        from src.therapy.prescriptions import PrescriptionEngine\n        print(\"âœ… ç°æœ‰ç–—æ„ˆç³»ç»Ÿå¯¼å…¥æˆåŠŸ\")\n        therapy_system_ok = True\n        \n    except ImportError as e:\n        print(f\"âš ï¸  ç°æœ‰ç–—æ„ˆç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}\")\n        print(\"ğŸ”§ åˆ›å»ºMockç–—æ„ˆç³»ç»Ÿ...\")\n        \n        # åˆ›å»ºç–—æ„ˆç³»ç»Ÿç›®å½•\n        therapy_dir = PROJECT_ROOT / 'src' / 'therapy'\n        therapy_dir.mkdir(parents=True, exist_ok=True)\n        \n        # åˆ›å»ºMockç–—æ„ˆç³»ç»Ÿæ–‡ä»¶\n        mock_therapy_files = {\n            'core.py': '''\n\"\"\"ç–—æ„ˆç³»ç»Ÿæ ¸å¿ƒ - Mockç‰ˆæœ¬\"\"\"\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass TherapySession:\n    session_id: str\n    user_id: str\n    start_time: datetime\n    current_emotion: Dict\n    target_emotion: Dict\n    status: str = \"active\"\n\nclass EmotionTrajectoryPlanner:\n    \"\"\"æƒ…ç»ªè½¨è¿¹è§„åˆ’å™¨\"\"\"\n    \n    def __init__(self):\n        self.planning_strategies = [\"linear\", \"curved\", \"staged\"]\n    \n    def plan_trajectory(self, current_emotion: Dict, target_emotion: Dict, duration_minutes: int = 30) -> List[Dict]:\n        \"\"\"è§„åˆ’æƒ…ç»ªè½¬æ¢è½¨è¿¹\"\"\"\n        steps = max(3, duration_minutes // 10)\n        trajectory = []\n        \n        for i in range(steps):\n            progress = (i + 1) / steps\n            interpolated_valence = current_emotion[\"valence\"] + (target_emotion[\"valence\"] - current_emotion[\"valence\"]) * progress\n            interpolated_arousal = current_emotion[\"arousal\"] + (target_emotion[\"arousal\"] - current_emotion[\"arousal\"]) * progress\n            \n            trajectory.append({\n                \"step\": i + 1,\n                \"timestamp\": i * (duration_minutes // steps),\n                \"valence\": interpolated_valence,\n                \"arousal\": interpolated_arousal,\n                \"confidence\": 0.8\n            })\n        \n        return trajectory\n\nclass TherapyOrchestrator:\n    \"\"\"ç–—æ„ˆç¼–æ’å™¨\"\"\"\n    \n    def __init__(self):\n        self.active_sessions = {}\n        self.trajectory_planner = EmotionTrajectoryPlanner()\n        self.session_history = []\n    \n    def create_session(self, user_id: str, current_emotion: Dict, target_emotion: Dict) -> TherapySession:\n        \"\"\"åˆ›å»ºæ–°çš„ç–—æ„ˆä¼šè¯\"\"\"\n        session_id = str(uuid.uuid4())[:8]\n        \n        session = TherapySession(\n            session_id=session_id,\n            user_id=user_id,\n            start_time=datetime.now(),\n            current_emotion=current_emotion,\n            target_emotion=target_emotion\n        )\n        \n        self.active_sessions[session_id] = session\n        print(f\"ğŸ¯ åˆ›å»ºç–—æ„ˆä¼šè¯: {session_id}\")\n        return session\n    \n    def get_session_recommendations(self, session_id: str) -> Dict:\n        \"\"\"è·å–ä¼šè¯æ¨è\"\"\"\n        if session_id not in self.active_sessions:\n            return {\"error\": \"Session not found\"}\n        \n        session = self.active_sessions[session_id]\n        trajectory = self.trajectory_planner.plan_trajectory(\n            session.current_emotion, \n            session.target_emotion\n        )\n        \n        return {\n            \"session_id\": session_id,\n            \"trajectory\": trajectory,\n            \"recommendations\": {\n                \"music_style\": \"ambient\",\n                \"tempo_bpm\": 60,\n                \"video_theme\": \"nature\",\n                \"duration_minutes\": 30\n            }\n        }\n''',\n            'stages.py': '''\n\"\"\"ISOé˜¶æ®µç®¡ç†å™¨ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Dict, List\nfrom enum import Enum\n\nclass ISOStage(Enum):\n    SYNCHRONIZATION = \"synchronization\"\n    GUIDANCE = \"guidance\"\n    CONSOLIDATION = \"consolidation\"\n\nclass ISOStageManager:\n    \"\"\"ISOä¸‰é˜¶æ®µç®¡ç†å™¨\"\"\"\n    \n    def __init__(self):\n        self.current_stage = None\n        self.stage_history = []\n        \n        # é˜¶æ®µé…ç½®\n        self.stage_configs = {\n            ISOStage.SYNCHRONIZATION: {\n                \"duration_ratio\": 0.25,\n                \"description\": \"ä¸ç”¨æˆ·å½“å‰æƒ…ç»ªåŒæ­¥\",\n                \"music_strategy\": \"match_current_emotion\",\n                \"intensity\": \"low\"\n            },\n            ISOStage.GUIDANCE: {\n                \"duration_ratio\": 0.50,\n                \"description\": \"å¼•å¯¼æƒ…ç»ªå‘ç›®æ ‡è½¬æ¢\",\n                \"music_strategy\": \"gradual_transition\",\n                \"intensity\": \"medium\"\n            },\n            ISOStage.CONSOLIDATION: {\n                \"duration_ratio\": 0.25,\n                \"description\": \"å·©å›ºç›®æ ‡æƒ…ç»ªçŠ¶æ€\",\n                \"music_strategy\": \"stabilize_target\",\n                \"intensity\": \"low\"\n            }\n        }\n    \n    def plan_stages(self, total_duration: int, current_emotion: Dict, target_emotion: Dict) -> List[Dict]:\n        \"\"\"è§„åˆ’ISOä¸‰é˜¶æ®µ\"\"\"\n        stages = []\n        \n        for stage in ISOStage:\n            config = self.stage_configs[stage]\n            duration = int(total_duration * config[\"duration_ratio\"])\n            \n            stages.append({\n                \"stage\": stage.value,\n                \"duration_minutes\": duration,\n                \"description\": config[\"description\"],\n                \"music_strategy\": config[\"music_strategy\"],\n                \"intensity\": config[\"intensity\"]\n            })\n        \n        return stages\n    \n    def get_current_stage_config(self) -> Dict:\n        \"\"\"è·å–å½“å‰é˜¶æ®µé…ç½®\"\"\"\n        if self.current_stage:\n            return self.stage_configs[self.current_stage]\n        return {}\n''',\n            'prescriptions.py': '''\n\"\"\"å¤„æ–¹å¼•æ“ - Mockç‰ˆæœ¬\"\"\"\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass TherapyPrescription:\n    prescription_id: str\n    user_profile: Dict\n    current_emotion: Dict\n    target_emotion: Dict\n    recommendations: Dict\n    confidence_score: float\n\nclass PrescriptionEngine:\n    \"\"\"å¤„æ–¹å¼•æ“\"\"\"\n    \n    def __init__(self):\n        self.prescription_templates = {\n            \"anxiety_to_calm\": {\n                \"music_genre\": \"ambient\",\n                \"tempo_range\": (40, 70),\n                \"key_preference\": \"major\",\n                \"video_theme\": \"nature\",\n                \"duration\": 25\n            },\n            \"sadness_to_comfort\": {\n                \"music_genre\": \"classical\",\n                \"tempo_range\": (50, 80),\n                \"key_preference\": \"minor_to_major\",\n                \"video_theme\": \"warm_colors\",\n                \"duration\": 30\n            },\n            \"anger_to_peace\": {\n                \"music_genre\": \"meditation\",\n                \"tempo_range\": (40, 60),\n                \"key_preference\": \"major\",\n                \"video_theme\": \"water\",\n                \"duration\": 35\n            }\n        }\n    \n    def generate_prescription(self, user_profile: Dict, current_emotion: Dict, target_emotion: Dict) -> TherapyPrescription:\n        \"\"\"ç”Ÿæˆæ²»ç–—å¤„æ–¹\"\"\"\n        \n        # ç®€å•çš„å¤„æ–¹åŒ¹é…é€»è¾‘\n        emotion_key = self._classify_emotion_transition(current_emotion, target_emotion)\n        template = self.prescription_templates.get(emotion_key, self.prescription_templates[\"anxiety_to_calm\"])\n        \n        prescription = TherapyPrescription(\n            prescription_id=f\"rx_{hash(str(current_emotion))%10000:04d}\",\n            user_profile=user_profile,\n            current_emotion=current_emotion,\n            target_emotion=target_emotion,\n            recommendations={\n                \"music\": {\n                    \"genre\": template[\"music_genre\"],\n                    \"tempo_bpm\": template[\"tempo_range\"],\n                    \"key\": template[\"key_preference\"]\n                },\n                \"video\": {\n                    \"theme\": template[\"video_theme\"],\n                    \"style\": \"soft_transitions\"\n                },\n                \"session\": {\n                    \"duration_minutes\": template[\"duration\"],\n                    \"stages\": [\"sync\", \"guide\", \"consolidate\"]\n                }\n            },\n            confidence_score=0.85\n        )\n        \n        return prescription\n    \n    def _classify_emotion_transition(self, current: Dict, target: Dict) -> str:\n        \"\"\"åˆ†ç±»æƒ…ç»ªè½¬æ¢ç±»å‹\"\"\"\n        current_valence = current.get(\"valence\", 0)\n        current_arousal = current.get(\"arousal\", 0.5)\n        \n        if current_arousal > 0.7 and current_valence < 0:\n            return \"anxiety_to_calm\"  # é«˜å”¤é†’è´Ÿæƒ…ç»ª\n        elif current_valence < -0.3:\n            return \"sadness_to_comfort\"  # ä½æ•ˆä»·\n        elif current_arousal > 0.8:\n            return \"anger_to_peace\"  # é«˜å”¤é†’\n        else:\n            return \"anxiety_to_calm\"  # é»˜è®¤\n    \n    def validate_prescription(self, prescription: TherapyPrescription) -> Dict:\n        \"\"\"éªŒè¯å¤„æ–¹æœ‰æ•ˆæ€§\"\"\"\n        return {\n            \"is_valid\": True,\n            \"confidence\": prescription.confidence_score,\n            \"warnings\": [],\n            \"suggestions\": [\"å»ºè®®åœ¨å®‰é™ç¯å¢ƒä¸­è¿›è¡Œ\", \"ä¿æŒèˆ’é€‚çš„åå§¿æˆ–èººå§¿\"]\n        }\n'''\n        }\n        \n        # å†™å…¥Mockæ–‡ä»¶\n        for filename, content in mock_therapy_files.items():\n            file_path = therapy_dir / filename\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n            print(f\"ğŸ”§ åˆ›å»º {filename}\")\n        \n        # åˆ›å»º__init__.py\n        init_file = therapy_dir / '__init__.py'\n        with open(init_file, 'w', encoding='utf-8') as f:\n            f.write('\"\"\"ç–—æ„ˆç³»ç»Ÿæ¨¡å—\"\"\"\\n')\n        \n        # é‡æ–°å¯¼å…¥\n        try:\n            import importlib\n            import sys\n            \n            # æ¸…ç†ç¼“å­˜\n            modules_to_clear = [name for name in sys.modules.keys() if name.startswith('src.therapy')]\n            for module_name in modules_to_clear:\n                del sys.modules[module_name]\n            \n            from src.therapy.core import TherapyOrchestrator, TherapySession, EmotionTrajectoryPlanner\n            from src.therapy.stages import ISOStageManager\n            from src.therapy.prescriptions import PrescriptionEngine\n            \n            print(\"âœ… Mockç–—æ„ˆç³»ç»Ÿåˆ›å»ºå¹¶å¯¼å…¥æˆåŠŸ\")\n            therapy_system_ok = True\n            \n        except Exception as e2:\n            print(f\"âŒ Mockç–—æ„ˆç³»ç»Ÿåˆ›å»ºå¤±è´¥: {e2}\")\n    \n    # æµ‹è¯•ç–—æ„ˆç³»ç»ŸåŠŸèƒ½\n    if therapy_system_ok:\n        try:\n            # åˆ›å»ºå¤„æ–¹å¼•æ“æµ‹è¯•\n            prescription_engine = PrescriptionEngine()\n            print(\"âœ… å¤„æ–¹å¼•æ“åˆå§‹åŒ–æˆåŠŸ\")\n            \n            # åˆ›å»ºç–—æ„ˆç¼–æ’å™¨æµ‹è¯•\n            orchestrator = TherapyOrchestrator()\n            \n            # æµ‹è¯•åˆ›å»ºä¼šè¯\n            test_current = {\"valence\": -0.4, \"arousal\": 0.8}  # ç„¦è™‘çŠ¶æ€\n            test_target = {\"valence\": 0.6, \"arousal\": 0.3}    # å¹³é™çŠ¶æ€\n            \n            session = orchestrator.create_session(\"test_user\", test_current, test_target)\n            recommendations = orchestrator.get_session_recommendations(session.session_id)\n            \n            print(f\"âœ… ç–—æ„ˆä¼šè¯åˆ›å»ºæˆåŠŸ: {session.session_id}\")\n            print(f\"âœ… è½¨è¿¹è§„åˆ’: {len(recommendations['trajectory'])}ä¸ªæ­¥éª¤\")\n            \n            # æµ‹è¯•å¤„æ–¹ç”Ÿæˆ\n            prescription = prescription_engine.generate_prescription(\n                {\"user_type\": \"student\"}, test_current, test_target\n            )\n            print(f\"âœ… å¤„æ–¹ç”ŸæˆæˆåŠŸ: {prescription.prescription_id}\")\n            \n        except Exception as e:\n            print(f\"âš ï¸  ç–—æ„ˆç³»ç»Ÿæµ‹è¯•è­¦å‘Š: {e}\")\n            \nexcept Exception as e:\n    print(f\"âŒ ç–—æ„ˆç³»ç»Ÿä¸¥é‡é”™è¯¯: {e}\")\n    therapy_system_ok = False\n\nif not therapy_system_ok:\n    print(\"ğŸ’¡ æç¤º: ç–—æ„ˆç³»ç»Ÿæµ‹è¯•å¤±è´¥ï¼Œä½†ç³»ç»Ÿä»å¯ç»§ç»­è¿è¡Œ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ¨¡å‹ç¼“å­˜é¢„çƒ­ (å¯é€‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”¥ æ¨¡å‹ç¼“å­˜é¢„çƒ­:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"âš ï¸ æ­¤æ­¥éª¤å¯é€‰ï¼Œé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ä¸‹è½½æ¨¡å‹\")\n",
    "print(\"å»ºè®®åœ¨ç½‘ç»œæ¡ä»¶è‰¯å¥½æ—¶è¿è¡Œ\")\n",
    "\n",
    "# é¢„çƒ­å°æ¨¡å‹ (è¾ƒå¿«)\n",
    "PRELOAD_MODELS = input(\"\\næ˜¯å¦é¢„åŠ è½½å°æ¨¡å‹è¿›è¡Œæµ‹è¯•? (y/n): \").lower().strip() == 'y'\n",
    "\n",
    "if PRELOAD_MODELS:\n",
    "    try:\n",
    "        print(\"\\nå¼€å§‹é¢„åŠ è½½æ¨¡å‹...\")\n",
    "        \n",
    "        # é¢„åŠ è½½æ–‡æœ¬æƒ…ç»ªè¯†åˆ«æ¨¡å‹ (è¾ƒå°)\n",
    "        print(\"ğŸ“¥ é¢„åŠ è½½æ–‡æœ¬æƒ…ç»ªè¯†åˆ«æ¨¡å‹...\")\n",
    "        from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "        \n",
    "        model_id = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id, \n",
    "            cache_dir=cache_dir / 'transformers'\n",
    "        )\n",
    "        print(f\"âœ… TokenizeråŠ è½½æˆåŠŸ: {model_id}\")\n",
    "        \n",
    "        # å¦‚æœGPUå¯ç”¨ä¸”å†…å­˜å……è¶³ï¼Œé¢„åŠ è½½æ¨¡å‹\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            if gpu_memory >= 8:  # è‡³å°‘8GBæ‰åŠ è½½æ¨¡å‹\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_id,\n",
    "                    cache_dir=cache_dir / 'transformers'\n",
    "                )\n",
    "                print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_id}\")\n",
    "                \n",
    "                # é‡Šæ”¾å†…å­˜\n",
    "                del model\n",
    "                torch.cuda.empty_cache()\n",
    "                print(\"âœ… GPUå†…å­˜å·²æ¸…ç†\")\n",
    "            else:\n",
    "                print(\"âš ï¸ GPUå†…å­˜ä¸è¶³ï¼Œè·³è¿‡æ¨¡å‹é¢„åŠ è½½\")\n",
    "        \n",
    "        del tokenizer\n",
    "        gc.collect()\n",
    "        print(\"âœ… æ¨¡å‹ç¼“å­˜é¢„çƒ­å®Œæˆ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}\")\n",
    "        print(\"è¿™å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥ç¨åå†è¯•\")\nelse:\n",
    "    print(\"â­ï¸ è·³è¿‡æ¨¡å‹é¢„çƒ­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç³»ç»ŸçŠ¶æ€æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿåˆå§‹åŒ–æ€»ç»“\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ”¶é›†çŠ¶æ€ä¿¡æ¯\n",
    "status_report = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'environment': {\n",
    "        'python_version': sys.version.split()[0],\n",
    "        'platform': platform.system(),\n",
    "        'working_directory': str(PROJECT_ROOT)\n",
    "    },\n",
    "    'resources': {\n",
    "        'cpu_cores': cpu_count,\n",
    "        'total_memory_gb': round(memory_gb, 1),\n",
    "        'available_memory_gb': round(memory_available_gb, 1),\n",
    "        'disk_free_gb': round(disk_free_gb, 1)\n",
    "    },\n",
    "    'gpu': {\n",
    "        'cuda_available': torch.cuda.is_available() if 'torch' in locals() else False,\n",
    "        'gpu_count': torch.cuda.device_count() if 'torch' in locals() and torch.cuda.is_available() else 0\n",
    "    },\n",
    "    'dependencies': {\n",
    "        'core_installed': len(missing_packages) == 0,\n",
    "        'missing_packages': missing_packages\n",
    "    },\n",
    "    'modules': {\n",
    "        'theory_modules': 'iso_planner' in locals(),\n",
    "        'model_adapters': 'ModelFactory' in locals(),\n",
    "        'therapy_system': 'TherapyOrchestrator' in locals()\n",
    "    }\n",
    "}\n",
    "\n",
    "# æ·»åŠ GPUè¯¦ç»†ä¿¡æ¯\n",
    "if status_report['gpu']['cuda_available']:\n",
    "    gpu_info = []\n",
    "    for i in range(status_report['gpu']['gpu_count']):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        gpu_info.append({\n",
    "            'name': props.name,\n",
    "            'memory_gb': round(props.total_memory / (1024**3), 1),\n",
    "            'compute_capability': f\"{props.major}.{props.minor}\"\n",
    "        })\n",
    "    status_report['gpu']['devices'] = gpu_info\n",
    "\n",
    "# æ˜¾ç¤ºçŠ¶æ€æŠ¥å‘Š\n",
    "print(f\"åˆå§‹åŒ–æ—¶é—´: {status_report['timestamp']}\")\n",
    "print(f\"Pythonç‰ˆæœ¬: {status_report['environment']['python_version']}\")\n",
    "print(f\"ç³»ç»Ÿå¹³å°: {status_report['environment']['platform']}\")\n",
    "print(f\"\\nğŸ’¾ ç³»ç»Ÿèµ„æº:\")\n",
    "print(f\"  CPUæ ¸å¿ƒ: {status_report['resources']['cpu_cores']}\")\n",
    "print(f\"  æ€»å†…å­˜: {status_report['resources']['total_memory_gb']} GB\")\n",
    "print(f\"  å¯ç”¨å†…å­˜: {status_report['resources']['available_memory_gb']} GB\")\n",
    "print(f\"  ç£ç›˜å¯ç”¨: {status_report['resources']['disk_free_gb']} GB\")\n",
    "\n",
    "print(f\"\\nğŸ® GPUçŠ¶æ€:\")\n",
    "if status_report['gpu']['cuda_available']:\n",
    "    print(f\"  CUDAå¯ç”¨: âœ…\")\n",
    "    print(f\"  GPUæ•°é‡: {status_report['gpu']['gpu_count']}\")\n",
    "    for i, gpu in enumerate(status_report['gpu']['devices']):\n",
    "        print(f\"  GPU {i}: {gpu['name']} ({gpu['memory_gb']} GB)\")\nelse:\n",
    "    print(f\"  CUDAå¯ç”¨: âŒ\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ ä¾èµ–çŠ¶æ€:\")\n",
    "if status_report['dependencies']['core_installed']:\n",
    "    print(\"  æ ¸å¿ƒä¾èµ–: âœ… å…¨éƒ¨å·²å®‰è£…\")\nelse:\n",
    "    print(f\"  æ ¸å¿ƒä¾èµ–: âŒ ç¼ºå¤± {len(status_report['dependencies']['missing_packages'])} ä¸ª\")\n",
    "\n",
    "print(f\"\\nğŸ§© æ¨¡å—çŠ¶æ€:\")\n",
    "modules = status_report['modules']\n",
    "print(f\"  ç†è®ºæ¨¡å—: {'âœ…' if modules['theory_modules'] else 'âŒ'}\")\n",
    "print(f\"  æ¨¡å‹é€‚é…å™¨: {'âœ…' if modules['model_adapters'] else 'âŒ'}\")\n",
    "print(f\"  ç–—æ„ˆç³»ç»Ÿ: {'âœ…' if modules['therapy_system'] else 'âŒ'}\")\n",
    "\n",
    "# ç»™å‡ºæ€»ä½“è¯„ä¼°\n",
    "all_good = (\n",
    "    status_report['dependencies']['core_installed'] and\n",
    "    modules['theory_modules'] and\n",
    "    modules['model_adapters'] and\n",
    "    modules['therapy_system']\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ¯ ç³»ç»ŸçŠ¶æ€:\")\n",
    "if all_good:\n",
    "    print(\"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼å¯ä»¥ç»§ç»­è¿è¡Œå…¶ä»–notebook\")\n",
    "    recommendation = \"å»ºè®®æŒ‰é¡ºåºè¿è¡Œï¼š02_theory_models_demo â†’ 03_model_adapters_test â†’ 04_therapy_session_demo\"\nelse:\n",
    "    print(\"âš ï¸ ç³»ç»Ÿåˆå§‹åŒ–å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯\")\n",
    "    recommendation = \"è¯·å…ˆè§£å†³ä¾èµ–åº“å’Œæ¨¡å—å¯¼å…¥é—®é¢˜ï¼Œç„¶åé‡æ–°è¿è¡Œæ­¤notebook\"\n",
    "\n",
    "print(f\"\\nğŸ’¡ å»ºè®®: {recommendation}\")\n",
    "\n",
    "# ä¿å­˜çŠ¶æ€æŠ¥å‘Š\n",
    "status_file = PROJECT_ROOT / 'outputs' / 'initialization_status.json'\n",
    "with open(status_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(status_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ“„ çŠ¶æ€æŠ¥å‘Šå·²ä¿å­˜: {status_file}\")\nprint(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ åˆå§‹åŒ–å®Œæˆï¼\n",
    "\n",
    "å¦‚æœä¸Šè¿°æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼Œæ‚¨ç°åœ¨å¯ä»¥ï¼š\n",
    "\n",
    "1. **ç»§ç»­è¿è¡Œç†è®ºæ¼”ç¤º**: `02_theory_models_demo.ipynb`\n",
    "2. **æµ‹è¯•æ¨¡å‹é€‚é…å™¨**: `03_model_adapters_test.ipynb`  \n",
    "3. **ä½“éªŒå®Œæ•´ç–—æ„ˆæµç¨‹**: `04_therapy_session_demo.ipynb`\n",
    "\n",
    "### ğŸ“ é‡è¦æç¤º\n",
    "- æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å°†ä¿å­˜åœ¨ `outputs/` ç›®å½•\n",
    "- æ¨¡å‹ç¼“å­˜ä½äº `outputs/cache/` ç›®å½•\n",
    "- å¦‚é‡é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ `10_troubleshooting_guide.ipynb`\n",
    "\n",
    "### ğŸ†˜ è·å–å¸®åŠ©\n",
    "å¦‚æœåˆå§‹åŒ–è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š\n",
    "1. æ£€æŸ¥JupyterHubç¯å¢ƒçš„GPUå’Œå†…å­˜èµ„æº\n",
    "2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸ (æ¨¡å‹ä¸‹è½½éœ€è¦)\n",
    "3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—å®šä½é—®é¢˜\n",
    "4. å‚è€ƒæ•…éšœæ’é™¤æŒ‡å—"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}