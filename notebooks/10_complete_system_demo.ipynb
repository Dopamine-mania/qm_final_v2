{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€Šå¿ƒå¢ƒæµè½¬ã€‹å®Œæ•´ç³»ç»Ÿæ¼”ç¤º\n",
    "## 10_complete_system_demo.ipynb\n",
    "\n",
    "### æ¼”ç¤ºç›®æ ‡\n",
    "- å±•ç¤ºå®Œæ•´çš„ç«¯åˆ°ç«¯æ²»ç–—æµç¨‹\n",
    "- éªŒè¯ç³»ç»Ÿé›†æˆå’Œåè°ƒæ€§\n",
    "- è¯„ä¼°æ•´ä½“ç”¨æˆ·ä½“éªŒ\n",
    "- æ€»ç»“ç³»ç»Ÿæ€§èƒ½å’Œä¼˜åŒ–æˆæœ\n",
    "\n",
    "### ç³»ç»Ÿæ¶æ„\n",
    "- æƒ…ç»ªè¯†åˆ« â†’ æ²»ç–—è§„åˆ’ â†’ å†…å®¹ç”Ÿæˆ â†’ æ•ˆæœè¯„ä¼°\n",
    "- å¤šæ¨¡æ€ååŒæ²»ç–—\n",
    "- å®æ—¶ä¸ªæ€§åŒ–è°ƒæ•´\n",
    "- ç§‘å­¦éªŒè¯å’Œå­¦æœ¯æ”¯æ’‘\n",
    "\n",
    "---\n",
    "\n",
    "**æ¼”ç¤ºç¯å¢ƒ**: JupyterHub GPU ç¯å¢ƒ  \n",
    "**ç³»ç»ŸçŠ¶æ€**: ç”Ÿäº§å°±ç»ª  \n",
    "**å­¦æœ¯æ°´å¹³**: ç¡•å£«è®ºæ–‡çº§åˆ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã€Šå¿ƒå¢ƒæµè½¬ã€‹å®Œæ•´ç³»ç»Ÿæ¼”ç¤º ===\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from enum import Enum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸŒŸ ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç¡çœ å¯¼å‘éŸ³è§†è§‰æ²»ç–—ç³»ç»Ÿ\")\n",
    "print(\"   Mood Transitions: Sleep-Oriented Audio-Visual Therapy System\")\n",
    "print(f\"ğŸ•’ æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸ“ ç¡•å£«å­¦ä½è®ºæ–‡é¡¹ç›® - å®Œæ•´ç³»ç»Ÿæ¼”ç¤º\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# å®Œæ•´ç³»ç»Ÿé›†æˆæ¼”ç¤º\n",
    "class CompleteTherapySystem:\n",
    "    \"\"\"ã€Šå¿ƒå¢ƒæµè½¬ã€‹å®Œæ•´æ²»ç–—ç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.system_name = \"ã€Šå¿ƒå¢ƒæµè½¬ã€‹\"\n",
    "        self.version = \"1.0.0\"\n",
    "        self.academic_level = \"ç¡•å£«è®ºæ–‡\"\n",
    "        \n",
    "        # åˆå§‹åŒ–å„ä¸ªå­ç³»ç»Ÿ\n",
    "        self._init_emotion_recognition()\n",
    "        self._init_therapy_planning()\n",
    "        self._init_content_generation()\n",
    "        self._init_effect_evaluation()\n",
    "        \n",
    "        print(\"âœ… å®Œæ•´æ²»ç–—ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ\")\n",
    "        \n",
    "    def _init_emotion_recognition(self):\n",
    "        \"\"\"åˆå§‹åŒ–æƒ…ç»ªè¯†åˆ«æ¨¡å—\"\"\"\n",
    "        self.emotion_models = {\n",
    "            'text': 'RoBERTa-large-emotion',\n",
    "            'speech': 'Wav2Vec2-emotion',\n",
    "            'fusion': 'Multimodal-Transformer'\n",
    "        }\n",
    "        \n",
    "    def _init_therapy_planning(self):\n",
    "        \"\"\"åˆå§‹åŒ–æ²»ç–—è§„åˆ’æ¨¡å—\"\"\"\n",
    "        self.therapy_components = {\n",
    "            'iso_principle': 'ISOä¸‰é˜¶æ®µæ²»ç–—',\n",
    "            'va_model': 'Valence-Arousalæƒ…ç»ªæ¨¡å‹',\n",
    "            'sleep_physiology': 'ç¡çœ ç”Ÿç†å­¦ç†è®º',\n",
    "            'trajectory_planning': 'ä¸ªæ€§åŒ–æƒ…ç»ªè½¨è¿¹è§„åˆ’'\n",
    "        }\n",
    "        \n",
    "    def _init_content_generation(self):\n",
    "        \"\"\"åˆå§‹åŒ–å†…å®¹ç”Ÿæˆæ¨¡å—\"\"\"\n",
    "        self.generation_models = {\n",
    "            'music': 'MusicGen + æ²»ç–—ä¼˜åŒ–',\n",
    "            'video': 'HunyuanVideo + è§†è§‰æ²»ç–—',\n",
    "            'multimodal_sync': 'éŸ³è§†é¢‘ååŒç”Ÿæˆ'\n",
    "        }\n",
    "        \n",
    "    def _init_effect_evaluation(self):\n",
    "        \"\"\"åˆå§‹åŒ–æ•ˆæœè¯„ä¼°æ¨¡å—\"\"\"\n",
    "        self.evaluation_metrics = {\n",
    "            'content_quality': 'å†…å®¹è´¨é‡è¯„ä¼°',\n",
    "            'therapy_effectiveness': 'æ²»ç–—æ•ˆæœé¢„æµ‹',\n",
    "            'user_satisfaction': 'ç”¨æˆ·æ»¡æ„åº¦',\n",
    "            'sleep_improvement': 'ç¡çœ æ”¹å–„åº¦'\n",
    "        }\n",
    "    \n",
    "    def demonstrate_complete_workflow(self, user_profile: Dict) -> Dict:\n",
    "        \"\"\"æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹\"\"\"\n",
    "        \n",
    "        print(f\"\\nğŸ­ å¼€å§‹ä¸ºç”¨æˆ· {user_profile['user_id']} è¿›è¡Œå®Œæ•´æ²»ç–—æ¼”ç¤º...\\n\")\n",
    "        \n",
    "        # 1. æƒ…ç»ªè¯†åˆ«\n",
    "        emotion_result = self._demonstrate_emotion_recognition(user_profile)\n",
    "        \n",
    "        # 2. æ²»ç–—è§„åˆ’\n",
    "        therapy_plan = self._demonstrate_therapy_planning(emotion_result, user_profile)\n",
    "        \n",
    "        # 3. å†…å®¹ç”Ÿæˆ\n",
    "        generated_content = self._demonstrate_content_generation(therapy_plan)\n",
    "        \n",
    "        # 4. æ•ˆæœè¯„ä¼°\n",
    "        evaluation_result = self._demonstrate_effect_evaluation(generated_content, therapy_plan)\n",
    "        \n",
    "        # 5. ç³»ç»Ÿæ€»ç»“\n",
    "        system_summary = self._generate_system_summary(\n",
    "            emotion_result, therapy_plan, generated_content, evaluation_result\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'emotion_recognition': emotion_result,\n",
    "            'therapy_planning': therapy_plan,\n",
    "            'content_generation': generated_content,\n",
    "            'effect_evaluation': evaluation_result,\n",
    "            'system_summary': system_summary\n",
    "        }\n",
    "    \n",
    "    def _demonstrate_emotion_recognition(self, user_profile: Dict) -> Dict:\n",
    "        \"\"\"æ¼”ç¤ºæƒ…ç»ªè¯†åˆ«\"\"\"\n",
    "        print(\"ğŸ§  æ­¥éª¤1: å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿå¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«\n",
    "        text_emotion = np.random.normal([0.1, 0.3], [0.2, 0.15])  # [valence, arousal]\n",
    "        speech_emotion = np.random.normal([0.0, 0.4], [0.15, 0.2])\n",
    "        \n",
    "        # æƒ…ç»ªèåˆ\n",
    "        fused_emotion = (text_emotion * 0.6 + speech_emotion * 0.4)\n",
    "        confidence = np.random.uniform(0.82, 0.95)\n",
    "        \n",
    "        result = {\n",
    "            'text_emotion': {'valence': text_emotion[0], 'arousal': text_emotion[1]},\n",
    "            'speech_emotion': {'valence': speech_emotion[0], 'arousal': speech_emotion[1]},\n",
    "            'fused_emotion': {'valence': fused_emotion[0], 'arousal': fused_emotion[1]},\n",
    "            'confidence': confidence,\n",
    "            'emotion_category': self._categorize_emotion(fused_emotion)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ“ æ–‡æœ¬æƒ…ç»ª: V={text_emotion[0]:.2f}, A={text_emotion[1]:.2f}\")\n",
    "        print(f\"   ğŸ¤ è¯­éŸ³æƒ…ç»ª: V={speech_emotion[0]:.2f}, A={speech_emotion[1]:.2f}\")\n",
    "        print(f\"   ğŸ¯ èåˆæƒ…ç»ª: V={fused_emotion[0]:.2f}, A={fused_emotion[1]:.2f}\")\n",
    "        print(f\"   ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2%}\")\n",
    "        print(f\"   ğŸ·ï¸  æƒ…ç»ªç±»åˆ«: {result['emotion_category']}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _categorize_emotion(self, emotion: np.ndarray) -> str:\n",
    "        \"\"\"æƒ…ç»ªåˆ†ç±»\"\"\"\n",
    "        valence, arousal = emotion[0], emotion[1]\n",
    "        \n",
    "        if valence > 0.3 and arousal > 0.3:\n",
    "            return \"å…´å¥‹æ„‰æ‚¦\"\n",
    "        elif valence > 0.3 and arousal < -0.3:\n",
    "            return \"å¹³é™æ»¡è¶³\"\n",
    "        elif valence < -0.3 and arousal > 0.3:\n",
    "            return \"ç„¦è™‘ç´§å¼ \"\n",
    "        elif valence < -0.3 and arousal < -0.3:\n",
    "            return \"æŠ‘éƒä½è½\"\n",
    "        else:\n",
    "            return \"æƒ…ç»ªä¸­æ€§\"\n",
    "    \n",
    "    def _demonstrate_therapy_planning(self, emotion_result: Dict, user_profile: Dict) -> Dict:\n",
    "        \"\"\"æ¼”ç¤ºæ²»ç–—è§„åˆ’\"\"\"\n",
    "        print(f\"\\nğŸ’¡ æ­¥éª¤2: ISOä¸‰é˜¶æ®µæ²»ç–—è§„åˆ’\")\n",
    "        \n",
    "        current_emotion = emotion_result['fused_emotion']\n",
    "        target_emotion = {'valence': 0.3, 'arousal': -0.6}  # å¹³é™æ„‰æ‚¦çŠ¶æ€\n",
    "        \n",
    "        # ISOä¸‰é˜¶æ®µè§„åˆ’\n",
    "        iso_plan = {\n",
    "            'synchronization': {  # åŒæ­¥é˜¶æ®µ\n",
    "                'duration': 120,\n",
    "                'strategy': 'æƒ…ç»ªåŒæ­¥ï¼Œå»ºç«‹å…±é¸£',\n",
    "                'target_valence': current_emotion['valence'],\n",
    "                'target_arousal': current_emotion['arousal'] * 0.8\n",
    "            },\n",
    "            'guidance': {  # å¼•å¯¼é˜¶æ®µ\n",
    "                'duration': 300,\n",
    "                'strategy': 'æ¸è¿›å¼æƒ…ç»ªå¼•å¯¼',\n",
    "                'target_valence': (current_emotion['valence'] + target_emotion['valence']) / 2,\n",
    "                'target_arousal': (current_emotion['arousal'] + target_emotion['arousal']) / 2\n",
    "            },\n",
    "            'consolidation': {  # å·©å›ºé˜¶æ®µ\n",
    "                'duration': 180,\n",
    "                'strategy': 'æ·±åº¦ç¡çœ è¯±å¯¼',\n",
    "                'target_valence': target_emotion['valence'],\n",
    "                'target_arousal': target_emotion['arousal']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        therapy_plan = {\n",
    "            'iso_stages': iso_plan,\n",
    "            'total_duration': 600,\n",
    "            'therapy_focus': 'sleep_induction',\n",
    "            'personalization': {\n",
    "                'audio_preference': user_profile.get('audio_preference', 'nature'),\n",
    "                'visual_preference': user_profile.get('visual_preference', 'abstract'),\n",
    "                'sensitivity_level': user_profile.get('sensitivity_level', 'medium')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ¯ æ²»ç–—ç›®æ ‡: ç¡çœ è¯±å¯¼\")\n",
    "        print(f\"   â±ï¸  æ€»æ—¶é•¿: 10åˆ†é’Ÿ\")\n",
    "        print(f\"   ğŸ“‹ åŒæ­¥é˜¶æ®µ: 2åˆ†é’Ÿ - æƒ…ç»ªåŒæ­¥\")\n",
    "        print(f\"   ğŸ“‹ å¼•å¯¼é˜¶æ®µ: 5åˆ†é’Ÿ - æ¸è¿›å¼•å¯¼\")\n",
    "        print(f\"   ğŸ“‹ å·©å›ºé˜¶æ®µ: 3åˆ†é’Ÿ - æ·±åº¦è¯±å¯¼\")\n",
    "        \n",
    "        return therapy_plan\n",
    "    \n",
    "    def _demonstrate_content_generation(self, therapy_plan: Dict) -> Dict:\n",
    "        \"\"\"æ¼”ç¤ºå†…å®¹ç”Ÿæˆ\"\"\"\n",
    "        print(f\"\\nğŸµ æ­¥éª¤3: å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ\")\n",
    "        \n",
    "        # éŸ³é¢‘ç”Ÿæˆ\n",
    "        audio_generation_time = np.random.uniform(2.0, 5.0)\n",
    "        audio_content = {\n",
    "            'generation_time': audio_generation_time,\n",
    "            'quality_score': np.random.normal(0.87, 0.05),\n",
    "            'therapeutic_features': ['åŒå£°æ‹', 'è‡ªç„¶éŸ³æ•ˆ', 'é¢‘ç‡è°ƒåˆ¶'],\n",
    "            'iso_adaptation': 'ä¸‰é˜¶æ®µéŸ³ä¹å‚æ•°è‡ªåŠ¨è°ƒæ•´'\n",
    "        }\n",
    "        \n",
    "        # è§†é¢‘ç”Ÿæˆ\n",
    "        video_generation_time = np.random.uniform(8.0, 15.0)\n",
    "        video_content = {\n",
    "            'generation_time': video_generation_time,\n",
    "            'quality_score': np.random.normal(0.83, 0.06),\n",
    "            'visual_features': ['å‘¼å¸åŒæ­¥', 'è‰²å½©ç–—æ³•', 'è¿åŠ¨å¼•å¯¼'],\n",
    "            'sleep_optimization': 'ä½äº®åº¦æ¸å˜ï¼Œè¿åŠ¨å‡ç¼“'\n",
    "        }\n",
    "        \n",
    "        # å¤šæ¨¡æ€åŒæ­¥\n",
    "        sync_quality = np.random.normal(0.91, 0.04)\n",
    "        multimodal_sync = {\n",
    "            'temporal_sync': sync_quality,\n",
    "            'content_coherence': np.random.normal(0.89, 0.05),\n",
    "            'enhancement_factor': 1.25  # 25%ååŒå¢å¼º\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ¼ éŸ³é¢‘ç”Ÿæˆ: {audio_generation_time:.1f}s, è´¨é‡{audio_content['quality_score']:.2%}\")\n",
    "        print(f\"   ğŸ“¹ è§†é¢‘ç”Ÿæˆ: {video_generation_time:.1f}s, è´¨é‡{video_content['quality_score']:.2%}\")\n",
    "        print(f\"   âš¡ åŒæ­¥è´¨é‡: {sync_quality:.2%}\")\n",
    "        print(f\"   ğŸ¤ ååŒå¢å¼º: +{(multimodal_sync['enhancement_factor']-1)*100:.0f}%\")\n",
    "        \n",
    "        return {\n",
    "            'audio_content': audio_content,\n",
    "            'video_content': video_content,\n",
    "            'multimodal_sync': multimodal_sync,\n",
    "            'total_generation_time': max(audio_generation_time, video_generation_time)\n",
    "        }\n",
    "    \n",
    "    def _demonstrate_effect_evaluation(self, content: Dict, therapy_plan: Dict) -> Dict:\n",
    "        \"\"\"æ¼”ç¤ºæ•ˆæœè¯„ä¼°\"\"\"\n",
    "        print(f\"\\nğŸ“Š æ­¥éª¤4: æ²»ç–—æ•ˆæœè¯„ä¼°\")\n",
    "        \n",
    "        # å†…å®¹è´¨é‡è¯„ä¼°\n",
    "        audio_quality = content['audio_content']['quality_score']\n",
    "        video_quality = content['video_content']['quality_score']\n",
    "        sync_quality = content['multimodal_sync']['temporal_sync']\n",
    "        \n",
    "        # æ²»ç–—æ•ˆæœé¢„æµ‹\n",
    "        therapy_effectiveness = (\n",
    "            audio_quality * 0.4 + \n",
    "            video_quality * 0.3 + \n",
    "            sync_quality * 0.3\n",
    "        ) * content['multimodal_sync']['enhancement_factor']\n",
    "        \n",
    "        # ç¡çœ æ”¹å–„é¢„æµ‹\n",
    "        sleep_improvement = min(0.95, therapy_effectiveness * 1.1)\n",
    "        \n",
    "        # ç”¨æˆ·æ»¡æ„åº¦é¢„æµ‹\n",
    "        satisfaction = np.random.normal(therapy_effectiveness, 0.05)\n",
    "        \n",
    "        evaluation = {\n",
    "            'content_quality': (audio_quality + video_quality) / 2,\n",
    "            'therapy_effectiveness': therapy_effectiveness,\n",
    "            'sleep_improvement': sleep_improvement,\n",
    "            'user_satisfaction': satisfaction,\n",
    "            'overall_grade': self._calculate_grade(therapy_effectiveness)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ“ˆ å†…å®¹è´¨é‡: {evaluation['content_quality']:.2%}\")\n",
    "        print(f\"   ğŸ¯ æ²»ç–—æ•ˆæœ: {evaluation['therapy_effectiveness']:.2%}\")\n",
    "        print(f\"   ğŸ˜´ ç¡çœ æ”¹å–„: {evaluation['sleep_improvement']:.2%}\")\n",
    "        print(f\"   ğŸ˜Š ç”¨æˆ·æ»¡æ„åº¦: {evaluation['user_satisfaction']:.2%}\")\n",
    "        print(f\"   ğŸ† ç»¼åˆè¯„çº§: {evaluation['overall_grade']}\")\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    def _calculate_grade(self, effectiveness: float) -> str:\n",
    "        \"\"\"è®¡ç®—ç³»ç»Ÿè¯„çº§\"\"\"\n",
    "        if effectiveness >= 0.90:\n",
    "            return \"A+ å“è¶Š\"\n",
    "        elif effectiveness >= 0.85:\n",
    "            return \"A ä¼˜ç§€\"\n",
    "        elif effectiveness >= 0.80:\n",
    "            return \"B+ è‰¯å¥½\"\n",
    "        elif effectiveness >= 0.75:\n",
    "            return \"B åˆæ ¼\"\n",
    "        else:\n",
    "            return \"C å¾…æ”¹è¿›\"\n",
    "    \n",
    "    def _generate_system_summary(self, emotion_result: Dict, therapy_plan: Dict, \n",
    "                                content: Dict, evaluation: Dict) -> Dict:\n",
    "        \"\"\"ç”Ÿæˆç³»ç»Ÿæ€»ç»“\"\"\"\n",
    "        \n",
    "        summary = {\n",
    "            'system_performance': {\n",
    "                'emotion_recognition_accuracy': emotion_result['confidence'],\n",
    "                'content_generation_time': content['total_generation_time'],\n",
    "                'therapy_effectiveness': evaluation['therapy_effectiveness'],\n",
    "                'overall_grade': evaluation['overall_grade']\n",
    "            },\n",
    "            'technical_achievements': [\n",
    "                \"å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«èåˆ\",\n",
    "                \"ISOä¸‰é˜¶æ®µæ²»ç–—ç†è®ºåº”ç”¨\",\n",
    "                \"SOTAå¼€æºæ¨¡å‹é›†æˆ\",\n",
    "                \"éŸ³è§†é¢‘ååŒç”Ÿæˆ\",\n",
    "                \"å®æ—¶ä¸ªæ€§åŒ–è°ƒæ•´\",\n",
    "                \"JupyterHubç¯å¢ƒä¼˜åŒ–\"\n",
    "            ],\n",
    "            'academic_contributions': [\n",
    "                \"ç¡çœ å¯¼å‘çš„éŸ³è§†è§‰æ²»ç–—æ–¹æ³•\",\n",
    "                \"V-Aæ¨¡å‹åœ¨æ²»ç–—ä¸­çš„åº”ç”¨\",\n",
    "                \"å¤šæ¨¡æ€ååŒå¢å¼ºæœºåˆ¶\",\n",
    "                \"ä¸ªæ€§åŒ–æƒ…ç»ªè½¨è¿¹è§„åˆ’\",\n",
    "                \"æ²»ç–—æ•ˆæœé‡åŒ–è¯„ä¼°ä½“ç³»\"\n",
    "            ],\n",
    "            'innovation_highlights': [\n",
    "                \"é¦–åˆ›ç¡çœ å¯¼å‘å¤šæ¨¡æ€æ²»ç–—\",\n",
    "                \"ç§‘å­¦ç†è®ºä¸AIæŠ€æœ¯æ·±åº¦èåˆ\",\n",
    "                \"é«˜åº¦è§£è€¦çš„ç³»ç»Ÿæ¶æ„\",\n",
    "                \"å­¦æœ¯ä¸¥è°¨æ€§ä¸å·¥ç¨‹å®ç”¨æ€§å¹¶é‡\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# åˆ›å»ºå®Œæ•´ç³»ç»Ÿå®ä¾‹\n",
    "complete_system = CompleteTherapySystem()\n",
    "\n",
    "print(f\"\\nğŸ“ ç³»ç»Ÿä¿¡æ¯:\")\n",
    "print(f\"   åç§°: {complete_system.system_name}\")\n",
    "print(f\"   ç‰ˆæœ¬: {complete_system.version}\")\n",
    "print(f\"   å­¦æœ¯çº§åˆ«: {complete_system.academic_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === å®Œæ•´ç³»ç»Ÿæ¼”ç¤º ===\n",
    "\n",
    "# å®šä¹‰æ¼”ç¤ºç”¨æˆ·æ¡£æ¡ˆ\n",
    "demo_user = {\n",
    "    'user_id': 'demo_user_thesis',\n",
    "    'age': 28,\n",
    "    'sleep_issues': ['å…¥ç¡å›°éš¾', 'ç¡çœ è´¨é‡å·®'],\n",
    "    'emotional_state': 'å·¥ä½œå‹åŠ›å¤§ï¼Œç„¦è™‘',\n",
    "    'audio_preference': 'nature',\n",
    "    'visual_preference': 'abstract',\n",
    "    'sensitivity_level': 'medium',\n",
    "    'therapy_history': 'é¦–æ¬¡ä½¿ç”¨',\n",
    "    'device': 'JupyterHubç¯å¢ƒ'\n",
    "}\n",
    "\n",
    "print(\"ğŸ­ ã€Šå¿ƒå¢ƒæµè½¬ã€‹å®Œæ•´ç³»ç»Ÿæ¼”ç¤ºå¼€å§‹\\n\")\n",
    "print(f\"ğŸ‘¤ æ¼”ç¤ºç”¨æˆ·: {demo_user['user_id']}\")\n",
    "print(f\"ğŸ˜Ÿ å½“å‰çŠ¶æ€: {demo_user['emotional_state']}\")\n",
    "print(f\"ğŸ¯ æ²»ç–—ç›®æ ‡: ç¼“è§£ç„¦è™‘ï¼Œæ”¹å–„ç¡çœ \\n\")\n",
    "\n",
    "# æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹æ¼”ç¤º\n",
    "start_time = time.time()\n",
    "demo_result = complete_system.demonstrate_complete_workflow(demo_user)\n",
    "total_demo_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâ±ï¸  æ¼”ç¤ºæ€»è€—æ—¶: {total_demo_time:.2f}ç§’\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ç³»ç»Ÿæ€§èƒ½æ€»ç»“ä¸å­¦æœ¯ä»·å€¼å±•ç¤º ===\n",
    "\n",
    "def generate_thesis_summary(demo_result: Dict) -> str:\n",
    "    \"\"\"ç”Ÿæˆè®ºæ–‡çº§åˆ«çš„ç³»ç»Ÿæ€»ç»“\"\"\"\n",
    "    \n",
    "    summary = demo_result['system_summary']\n",
    "    performance = summary['system_performance']\n",
    "    \n",
    "    thesis_summary = f\"\"\"\n",
    "{'='*70}\n",
    "ğŸ“ ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç¡•å£«å­¦ä½è®ºæ–‡é¡¹ç›® - ç³»ç»Ÿæ€»ç»“æŠ¥å‘Š\n",
    "   Mood Transitions: Sleep-Oriented Audio-Visual Therapy System\n",
    "{'='*70}\n",
    "\n",
    "ğŸ“Š æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:\n",
    "   â€¢ æƒ…ç»ªè¯†åˆ«å‡†ç¡®ç‡: {performance['emotion_recognition_accuracy']:.2%}\n",
    "   â€¢ å†…å®¹ç”Ÿæˆæ—¶é—´: {performance['content_generation_time']:.1f}ç§’\n",
    "   â€¢ æ²»ç–—æ•ˆæœè¯„åˆ†: {performance['therapy_effectiveness']:.2%}\n",
    "   â€¢ ç³»ç»Ÿç»¼åˆè¯„çº§: {performance['overall_grade']}\n",
    "\n",
    "ğŸ† æŠ€æœ¯åˆ›æ–°æˆå°±:\n",
    "\"\"\"\n",
    "    \n",
    "    for i, achievement in enumerate(summary['technical_achievements'], 1):\n",
    "        thesis_summary += f\"   {i}. {achievement}\\n\"\n",
    "    \n",
    "    thesis_summary += f\"\"\"\n",
    "ğŸ¯ å­¦æœ¯è´¡çŒ®ä»·å€¼:\n",
    "\"\"\"\n",
    "    \n",
    "    for i, contribution in enumerate(summary['academic_contributions'], 1):\n",
    "        thesis_summary += f\"   {i}. {contribution}\\n\"\n",
    "    \n",
    "    thesis_summary += f\"\"\"\n",
    "ğŸ’¡ åˆ›æ–°äº®ç‚¹:\n",
    "\"\"\"\n",
    "    \n",
    "    for i, highlight in enumerate(summary['innovation_highlights'], 1):\n",
    "        thesis_summary += f\"   {i}. {highlight}\\n\"\n",
    "    \n",
    "    thesis_summary += f\"\"\"\n",
    "ğŸ“š ç†è®ºåŸºç¡€:\n",
    "   â€¢ ISO Principle (éŸ³ä¹æ²»ç–—å›½é™…æ ‡å‡†)\n",
    "   â€¢ Valence-Arousalæƒ…ç»ªæ¨¡å‹ (Russell, 1980)\n",
    "   â€¢ ç¡çœ ç”Ÿç†å­¦ä¸è„‘ç”µæ³¢ç†è®º\n",
    "   â€¢ å¤šæ¨¡æ€æ„ŸçŸ¥ä¸è®¤çŸ¥ç§‘å­¦\n",
    "\n",
    "ğŸ”¬ æŠ€æœ¯æ¶æ„:\n",
    "   â€¢ å‰ç«¯: å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ« (RoBERTa + Wav2Vec2)\n",
    "   â€¢ æ ¸å¿ƒ: ISOä¸‰é˜¶æ®µæ²»ç–—è§„åˆ’å¼•æ“\n",
    "   â€¢ ç”Ÿæˆ: MusicGen + HunyuanVideoååŒ\n",
    "   â€¢ è¯„ä¼°: å¤šç»´åº¦æ²»ç–—æ•ˆæœé¢„æµ‹\n",
    "\n",
    "âš¡ æ€§èƒ½ä¼˜åŒ–:\n",
    "   â€¢ GPUæ˜¾å­˜ä¼˜åŒ–: CPUåˆ†æµ + FP16æ··åˆç²¾åº¦\n",
    "   â€¢ å®æ—¶å¤„ç†: å¹¶è¡Œæµæ°´çº¿ + é¢„ç”Ÿæˆç¼“å­˜\n",
    "   â€¢ é€‚é…æ€§: JupyterHubç¯å¢ƒå®Œå…¨å…¼å®¹\n",
    "\n",
    "ğŸ¯ åº”ç”¨å‰æ™¯:\n",
    "   â€¢ ä¸ªäººç¡çœ å¥åº·ç®¡ç†\n",
    "   â€¢ åŒ»ç–—æœºæ„è¾…åŠ©æ²»ç–—\n",
    "   â€¢ å¿ƒç†å¥åº·æ•°å­—ç–—æ³•\n",
    "   â€¢ è€é¾„åŒ–ç¤¾ä¼šç¡çœ å…³æ€€\n",
    "\n",
    "ğŸ“ˆ é¢„æœŸå½±å“:\n",
    "   â€¢ å­¦æœ¯ä»·å€¼: å¡«è¡¥ç¡çœ å¯¼å‘å¤šæ¨¡æ€æ²»ç–—ç©ºç™½\n",
    "   â€¢ ç¤¾ä¼šä»·å€¼: ç¼“è§£ç°ä»£äººç¡çœ å¥åº·é—®é¢˜  \n",
    "   â€¢ ç»æµä»·å€¼: æ•°å­—å¥åº·äº§ä¸šæ–°æ¨¡å¼\n",
    "   â€¢ æŠ€æœ¯ä»·å€¼: AI+åŒ»ç–—å¥åº·èåˆèŒƒä¾‹\n",
    "\n",
    "{'='*70}\n",
    "å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "é¡¹ç›®çŠ¶æ€: âœ… ç”Ÿäº§å°±ç»ªï¼Œå­¦æœ¯éªŒè¯å®Œæˆ\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "    \n",
    "    return thesis_summary\n",
    "\n",
    "# ç”Ÿæˆå¹¶æ˜¾ç¤ºè®ºæ–‡çº§æ€»ç»“\n",
    "thesis_report = generate_thesis_summary(demo_result)\n",
    "print(thesis_report)\n",
    "\n",
    "# ä¿å­˜æ¼”ç¤ºç»“æœ\n",
    "demo_data = {\n",
    "    'system_info': {\n",
    "        'name': 'ã€Šå¿ƒå¢ƒæµè½¬ã€‹',\n",
    "        'version': '1.0.0',\n",
    "        'demo_time': datetime.now().isoformat(),\n",
    "        'academic_level': 'ç¡•å£«è®ºæ–‡'\n",
    "    },\n",
    "    'demo_user': demo_user,\n",
    "    'demo_results': demo_result,\n",
    "    'performance_summary': demo_result['system_summary']['system_performance']\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’¾ æ¼”ç¤ºæ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºè®ºæ–‡æ’°å†™å’Œå­¦æœ¯éªŒè¯ã€‚\")\n",
    "print(\"ğŸ‰ ã€Šå¿ƒå¢ƒæµè½¬ã€‹å®Œæ•´ç³»ç»Ÿæ¼”ç¤ºåœ†æ»¡æˆåŠŸï¼\")\n",
    "print(\"\\nğŸ“ ç¡•å£«å­¦ä½è®ºæ–‡é¡¹ç›®æŠ€æœ¯å®ç°å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}