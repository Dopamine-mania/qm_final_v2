{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - 理论模型演示\n",
        "\n",
        "本notebook演示《心境流转》系统的核心理论基础:\n",
        "- ISO三阶段治疗原则\n",
        "- Valence-Arousal情绪模型\n",
        "- 音乐心理学应用\n",
        "- 理论模型整合验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 基础设置\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设置matplotlib中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"《心境流转》理论模型演示\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 导入理论模块并创建Mock类\n",
        "try:\n",
        "    from research.theory.iso_principle import ISOPrinciple, EmotionState\n",
        "    from research.theory.valence_arousal import ValenceArousalModel\n",
        "    print(\"✅ 理论模块导入成功\")\n",
        "    iso_mode = \"real\"\n",
        "except ImportError:\n",
        "    print(\"🔧 使用Mock理论模块\")\n",
        "    iso_mode = \"mock\"\n",
        "\n",
        "# 定义核心数据结构\n",
        "@dataclass\n",
        "class EmotionState:\n",
        "    valence: float  # -1到1，负值表示消极\n",
        "    arousal: float  # -1到1，正值表示激活\n",
        "    confidence: float = 0.8\n",
        "    \n",
        "    def distance_to(self, other):\n",
        "        return ((self.valence - other.valence)**2 + (self.arousal - other.arousal)**2)**0.5\n",
        "\n",
        "class ISOStage(Enum):\n",
        "    SYNCHRONIZATION = \"同步化\"  # 与当前情绪同步\n",
        "    GUIDANCE = \"引导化\"        # 情绪转换引导\n",
        "    CONSOLIDATION = \"巩固化\"   # 目标情绪巩固\n",
        "\n",
        "class EmotionQuadrant(Enum):\n",
        "    POSITIVE_ACTIVE = \"积极激活\"    # 高兴、兴奋\n",
        "    NEGATIVE_ACTIVE = \"消极激活\"    # 愤怒、恐惧\n",
        "    NEGATIVE_PASSIVE = \"消极平静\"   # 悲伤、沮丧\n",
        "    POSITIVE_PASSIVE = \"积极平静\"   # 满足、放松\n",
        "\n",
        "print(\"✅ 核心数据结构定义完成\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 创建理论模型类\n",
        "class ISOPrinciple:\n",
        "    \"\"\"ISO三阶段治疗原则模型\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.stage_ratios = {\n",
        "            ISOStage.SYNCHRONIZATION: 0.25,  # 25%时间同步\n",
        "            ISOStage.GUIDANCE: 0.50,         # 50%时间引导\n",
        "            ISOStage.CONSOLIDATION: 0.25     # 25%时间巩固\n",
        "        }\n",
        "        print(\"🎵 ISO三阶段治疗原则已初始化\")\n",
        "    \n",
        "    def plan_stages(self, current_emotion, target_emotion, total_duration):\n",
        "        \"\"\"规划ISO三阶段\"\"\"\n",
        "        stages = []\n",
        "        \n",
        "        for stage, ratio in self.stage_ratios.items():\n",
        "            duration = total_duration * ratio\n",
        "            \n",
        "            if stage == ISOStage.SYNCHRONIZATION:\n",
        "                stage_emotion = current_emotion\n",
        "            elif stage == ISOStage.GUIDANCE:\n",
        "                # 中间状态\n",
        "                stage_emotion = EmotionState(\n",
        "                    valence=(current_emotion.valence + target_emotion.valence) / 2,\n",
        "                    arousal=(current_emotion.arousal + target_emotion.arousal) / 2\n",
        "                )\n",
        "            else:  # CONSOLIDATION\n",
        "                stage_emotion = target_emotion\n",
        "            \n",
        "            stages.append({\n",
        "                'stage': stage,\n",
        "                'duration': duration,\n",
        "                'target_emotion': stage_emotion,\n",
        "                'description': stage.value\n",
        "            })\n",
        "        \n",
        "        return stages\n",
        "    \n",
        "    def generate_trajectory(self, current_emotion, target_emotion, total_duration, points=50):\n",
        "        \"\"\"生成情绪变化轨迹\"\"\"\n",
        "        trajectory = []\n",
        "        \n",
        "        for i in range(points):\n",
        "            progress = i / (points - 1)\n",
        "            time = progress * total_duration\n",
        "            \n",
        "            # 使用平滑的S型曲线而非线性变化\n",
        "            smooth_progress = 3 * progress**2 - 2 * progress**3\n",
        "            \n",
        "            valence = current_emotion.valence + (target_emotion.valence - current_emotion.valence) * smooth_progress\n",
        "            arousal = current_emotion.arousal + (target_emotion.arousal - current_emotion.arousal) * smooth_progress\n",
        "            \n",
        "            # 确定当前阶段\n",
        "            if progress < 0.25:\n",
        "                stage = ISOStage.SYNCHRONIZATION\n",
        "            elif progress < 0.75:\n",
        "                stage = ISOStage.GUIDANCE\n",
        "            else:\n",
        "                stage = ISOStage.CONSOLIDATION\n",
        "            \n",
        "            trajectory.append({\n",
        "                'time': time,\n",
        "                'emotion': EmotionState(valence=valence, arousal=arousal),\n",
        "                'stage': stage\n",
        "            })\n",
        "        \n",
        "        return trajectory\n",
        "\n",
        "class VAModel:\n",
        "    \"\"\"Valence-Arousal情绪模型\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # 基础情绪映射\n",
        "        self.basic_emotions = {\n",
        "            '开心': (0.8, 0.6),   '兴奋': (0.7, 0.9),\n",
        "            '平静': (0.4, -0.7),  '满足': (0.6, -0.4),\n",
        "            '悲伤': (-0.6, -0.5), '沮丧': (-0.4, -0.6),\n",
        "            '愤怒': (-0.4, 0.8),  '恐惧': (-0.7, 0.6),\n",
        "            '中性': (0.0, 0.0)\n",
        "        }\n",
        "        print(\"📊 V-A情绪模型已初始化\")\n",
        "    \n",
        "    def determine_quadrant(self, emotion):\n",
        "        \"\"\"确定情绪象限\"\"\"\n",
        "        if emotion.valence >= 0 and emotion.arousal >= 0:\n",
        "            return EmotionQuadrant.POSITIVE_ACTIVE\n",
        "        elif emotion.valence < 0 and emotion.arousal >= 0:\n",
        "            return EmotionQuadrant.NEGATIVE_ACTIVE\n",
        "        elif emotion.valence < 0 and emotion.arousal < 0:\n",
        "            return EmotionQuadrant.NEGATIVE_PASSIVE\n",
        "        else:\n",
        "            return EmotionQuadrant.POSITIVE_PASSIVE\n",
        "    \n",
        "    def find_closest_emotion(self, emotion):\n",
        "        \"\"\"找到最接近的基础情绪\"\"\"\n",
        "        min_distance = float('inf')\n",
        "        closest_emotion = '中性'\n",
        "        \n",
        "        for emotion_name, (v, a) in self.basic_emotions.items():\n",
        "            distance = ((emotion.valence - v)**2 + (emotion.arousal - a)**2)**0.5\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                closest_emotion = emotion_name\n",
        "        \n",
        "        return closest_emotion, min_distance\n",
        "\n",
        "# 初始化模型\n",
        "iso_model = ISOPrinciple()\n",
        "va_model = VAModel()\n",
        "\n",
        "print(\"✅ 理论模型创建完成\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 定义测试情绪状态\n",
        "print(\"\\n🧪 定义测试情绪状态...\")\n",
        "\n",
        "# 当前情绪：焦虑状态 (负效价，高唤醒)\n",
        "current_emotion = EmotionState(\n",
        "    valence=-0.6,  # 负面情绪\n",
        "    arousal=0.8,   # 高唤醒（焦虑、紧张）\n",
        "    confidence=0.9\n",
        ")\n",
        "\n",
        "# 目标情绪：平静放松状态 (正效价，低唤醒)\n",
        "target_emotion = EmotionState(\n",
        "    valence=0.5,   # 轻微正面\n",
        "    arousal=-0.7,  # 低唤醒（放松）\n",
        "    confidence=0.9\n",
        ")\n",
        "\n",
        "print(f\"当前情绪: V={current_emotion.valence:.2f}, A={current_emotion.arousal:.2f}\")\n",
        "print(f\"目标情绪: V={target_emotion.valence:.2f}, A={target_emotion.arousal:.2f}\")\n",
        "print(f\"情绪距离: {current_emotion.distance_to(target_emotion):.3f}\")\n",
        "\n",
        "# VA象限分析\n",
        "current_quadrant = va_model.determine_quadrant(current_emotion)\n",
        "target_quadrant = va_model.determine_quadrant(target_emotion)\n",
        "current_basic, _ = va_model.find_closest_emotion(current_emotion)\n",
        "target_basic, _ = va_model.find_closest_emotion(target_emotion)\n",
        "\n",
        "print(f\"\\n当前象限: {current_quadrant.value} (基础情绪: {current_basic})\")\n",
        "print(f\"目标象限: {target_quadrant.value} (基础情绪: {target_basic})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. ISO三阶段规划\n",
        "print(\"\\n🎵 ISO三阶段治疗规划...\")\n",
        "\n",
        "total_duration = 20.0  # 20分钟治疗时长\n",
        "stages = iso_model.plan_stages(current_emotion, target_emotion, total_duration)\n",
        "\n",
        "print(f\"\\n总治疗时长: {total_duration} 分钟\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, stage_info in enumerate(stages, 1):\n",
        "    stage = stage_info['stage']\n",
        "    duration = stage_info['duration']\n",
        "    emotion = stage_info['target_emotion']\n",
        "    \n",
        "    print(f\"第{i}阶段: {stage.value}\")\n",
        "    print(f\"  持续时间: {duration:.1f} 分钟\")\n",
        "    print(f\"  目标情绪: V={emotion.valence:.2f}, A={emotion.arousal:.2f}\")\n",
        "    print(f\"  治疗策略: {stage_info['description']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. 生成情绪轨迹并可视化\n",
        "print(\"\\n📊 生成情绪变化轨迹...\")\n",
        "\n",
        "trajectory = iso_model.generate_trajectory(current_emotion, target_emotion, total_duration)\n",
        "\n",
        "# 提取数据用于可视化\n",
        "times = [point['time'] for point in trajectory]\n",
        "valences = [point['emotion'].valence for point in trajectory]\n",
        "arousals = [point['emotion'].arousal for point in trajectory]\n",
        "stages = [point['stage'] for point in trajectory]\n",
        "\n",
        "print(f\"轨迹包含 {len(trajectory)} 个时间点\")\n",
        "print(f\"轨迹持续时间: {times[-1]:.1f} 分钟\")\n",
        "\n",
        "# 可视化情绪轨迹\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 时间序列图\n",
        "ax1.plot(times, valences, 'b-', linewidth=3, label='效价 (Valence)', alpha=0.8)\n",
        "ax1.plot(times, arousals, 'r-', linewidth=3, label='唤醒 (Arousal)', alpha=0.8)\n",
        "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
        "\n",
        "# 标记阶段分界\n",
        "stage_colors = {'同步化': 'lightblue', '引导化': 'lightgreen', '巩固化': 'lightcoral'}\n",
        "stage_boundaries = [0, 5, 15, 20]  # 根据阶段比例计算\n",
        "\n",
        "for i in range(len(stage_boundaries)-1):\n",
        "    stage_name = list(stage_colors.keys())[i]\n",
        "    ax1.axvspan(stage_boundaries[i], stage_boundaries[i+1], \n",
        "               alpha=0.2, color=stage_colors[stage_name], label=stage_name)\n",
        "\n",
        "ax1.set_xlabel('时间 (分钟)', fontsize=12)\n",
        "ax1.set_ylabel('情绪维度值', fontsize=12)\n",
        "ax1.set_title('ISO三阶段情绪变化轨迹', fontsize=14, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# VA空间轨迹图\n",
        "ax2.plot(valences, arousals, 'purple', linewidth=3, alpha=0.8)\n",
        "ax2.scatter(current_emotion.valence, current_emotion.arousal, \n",
        "           c='red', s=150, marker='o', label='起始状态', zorder=5)\n",
        "ax2.scatter(target_emotion.valence, target_emotion.arousal, \n",
        "           c='green', s=150, marker='*', label='目标状态', zorder=5)\n",
        "\n",
        "# 绘制象限\n",
        "ax2.axhline(y=0, color='black', linewidth=1.5)\n",
        "ax2.axvline(x=0, color='black', linewidth=1.5)\n",
        "\n",
        "# 添加象限标签\n",
        "ax2.text(0.5, 0.5, '积极激活\\n(兴奋)', ha='center', va='center', \n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgreen', alpha=0.5))\n",
        "ax2.text(-0.5, 0.5, '消极激活\\n(焦虑)', ha='center', va='center',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightcoral', alpha=0.5))\n",
        "ax2.text(-0.5, -0.5, '消极平静\\n(悲伤)', ha='center', va='center',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.5))\n",
        "ax2.text(0.5, -0.5, '积极平静\\n(放松)', ha='center', va='center',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightyellow', alpha=0.5))\n",
        "\n",
        "ax2.set_xlim(-1, 1)\n",
        "ax2.set_ylim(-1, 1)\n",
        "ax2.set_xlabel('效价 (Valence) - 负面 ← → 正面', fontsize=12)\n",
        "ax2.set_ylabel('唤醒 (Arousal) - 平静 ← → 激活', fontsize=12)\n",
        "ax2.set_title('VA空间中的情绪轨迹', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✅ 情绪从 {current_basic} 成功转换到 {target_basic}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. 音乐治疗参数推荐\n",
        "print(\"\\n🎼 音乐治疗参数推荐...\")\n",
        "\n",
        "class MusicTherapyModel:\n",
        "    \"\"\"音乐治疗模型\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # BPM与唤醒度的映射关系\n",
        "        self.arousal_to_bpm = {\n",
        "            -1.0: 40,   # 极低唤醒 -> 极慢节拍\n",
        "            -0.5: 60,   # 低唤醒 -> 慢节拍  \n",
        "            0.0: 80,    # 中性唤醒 -> 中等节拍\n",
        "            0.5: 100,   # 高唤醒 -> 快节拍\n",
        "            1.0: 120    # 极高唤醒 -> 极快节拍\n",
        "        }\n",
        "        \n",
        "        # 效价与调性的映射\n",
        "        self.valence_to_key = {\n",
        "            'positive': ['C大调', 'G大调', 'D大调'],  # 明亮调性\n",
        "            'negative': ['A小调', 'E小调', 'B小调'],  # 忧郁调性\n",
        "            'neutral': ['F大调', 'C小调']            # 中性调性\n",
        "        }\n",
        "        \n",
        "        # 乐器推荐\n",
        "        self.therapy_instruments = {\n",
        "            'relaxation': ['钢琴', '弦乐', '长笛', '竖琴'],\n",
        "            'activation': ['小提琴', '木管', '轻打击乐'],\n",
        "            'stabilization': ['大提琴', '古典吉他', '合成音色']\n",
        "        }\n",
        "        \n",
        "        print(\"🎼 音乐治疗模型已初始化\")\n",
        "    \n",
        "    def interpolate_bpm(self, arousal):\n",
        "        \"\"\"根据唤醒度插值计算BPM\"\"\"\n",
        "        arousal = max(-1.0, min(1.0, arousal))  # 限制范围\n",
        "        \n",
        "        # 线性插值\n",
        "        if arousal >= 0:\n",
        "            return 80 + (arousal * 40)  # 80-120 BPM\n",
        "        else:\n",
        "            return 80 + (arousal * 40)  # 40-80 BPM\n",
        "    \n",
        "    def recommend_music(self, emotion_state, iso_stage):\n",
        "        \"\"\"推荐音乐参数\"\"\"\n",
        "        bpm = self.interpolate_bpm(emotion_state.arousal)\n",
        "        \n",
        "        # 选择调性\n",
        "        if emotion_state.valence > 0.2:\n",
        "            key_type = 'positive'\n",
        "        elif emotion_state.valence < -0.2:\n",
        "            key_type = 'negative'\n",
        "        else:\n",
        "            key_type = 'neutral'\n",
        "        \n",
        "        # 根据ISO阶段选择乐器\n",
        "        if iso_stage == ISOStage.SYNCHRONIZATION:\n",
        "            instruments = self.therapy_instruments['activation']\n",
        "        elif iso_stage == ISOStage.GUIDANCE:\n",
        "            instruments = self.therapy_instruments['relaxation']\n",
        "        else:  # CONSOLIDATION\n",
        "            instruments = self.therapy_instruments['stabilization']\n",
        "        \n",
        "        return {\n",
        "            'bpm': round(bpm),\n",
        "            'key_type': key_type,\n",
        "            'recommended_keys': self.valence_to_key[key_type],\n",
        "            'instruments': instruments,\n",
        "            'volume': 'soft' if emotion_state.arousal < 0 else 'moderate',\n",
        "            'dynamics': 'gentle' if abs(emotion_state.valence) > 0.5 else 'stable'\n",
        "        }\n",
        "\n",
        "# 创建音乐治疗模型\n",
        "music_model = MusicTherapyModel()\n",
        "\n",
        "# 为每个ISO阶段生成音乐推荐\n",
        "print(\"\\n=== 各阶段音乐治疗方案 ===\")\n",
        "\n",
        "for stage_info in stages:\n",
        "    stage = stage_info['stage']\n",
        "    emotion = stage_info['target_emotion']\n",
        "    duration = stage_info['duration']\n",
        "    \n",
        "    music_rec = music_model.recommend_music(emotion, stage)\n",
        "    \n",
        "    print(f\"\\n📍 {stage.value} ({duration:.1f}分钟)\")\n",
        "    print(f\"  目标情绪: V={emotion.valence:.2f}, A={emotion.arousal:.2f}\")\n",
        "    print(f\"  推荐BPM: {music_rec['bpm']}\")\n",
        "    print(f\"  调性类型: {music_rec['key_type']}\")\n",
        "    print(f\"  推荐调性: {', '.join(music_rec['recommended_keys'])}\")\n",
        "    print(f\"  主要乐器: {', '.join(music_rec['instruments'])}\")\n",
        "    print(f\"  音量: {music_rec['volume']}, 动态: {music_rec['dynamics']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. 可视化音乐参数变化\n",
        "print(\"\\n📊 可视化音乐参数变化...\")\n",
        "\n",
        "# 计算轨迹中每个点的音乐参数\n",
        "trajectory_bpms = []\n",
        "trajectory_volumes = []\n",
        "\n",
        "for point in trajectory:\n",
        "    emotion = point['emotion']\n",
        "    bpm = music_model.interpolate_bpm(emotion.arousal)\n",
        "    # 音量基于唤醒度映射到0-100\n",
        "    volume = 50 + (emotion.arousal * 25)  # 25-75音量范围\n",
        "    \n",
        "    trajectory_bpms.append(bpm)\n",
        "    trajectory_volumes.append(volume)\n",
        "\n",
        "# 可视化音乐参数变化\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# BPM变化\n",
        "ax1.plot(times, trajectory_bpms, 'orange', linewidth=3, marker='o', markersize=2)\n",
        "ax1.fill_between(times, trajectory_bpms, alpha=0.3, color='orange')\n",
        "\n",
        "# 标记ISO阶段\n",
        "for i in range(len(stage_boundaries)-1):\n",
        "    stage_name = list(stage_colors.keys())[i]\n",
        "    ax1.axvspan(stage_boundaries[i], stage_boundaries[i+1], \n",
        "               alpha=0.2, color=stage_colors[stage_name])\n",
        "\n",
        "ax1.set_ylabel('BPM', fontsize=12)\n",
        "ax1.set_title('治疗过程中的音乐节拍变化', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(40, 120)\n",
        "\n",
        "# 音量变化\n",
        "ax2.plot(times, trajectory_volumes, 'green', linewidth=3, marker='s', markersize=2)\n",
        "ax2.fill_between(times, trajectory_volumes, alpha=0.3, color='green')\n",
        "\n",
        "# 标记ISO阶段\n",
        "for i in range(len(stage_boundaries)-1):\n",
        "    stage_name = list(stage_colors.keys())[i]\n",
        "    ax2.axvspan(stage_boundaries[i], stage_boundaries[i+1], \n",
        "               alpha=0.2, color=stage_colors[stage_name])\n",
        "\n",
        "ax2.set_xlabel('时间 (分钟)', fontsize=12)\n",
        "ax2.set_ylabel('音量', fontsize=12)\n",
        "ax2.set_title('治疗过程中的音量变化', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(20, 80)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBPM变化: {trajectory_bpms[0]:.0f} → {trajectory_bpms[-1]:.0f} (降低 {trajectory_bpms[0]-trajectory_bpms[-1]:.0f})\")\n",
        "print(f\"音量变化: {trajectory_volumes[0]:.0f} → {trajectory_volumes[-1]:.0f} (降低 {trajectory_volumes[0]-trajectory_volumes[-1]:.0f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. 理论一致性验证\n",
        "print(\"\\n🔬 理论模型一致性验证...\")\n",
        "\n",
        "# 验证点1: 情绪变化的合理性\n",
        "emotion_change = abs(target_emotion.valence - current_emotion.valence) + abs(target_emotion.arousal - current_emotion.arousal)\n",
        "reasonable_change = emotion_change < 2.5  # 变化不应过于剧烈\n",
        "\n",
        "# 验证点2: ISO阶段时长分配\n",
        "guidance_longest = stages[1]['duration'] >= max(stages[0]['duration'], stages[2]['duration'])\n",
        "\n",
        "# 验证点3: 音乐参数与情绪的对应关系\n",
        "bpm_decreases = trajectory_bpms[0] > trajectory_bpms[-1]  # BPM应该降低（放松）\n",
        "volume_decreases = trajectory_volumes[0] > trajectory_volumes[-1]  # 音量应该降低\n",
        "\n",
        "# 验证点4: 轨迹平滑性\n",
        "valence_changes = [abs(valences[i+1] - valences[i]) for i in range(len(valences)-1)]\n",
        "arousal_changes = [abs(arousals[i+1] - arousals[i]) for i in range(len(arousals)-1)]\n",
        "smooth_trajectory = max(valence_changes + arousal_changes) < 0.1  # 变化应该平滑\n",
        "\n",
        "# 验证点5: 目标达成度\n",
        "final_emotion = trajectory[-1]['emotion']\n",
        "target_reached = final_emotion.distance_to(target_emotion) < 0.1\n",
        "\n",
        "# 计算一致性得分\n",
        "consistency_checks = [\n",
        "    ('情绪变化合理性', reasonable_change),\n",
        "    ('ISO阶段分配合理', guidance_longest),\n",
        "    ('BPM递减趋势', bpm_decreases),\n",
        "    ('音量递减趋势', volume_decreases),\n",
        "    ('轨迹平滑性', smooth_trajectory),\n",
        "    ('目标达成度', target_reached)\n",
        "]\n",
        "\n",
        "print(\"=== 一致性验证结果 ===\")\n",
        "passed_checks = 0\n",
        "for check_name, result in consistency_checks:\n",
        "    status = \"✅ 通过\" if result else \"❌ 未通过\"\n",
        "    print(f\"{check_name}: {status}\")\n",
        "    if result:\n",
        "        passed_checks += 1\n",
        "\n",
        "consistency_score = passed_checks / len(consistency_checks)\n",
        "print(f\"\\n🎯 总体一致性得分: {consistency_score:.1%}\")\n",
        "\n",
        "if consistency_score >= 0.8:\n",
        "    print(\"🎉 理论模型高度一致，验证通过！\")\n",
        "elif consistency_score >= 0.6:\n",
        "    print(\"⚠️ 理论模型基本一致，有改进空间\")\n",
        "else:\n",
        "    print(\"❗ 理论模型存在不一致，需要调整\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. 保存验证结果\n",
        "import json\n",
        "\n",
        "# 准备验证结果数据\n",
        "validation_results = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'test_scenario': {\n",
        "        'current_emotion': {\n",
        "            'valence': current_emotion.valence,\n",
        "            'arousal': current_emotion.arousal,\n",
        "            'quadrant': current_quadrant.value,\n",
        "            'basic_emotion': current_basic\n",
        "        },\n",
        "        'target_emotion': {\n",
        "            'valence': target_emotion.valence,\n",
        "            'arousal': target_emotion.arousal,\n",
        "            'quadrant': target_quadrant.value,\n",
        "            'basic_emotion': target_basic\n",
        "        },\n",
        "        'emotion_distance': current_emotion.distance_to(target_emotion)\n",
        "    },\n",
        "    'iso_planning': {\n",
        "        'total_duration': total_duration,\n",
        "        'stage_count': len(stages),\n",
        "        'trajectory_points': len(trajectory)\n",
        "    },\n",
        "    'music_therapy': {\n",
        "        'bpm_range': (min(trajectory_bpms), max(trajectory_bpms)),\n",
        "        'bpm_reduction': trajectory_bpms[0] - trajectory_bpms[-1],\n",
        "        'volume_reduction': trajectory_volumes[0] - trajectory_volumes[-1]\n",
        "    },\n",
        "    'consistency_validation': {\n",
        "        'checks_passed': passed_checks,\n",
        "        'total_checks': len(consistency_checks),\n",
        "        'consistency_score': consistency_score,\n",
        "        'validation_status': 'passed' if consistency_score >= 0.8 else 'warning' if consistency_score >= 0.6 else 'failed'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 确保输出目录存在\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == 'notebooks':\n",
        "    output_dir = current_dir.parent / 'outputs' / 'validation'\n",
        "else:\n",
        "    output_dir = current_dir / 'outputs' / 'validation'\n",
        "\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 保存结果\n",
        "result_file = output_dir / 'theory_models_validation.json'\n",
        "with open(result_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(validation_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n💾 验证结果已保存: {result_file}\")\n",
        "\n",
        "# 总结\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"《心境流转》理论模型演示完成\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n✅ 核心成果:\")\n",
        "print(f\"  • ISO三阶段规划: {len(stages)}个阶段，总时长{total_duration}分钟\")\n",
        "print(f\"  • 情绪轨迹生成: {len(trajectory)}个时间点，平滑过渡\")\n",
        "print(f\"  • VA象限分析: {current_quadrant.value} → {target_quadrant.value}\")\n",
        "print(f\"  • 音乐治疗参数: BPM {trajectory_bpms[0]:.0f}→{trajectory_bpms[-1]:.0f}\")\n",
        "print(f\"  • 一致性验证: {consistency_score:.1%} ({passed_checks}/{len(consistency_checks)}项通过)\")\n",
        "\n",
        "print(f\"\\n🚀 下一步: 运行 03_model_adapters_test.ipynb 测试AI模型集成\")\n",
        "print(f\"完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",\n      "language": "python",\n      "name": "python3"\n    },\n    "language_info": {\n      "codemirror_mode": {\n        "name": "ipython",\n        "version": 3\n      },\n      "file_extension": ".py",\n      "mimetype": "text/x-python",\n      "name": "python",\n      "nbconvert_exporter": "python",\n      "pygments_lexer": "ipython3",\n      "version": "3.11.7"\n    }\n  },\n  "nbformat": 4,\n  "nbformat_minor": 4\n}