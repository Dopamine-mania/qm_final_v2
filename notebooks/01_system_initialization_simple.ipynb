{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿåˆå§‹åŒ– - JupyterHubä¼˜åŒ–ç‰ˆ\n",
    "\n",
    "æœ¬notebookæ˜¯ä¸“ä¸ºJupyterHubç¯å¢ƒä¼˜åŒ–çš„ç®€åŒ–ç‰ˆåˆå§‹åŒ–è„šæœ¬ã€‚\n",
    "\n",
    "## ğŸ¯ ç›®æ ‡\n",
    "- å¿«é€ŸéªŒè¯JupyterHubç¯å¢ƒ\n",
    "- è‡ªåŠ¨åˆ›å»ºæ‰€éœ€çš„Mockæ¨¡å—\n",
    "- ç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿæ­£å¸¸è¿è¡Œ\n",
    "\n",
    "## âš ï¸ é‡è¦æç¤º\n",
    "- æ­¤ç‰ˆæœ¬ä¸“ä¸ºå­¦æ ¡æœåŠ¡å™¨ç¯å¢ƒè®¾è®¡\n",
    "- ä½¿ç”¨Mockæ¨¡å—ç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§\n",
    "- ä¼˜å…ˆè€ƒè™‘å…¼å®¹æ€§è€Œéå®Œæ•´åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŸºç¡€ç¯å¢ƒè®¾ç½®\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=" * 60)\n",
    "print(\"ã€Šå¿ƒå¢ƒæµè½¬ã€‹JupyterHubåˆå§‹åŒ–\")\n",
    "print(\"=" * 60)\n",
    "\n",
    "# æ™ºèƒ½é¡¹ç›®æ ¹ç›®å½•æ£€æµ‹\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    PROJECT_ROOT = current_dir.parent\n",
    "elif (current_dir / 'notebooks').exists():\n",
    "    PROJECT_ROOT = current_dir\n",
    "else:\n",
    "    # æŸ¥æ‰¾åŒ…å«é¡¹ç›®æ–‡ä»¶çš„ç›®å½•\n",
    "    PROJECT_ROOT = current_dir\n",
    "    for parent in current_dir.parents:\n",
    "        if (parent / 'notebooks').exists() or (parent / 'README.md').exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "print(f\"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}\")\n",
    "\n",
    "# æ·»åŠ Pythonè·¯å¾„\n",
    "paths_to_add = [str(PROJECT_ROOT), str(PROJECT_ROOT / 'src'), str(PROJECT_ROOT / 'research')]\n",
    "for path in paths_to_add:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "print(\"âœ… Pythonè·¯å¾„é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. å¿«é€Ÿç¡¬ä»¶æ£€æµ‹\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:\")\n",
    "print(f\"Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()}\")\n",
    "print(f\"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# GPUæ£€æµ‹\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"ğŸ® CUDAå¯ç”¨ï¼Œå‘ç° {gpu_count} ä¸ªGPU\")\n",
    "        \n",
    "        for i in range(gpu_count):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            memory_gb = props.total_memory / (1024**3)\n",
    "            print(f\"  GPU {i}: {props.name} ({memory_gb:.1f} GB)\")\n",
    "    else:\n",
    "        print(\"ğŸ’» ä½¿ç”¨CPUæ¨¡å¼\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorchæœªå®‰è£…\")\n",
    "\n",
    "# å†…å­˜æ£€æµ‹\n",
    "try:\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    memory_gb = memory.total / (1024**3)\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    print(f\"ğŸ’¾ å†…å­˜: {memory_gb:.1f} GB\")\n",
    "    print(f\"ğŸ”§ CPUæ ¸å¿ƒ: {cpu_count}\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’¾ å†…å­˜ä¿¡æ¯ä¸å¯ç”¨\")\n",
    "\n",
    "print(\"âœ… ç¡¬ä»¶æ£€æµ‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. åˆ›å»ºé¡¹ç›®ç»“æ„\n",
    "print(\"\\nğŸ“ åˆ›å»ºé¡¹ç›®ç»“æ„...\")\n",
    "\n",
    "# å¿…è¦çš„ç›®å½•ç»“æ„\n",
    "directories = [\n",
    "    'src',\n",
    "    'src/core',\n",
    "    'src/models', \n",
    "    'src/therapy',\n",
    "    'src/optimization',\n",
    "    'src/evaluation',\n",
    "    'research',\n",
    "    'research/theory',\n",
    "    'outputs',\n",
    "    'outputs/cache',\n",
    "    'outputs/logs',\n",
    "    'configs',\n",
    "    'api'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    dir_path = PROJECT_ROOT / directory\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    if directory.startswith('src/') or directory.startswith('research/'):\n",
    "        init_file = dir_path / '__init__.py'\n",
    "        if not init_file.exists():\n",
    "            init_file.touch()\n",
    "\n",
    "print(\"âœ… é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "os.environ['PROJECT_ROOT'] = str(PROJECT_ROOT)\n",
    "cache_dir = PROJECT_ROOT / 'outputs' / 'cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = str(cache_dir / 'transformers')\n",
    "os.environ['HF_HOME'] = str(cache_dir / 'huggingface')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. åˆ›å»ºç®€åŒ–çš„ç†è®ºæ¨¡å—\n",
    "print(\"\\nğŸ“š åˆ›å»ºç†è®ºæ¨¡å—...\")\n",
    "\n",
    "# ISOåŸåˆ™æ¨¡å—\n",
    "iso_content = '''\n",
    "\"\"\"ISOä¸‰é˜¶æ®µæ²»ç–—åŸåˆ™ - JupyterHubç‰ˆæœ¬\"\"\"\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "@dataclass\n",
    "class EmotionState:\n",
    "    valence: float  # -1åˆ°1ï¼Œè´Ÿå€¼è¡¨ç¤ºæ¶ˆææƒ…ç»ª\n",
    "    arousal: float  # 0åˆ°1ï¼Œè¡¨ç¤ºå”¤é†’ç¨‹åº¦\n",
    "    confidence: float = 0.8\n",
    "\n",
    "class ISOPrinciple:\n",
    "    \"\"\"ISOä¸‰é˜¶æ®µæ²»ç–—åŸåˆ™\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stages = ['synchronization', 'guidance', 'consolidation']\n",
    "        print(\"ğŸµ ISOä¸‰é˜¶æ®µæ²»ç–—åŸåˆ™åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    def plan_therapy_stages(self, current_emotion: EmotionState, target_emotion: EmotionState) -> List[Dict]:\n",
    "        \"\"\"è§„åˆ’æ²»ç–—é˜¶æ®µ\"\"\"\n",
    "        return [\n",
    "            {'stage': 'synchronization', 'duration': 10, 'description': 'åŒæ­¥å½“å‰æƒ…ç»ª'},\n",
    "            {'stage': 'guidance', 'duration': 15, 'description': 'å¼•å¯¼æƒ…ç»ªè½¬æ¢'}, \n",
    "            {'stage': 'consolidation', 'duration': 5, 'description': 'å·©å›ºç›®æ ‡æƒ…ç»ª'}\n",
    "        ]\n",
    "'''\n",
    "\n",
    "iso_file = PROJECT_ROOT / 'research' / 'theory' / 'iso_principle.py'\n",
    "with open(iso_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(iso_content)\n",
    "\n",
    "# VAæ¨¡å‹æ¨¡å—\n",
    "va_content = '''\n",
    "\"\"\"æƒ…ç»ªä»·å€¼-å”¤é†’æ¨¡å‹ - JupyterHubç‰ˆæœ¬\"\"\"\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "class ValenceArousalModel:\n",
    "    \"\"\"æƒ…ç»ªä»·å€¼-å”¤é†’äºŒç»´æ¨¡å‹\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.emotion_map = {\n",
    "            'happy': (0.8, 0.7), 'calm': (0.5, 0.2), 'sad': (-0.6, 0.3),\n",
    "            'angry': (-0.3, 0.8), 'anxious': (-0.4, 0.9), 'peaceful': (0.7, 0.1)\n",
    "        }\n",
    "        print(\"ğŸ“Š V-Aæƒ…ç»ªæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    def get_emotion_coordinates(self, emotion: str) -> Tuple[float, float]:\n",
    "        \"\"\"è·å–æƒ…ç»ªåœ¨VAç©ºé—´ä¸­çš„åæ ‡\"\"\"\n",
    "        return self.emotion_map.get(emotion, (0.0, 0.5))\n",
    "    \n",
    "    def map_to_emotion_space(self, valence: float, arousal: float) -> Dict:\n",
    "        \"\"\"å°†V-Aåæ ‡æ˜ å°„åˆ°æƒ…ç»ªç©ºé—´\"\"\"\n",
    "        return {\"valence\": valence, \"arousal\": arousal, \"quadrant\": self._get_quadrant(valence, arousal)}\n",
    "    \n",
    "    def _get_quadrant(self, valence: float, arousal: float) -> str:\n",
    "        if valence > 0 and arousal > 0.5:\n",
    "            return \"excited\"\n",
    "        elif valence > 0 and arousal <= 0.5:\n",
    "            return \"peaceful\"\n",
    "        elif valence <= 0 and arousal > 0.5:\n",
    "            return \"distressed\"\n",
    "        else:\n",
    "            return \"depressed\"\n",
    "'''\n",
    "\n",
    "va_file = PROJECT_ROOT / 'research' / 'theory' / 'valence_arousal.py'\n",
    "with open(va_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(va_content)\n",
    "\n",
    "print(\"âœ… ç†è®ºæ¨¡å—åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. åˆ›å»ºæ¨¡å‹é€‚é…å™¨\n",
    "print(\"\\nğŸ¤– åˆ›å»ºæ¨¡å‹é€‚é…å™¨...\")\n",
    "\n",
    "# åŸºç¡€é€‚é…å™¨\n",
    "base_content = '''\n",
    "\"\"\"åŸºç¡€æ¨¡å‹é€‚é…å™¨ - JupyterHubç‰ˆæœ¬\"\"\"\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    model_type: str\n",
    "    device: str = \"cpu\"\n",
    "    precision: str = \"float32\"\n",
    "\n",
    "class BaseModelAdapter:\n",
    "    \"\"\"åŸºç¡€æ¨¡å‹é€‚é…å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.is_loaded = False\n",
    "        print(f\"ğŸ”§ æ¨¡å‹é€‚é…å™¨åˆå§‹åŒ–: {config.model_name}\")\n",
    "    \n",
    "    def load_model(self) -> bool:\n",
    "        \"\"\"åŠ è½½æ¨¡å‹\"\"\"\n",
    "        print(f\"ğŸ“¥ æ¨¡æ‹ŸåŠ è½½æ¨¡å‹: {self.config.model_name}\")\n",
    "        self.is_loaded = True\n",
    "        return True\n",
    "    \n",
    "    def predict(self, input_data: Any) -> Dict[str, Any]:\n",
    "        \"\"\"æ¨¡å‹é¢„æµ‹\"\"\"\n",
    "        return {\"result\": \"mock_prediction\", \"confidence\": 0.85}\n",
    "'''\n",
    "\n",
    "base_file = PROJECT_ROOT / 'src' / 'models' / 'base.py'\n",
    "with open(base_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(base_content)\n",
    "\n",
    "# æ¨¡å‹å·¥å‚\n",
    "factory_content = '''\n",
    "\"\"\"æ¨¡å‹å·¥å‚ - JupyterHubç‰ˆæœ¬\"\"\"\n",
    "from typing import Dict, List\n",
    "from .base import BaseModelAdapter, ModelConfig\n",
    "\n",
    "class ModelFactory:\n",
    "    \"\"\"æ¨¡å‹å·¥å‚\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.available_models = {\n",
    "            'emotion_text': 'cardiffnlp/twitter-roberta-base-emotion',\n",
    "            'emotion_audio': 'facebook/wav2vec2-base-960h',\n",
    "            'music_generation': 'facebook/musicgen-small',\n",
    "            'video_generation': 'mock_video_model'\n",
    "        }\n",
    "        print(\"ğŸ­ æ¨¡å‹å·¥å‚åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    def create_model_adapter(self, model_type: str) -> BaseModelAdapter:\n",
    "        \"\"\"åˆ›å»ºæ¨¡å‹é€‚é…å™¨\"\"\"\n",
    "        model_name = self.available_models.get(model_type, f\"mock_{model_type}\")\n",
    "        config = ModelConfig(model_name=model_name, model_type=model_type)\n",
    "        return BaseModelAdapter(config)\n",
    "    \n",
    "    def get_recommended_models(self) -> Dict:\n",
    "        \"\"\"è·å–æ¨èæ¨¡å‹é…ç½®\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "                if gpu_memory >= 40:\n",
    "                    profile = \"gpu_40gb\"\n",
    "                else:\n",
    "                    profile = \"gpu_low\"\n",
    "            else:\n",
    "                profile = \"cpu_only\"\n",
    "        except:\n",
    "            profile = \"cpu_only\"\n",
    "        \n",
    "        return {\n",
    "            \"profile\": profile,\n",
    "            \"recommended\": self.available_models\n",
    "        }\n",
    "'''\n",
    "\n",
    "factory_file = PROJECT_ROOT / 'src' / 'models' / 'factory.py'\n",
    "with open(factory_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(factory_content)\n",
    "\n",
    "print(\"âœ… æ¨¡å‹é€‚é…å™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. åˆ›å»ºç–—æ„ˆç³»ç»Ÿ\n",
    "print(\"\\nğŸ§˜ åˆ›å»ºç–—æ„ˆç³»ç»Ÿ...\")\n",
    "\n",
    "# ç–—æ„ˆæ ¸å¿ƒ\n",
    "therapy_content = '''\n",
    "\"\"\"ç–—æ„ˆç³»ç»Ÿæ ¸å¿ƒ - JupyterHubç‰ˆæœ¬\"\"\"\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "import uuid\n",
    "\n",
    "class TherapySession:\n",
    "    \"\"\"ç–—æ„ˆä¼šè¯\"\"\"\n",
    "    \n",
    "    def __init__(self, user_id: str, current_emotion: Dict, target_emotion: Dict):\n",
    "        self.session_id = str(uuid.uuid4())[:8]\n",
    "        self.user_id = user_id\n",
    "        self.start_time = datetime.now()\n",
    "        self.current_emotion = current_emotion\n",
    "        self.target_emotion = target_emotion\n",
    "        self.status = \"active\"\n",
    "\n",
    "class TherapyOrchestrator:\n",
    "    \"\"\"ç–—æ„ˆç¼–æ’å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_sessions = {}\n",
    "        print(\"ğŸ§˜ ç–—æ„ˆç¼–æ’å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    def create_session(self, user_id: str, current_emotion: Dict, target_emotion: Dict) -> TherapySession:\n",
    "        \"\"\"åˆ›å»ºç–—æ„ˆä¼šè¯\"\"\"\n",
    "        session = TherapySession(user_id, current_emotion, target_emotion)\n",
    "        self.active_sessions[session.session_id] = session\n",
    "        print(f\"ğŸ¯ åˆ›å»ºç–—æ„ˆä¼šè¯: {session.session_id}\")\n",
    "        return session\n",
    "    \n",
    "    def get_session_recommendations(self, session_id: str) -> Dict:\n",
    "        \"\"\"è·å–ä¼šè¯æ¨è\"\"\"\n",
    "        if session_id not in self.active_sessions:\n",
    "            return {\"error\": \"Session not found\"}\n",
    "        \n",
    "        session = self.active_sessions[session_id]\n",
    "        return {\n",
    "            \"session_id\": session_id,\n",
    "            \"recommendations\": {\n",
    "                \"music_style\": \"ambient\",\n",
    "                \"tempo_bpm\": 60,\n",
    "                \"video_theme\": \"nature\",\n",
    "                \"duration_minutes\": 30\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PrescriptionEngine:\n",
    "    \"\"\"å¤„æ–¹å¼•æ“\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"ğŸ’Š å¤„æ–¹å¼•æ“åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    def generate_prescription(self, user_profile: Dict, current_emotion: Dict, target_emotion: Dict) -> Dict:\n",
    "        \"\"\"ç”Ÿæˆæ²»ç–—å¤„æ–¹\"\"\"\n",
    "        prescription_id = f\"rx_{hash(str(current_emotion)) % 10000:04d}\"\n",
    "        \n",
    "        return {\n",
    "            \"prescription_id\": prescription_id,\n",
    "            \"user_profile\": user_profile,\n",
    "            \"current_emotion\": current_emotion,\n",
    "            \"target_emotion\": target_emotion,\n",
    "            \"recommendations\": {\n",
    "                \"music\": {\"genre\": \"ambient\", \"tempo_bpm\": (40, 70)},\n",
    "                \"video\": {\"theme\": \"nature\", \"style\": \"soft_transitions\"},\n",
    "                \"session\": {\"duration_minutes\": 25}\n",
    "            },\n",
    "            \"confidence_score\": 0.85\n",
    "        }\n",
    "'''\n",
    "\n",
    "therapy_file = PROJECT_ROOT / 'src' / 'therapy' / 'core.py'\n",
    "with open(therapy_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(therapy_content)\n",
    "\n",
    "print(\"âœ… ç–—æ„ˆç³»ç»Ÿåˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. æµ‹è¯•æ‰€æœ‰æ¨¡å—\n",
    "print(\"\\nğŸ§ª æµ‹è¯•ç³»ç»Ÿæ¨¡å—...\")\n",
    "\n",
    "# é‡æ–°åŠ è½½sys.path\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# æ¸…ç†å¯èƒ½çš„ç¼“å­˜\n",
    "modules_to_clear = [name for name in sys.modules.keys() if name.startswith('research.') or name.startswith('src.')]\n",
    "for module_name in modules_to_clear:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "# æµ‹è¯•ç†è®ºæ¨¡å—\n",
    "theory_success = False\n",
    "try:\n",
    "    from research.theory.iso_principle import ISOPrinciple, EmotionState\n",
    "    from research.theory.valence_arousal import ValenceArousalModel\n",
    "    \n",
    "    # åŠŸèƒ½æµ‹è¯•\n",
    "    emotion_state = EmotionState(valence=-0.2, arousal=0.6, confidence=0.8)\n",
    "    iso_planner = ISOPrinciple()\n",
    "    va_model = ValenceArousalModel()\n",
    "    \n",
    "    print(f\"âœ… ç†è®ºæ¨¡å—: ISOåŸåˆ™ + VAæ¨¡å‹\")\n",
    "    theory_success = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç†è®ºæ¨¡å—: {e}\")\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹é€‚é…å™¨\n",
    "models_success = False\n",
    "try:\n",
    "    from src.models.factory import ModelFactory\n",
    "    from src.models.base import BaseModelAdapter, ModelConfig\n",
    "    \n",
    "    factory = ModelFactory()\n",
    "    recommendations = factory.get_recommended_models()\n",
    "    adapter = factory.create_model_adapter('emotion_text')\n",
    "    \n",
    "    print(f\"âœ… æ¨¡å‹é€‚é…å™¨: å·¥å‚ + é€‚é…å™¨ ({recommendations['profile']})\")\n",
    "    models_success = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹é€‚é…å™¨: {e}\")\n",
    "\n",
    "# æµ‹è¯•ç–—æ„ˆç³»ç»Ÿ\n",
    "therapy_success = False\n",
    "try:\n",
    "    from src.therapy.core import TherapyOrchestrator, PrescriptionEngine, TherapySession\n",
    "    \n",
    "    orchestrator = TherapyOrchestrator()\n",
    "    prescription_engine = PrescriptionEngine()\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ä¼šè¯\n",
    "    test_session = orchestrator.create_session(\n",
    "        \"test_user\",\n",
    "        {\"valence\": -0.4, \"arousal\": 0.8},\n",
    "        {\"valence\": 0.6, \"arousal\": 0.3}\n",
    "    )\n",
    "    \n",
    "    recommendations = orchestrator.get_session_recommendations(test_session.session_id)\n",
    "    prescription = prescription_engine.generate_prescription(\n",
    "        {\"user_type\": \"student\"}, \n",
    "        {\"valence\": -0.4, \"arousal\": 0.8}, \n",
    "        {\"valence\": 0.6, \"arousal\": 0.3}\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ç–—æ„ˆç³»ç»Ÿ: ç¼–æ’å™¨ + å¤„æ–¹å¼•æ“ (ä¼šè¯: {test_session.session_id})\")\n",
    "    therapy_success = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç–—æ„ˆç³»ç»Ÿ: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“Š æ¨¡å—æµ‹è¯•æ€»ç»“:\")\n",
    "print(f\"  ç†è®ºæ¨¡å—: {'âœ… æ­£å¸¸' if theory_success else 'âŒ å¼‚å¸¸'}\")\n",
    "print(f\"  æ¨¡å‹é€‚é…å™¨: {'âœ… æ­£å¸¸' if models_success else 'âŒ å¼‚å¸¸'}\")\n",
    "print(f\"  ç–—æ„ˆç³»ç»Ÿ: {'âœ… æ­£å¸¸' if therapy_success else 'âŒ å¼‚å¸¸'}\")\n",
    "\n",
    "all_success = theory_success and models_success and therapy_success\n",
    "print(f\"\\nğŸ¯ æ•´ä½“çŠ¶æ€: {'âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ' if all_success else 'âš ï¸ éƒ¨åˆ†æ¨¡å—å¼‚å¸¸'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ä¿å­˜åˆå§‹åŒ–çŠ¶æ€\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# æ”¶é›†ç³»ç»Ÿä¿¡æ¯\n",
    "system_info = {\n",
    "    \"initialization_time\": datetime.now().isoformat(),\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"platform\": platform.system(),\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"modules\": {\n",
    "        \"theory_modules\": theory_success,\n",
    "        \"model_adapters\": models_success,\n",
    "        \"therapy_system\": therapy_success\n",
    "    },\n",
    "    \"hardware\": {},\n",
    "    \"status\": \"success\" if all_success else \"partial\"\n",
    "}\n",
    "\n",
    "# GPUä¿¡æ¯\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        gpu_info = []\n",
    "        for i in range(gpu_count):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            gpu_info.append({\n",
    "                \"name\": props.name,\n",
    "                \"memory_gb\": round(props.total_memory / (1024**3), 1)\n",
    "            })\n",
    "        system_info[\"hardware\"][\"gpu\"] = {\"available\": True, \"devices\": gpu_info}\n",
    "    else:\n",
    "        system_info[\"hardware\"][\"gpu\"] = {\"available\": False}\n",
    "except:\n",
    "    system_info[\"hardware\"][\"gpu\"] = {\"available\": False}\n",
    "\n",
    "# å†…å­˜ä¿¡æ¯\n",
    "try:\n",
    "    import psutil\n",
    "    memory = psutil.virtual_memory()\n",
    "    system_info[\"hardware\"][\"memory\"] = {\n",
    "        \"total_gb\": round(memory.total / (1024**3), 1),\n",
    "        \"available_gb\": round(memory.available / (1024**3), 1),\n",
    "        \"cpu_cores\": psutil.cpu_count()\n",
    "    }\n",
    "except:\n",
    "    system_info[\"hardware\"][\"memory\"] = {\"available\": False}\n",
    "\n",
    "# ä¿å­˜çŠ¶æ€æ–‡ä»¶\n",
    "status_file = PROJECT_ROOT / 'outputs' / 'initialization_status.json'\n",
    "with open(status_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(system_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ åˆå§‹åŒ–çŠ¶æ€å·²ä¿å­˜: {status_file}\")\n",
    "\n",
    "# æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ã€Šå¿ƒå¢ƒæµè½¬ã€‹JupyterHubåˆå§‹åŒ–å®Œæˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if all_success:\n",
    "    print(\"ğŸ‰ æ‰€æœ‰æ¨¡å—åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "    print(\"\\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:\")\n",
    "    print(\"  1. è¿è¡Œ 02_theory_models_demo.ipynb\")\n",
    "    print(\"  2. è¿è¡Œ 03_model_adapters_test.ipynb\")\n",
    "    print(\"  3. è¿è¡Œ 04_therapy_session_demo.ipynb\")\n",
    "else:\n",
    "    print(\"âš ï¸  éƒ¨åˆ†æ¨¡å—å­˜åœ¨é—®é¢˜ï¼Œä½†åŸºç¡€åŠŸèƒ½å¯ç”¨\")\n",
    "    print(\"ğŸ’¡ å¯ä»¥ç»§ç»­è¿›è¡Œåç»­æµ‹è¯•\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç³»ç»Ÿé…ç½®:\")\n",
    "print(f\"  é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}\")\n",
    "print(f\"  ç¼“å­˜ç›®å½•: {cache_dir}\")\n",
    "print(f\"  åˆå§‹åŒ–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nâœ… åˆå§‹åŒ–å®Œæˆï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}