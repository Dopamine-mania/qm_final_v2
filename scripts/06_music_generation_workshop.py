#!/usr/bin/env python3
"""
06 - éŸ³ä¹ç”Ÿæˆå·¥ä½œåŠ
å±•ç¤ºAIéŸ³ä¹ç”Ÿæˆåœ¨ç¡çœ æ²»ç–—ä¸­çš„åº”ç”¨
"""

import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from pathlib import Path
import json
import wave
import struct
import warnings
warnings.filterwarnings('ignore')

# é…ç½®matplotlib
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class MusicTheoryEngine:
    """éŸ³ä¹ç†è®ºå¼•æ“"""
    
    def __init__(self):
        # éŸ³ç¬¦é¢‘ç‡è¡¨ (A4 = 440Hz)
        self.note_frequencies = {
            'C4': 261.63, 'D4': 293.66, 'E4': 329.63, 'F4': 349.23,
            'G4': 392.00, 'A4': 440.00, 'B4': 493.88,
            'C5': 523.25, 'D5': 587.33, 'E5': 659.25, 'F5': 698.46,
            'G5': 783.99, 'A5': 880.00, 'B5': 987.77
        }
        
        # å’Œå¼¦å®šä¹‰
        self.chord_patterns = {
            'major': [0, 4, 7],      # å¤§ä¸‰å’Œå¼¦
            'minor': [0, 3, 7],      # å°ä¸‰å’Œå¼¦
            'dim': [0, 3, 6],        # å‡ä¸‰å’Œå¼¦
            'sus4': [0, 5, 7],       # æŒ‚å››å’Œå¼¦
            'maj7': [0, 4, 7, 11],   # å¤§ä¸ƒå’Œå¼¦
            'min7': [0, 3, 7, 10]    # å°ä¸ƒå’Œå¼¦
        }
        
        # ç¡çœ éŸ³ä¹å’Œå¼¦è¿›è¡Œ
        self.sleep_progressions = [
            ['C', 'Am', 'F', 'G'],           # I-vi-IV-V
            ['Am', 'F', 'C', 'G'],           # vi-IV-I-V
            ['C', 'G', 'Am', 'F'],           # I-V-vi-IV
            ['F', 'G', 'C', 'Am'],           # IV-V-I-vi
            ['Dm', 'G', 'C', 'F'],           # ii-V-I-IV
            ['C', 'Em', 'F', 'C']            # I-iii-IV-I
        ]
    
    def get_scale_notes(self, root='C', scale_type='major'):
        """è·å–éŸ³é˜¶éŸ³ç¬¦"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåªå®ç°å¤§è°ƒå’Œè‡ªç„¶å°è°ƒ
        intervals = {
            'major': [0, 2, 4, 5, 7, 9, 11],
            'minor': [0, 2, 3, 5, 7, 8, 10]
        }
        
        # è·å–æ ¹éŸ³ç´¢å¼•
        note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
        root_idx = note_names.index(root)
        
        # ç”ŸæˆéŸ³é˜¶
        scale = []
        for interval in intervals[scale_type]:
            note_idx = (root_idx + interval) % 12
            scale.append(note_names[note_idx])
        
        return scale
    
    def generate_melody(self, scale_notes, num_bars=8, notes_per_bar=4):
        """ç”Ÿæˆæ—‹å¾‹"""
        melody = []
        
        # ä½¿ç”¨ç®€å•çš„è§„åˆ™ç”Ÿæˆèˆ’ç¼“çš„æ—‹å¾‹
        for bar in range(num_bars):
            for beat in range(notes_per_bar):
                if beat == 0:  # å¼ºæ‹
                    # å€¾å‘äºä½¿ç”¨æ ¹éŸ³ã€ä¸‰éŸ³ã€äº”éŸ³
                    note_idx = np.random.choice([0, 2, 4], p=[0.5, 0.3, 0.2])
                else:
                    # å¼±æ‹ä½¿ç”¨ä¸´è¿‘éŸ³ç¬¦
                    if melody:
                        last_idx = scale_notes.index(melody[-1]['note']) if melody[-1]['note'] in scale_notes else 0
                        # ä¸Šä¸‹çº§è¿›
                        step = np.random.choice([-2, -1, 0, 1, 2], p=[0.1, 0.3, 0.2, 0.3, 0.1])
                        note_idx = (last_idx + step) % len(scale_notes)
                    else:
                        note_idx = np.random.choice(range(len(scale_notes)))
                
                # æ·»åŠ éŸ³ç¬¦
                melody.append({
                    'note': scale_notes[note_idx],
                    'duration': 0.5 if beat % 2 == 0 else 0.25,  # èŠ‚å¥å˜åŒ–
                    'velocity': 0.7 - bar * 0.05  # æ¸å¼±
                })
        
        return melody

class SleepMusicGenerator:
    """ç¡çœ éŸ³ä¹ç”Ÿæˆå™¨"""
    
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        self.theory_engine = MusicTheoryEngine()
    
    def generate_sine_wave(self, frequency, duration, amplitude=0.5):
        """ç”Ÿæˆæ­£å¼¦æ³¢"""
        t = np.linspace(0, duration, int(self.sample_rate * duration))
        return amplitude * np.sin(2 * np.pi * frequency * t)
    
    def apply_envelope(self, signal, attack=0.01, decay=0.1, sustain=0.7, release=0.2):
        """åº”ç”¨ADSRåŒ…ç»œ"""
        total_length = len(signal)
        attack_samples = int(attack * self.sample_rate)
        decay_samples = int(decay * self.sample_rate)
        release_samples = int(release * self.sample_rate)
        sustain_samples = total_length - attack_samples - decay_samples - release_samples
        
        envelope = np.ones_like(signal)
        
        # Attack
        envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
        
        # Decay
        decay_start = attack_samples
        decay_end = decay_start + decay_samples
        envelope[decay_start:decay_end] = np.linspace(1, sustain, decay_samples)
        
        # Sustain
        sustain_start = decay_end
        sustain_end = sustain_start + sustain_samples
        envelope[sustain_start:sustain_end] = sustain
        
        # Release
        if release_samples > 0:
            envelope[-release_samples:] = np.linspace(sustain, 0, release_samples)
        
        return signal * envelope
    
    def add_reverb(self, signal, delay=0.02, decay=0.5):
        """æ·»åŠ ç®€å•æ··å“æ•ˆæœ"""
        delay_samples = int(delay * self.sample_rate)
        reverb = np.zeros_like(signal)
        
        # æ·»åŠ å¤šä¸ªå»¶è¿Ÿå›å£°
        for i in range(3):
            delay_time = delay_samples * (i + 1)
            decay_factor = decay ** (i + 1)
            if delay_time < len(signal):
                reverb[delay_time:] += signal[:-delay_time] * decay_factor
        
        return signal + reverb * 0.3
    
    def synthesize_note(self, note_name, duration, octave=4):
        """åˆæˆå•ä¸ªéŸ³ç¬¦"""
        # è·å–åŸºç¡€é¢‘ç‡
        base_note = note_name + str(octave)
        if base_note in self.theory_engine.note_frequencies:
            frequency = self.theory_engine.note_frequencies[base_note]
        else:
            # è®¡ç®—é¢‘ç‡
            frequency = 440.0  # é»˜è®¤A4
        
        # ç”ŸæˆåŸºç¡€æ³¢å½¢
        signal = self.generate_sine_wave(frequency, duration)
        
        # æ·»åŠ æ³›éŸ³
        signal += self.generate_sine_wave(frequency * 2, duration, 0.2)  # ç¬¬äºŒæ³›éŸ³
        signal += self.generate_sine_wave(frequency * 3, duration, 0.1)  # ç¬¬ä¸‰æ³›éŸ³
        
        # åº”ç”¨åŒ…ç»œ
        signal = self.apply_envelope(signal)
        
        return signal
    
    def generate_sleep_track(self, duration_minutes=2, bpm=60, key='C', mode='major'):
        """ç”Ÿæˆç¡çœ éŸ³ä¹è½¨é“"""
        print(f"\nğŸµ ç”Ÿæˆç¡çœ éŸ³ä¹")
        print(f"  æ—¶é•¿: {duration_minutes}åˆ†é’Ÿ")
        print(f"  é€Ÿåº¦: {bpm} BPM")
        print(f"  è°ƒæ€§: {key} {mode}")
        
        # è®¡ç®—å‚æ•°
        beat_duration = 60.0 / bpm
        total_beats = int(duration_minutes * 60 / beat_duration)
        
        # è·å–éŸ³é˜¶
        scale_notes = self.theory_engine.get_scale_notes(key, mode)
        
        # ç”Ÿæˆå’Œå¼¦è¿›è¡Œ
        progression = self.theory_engine.sleep_progressions[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¿›è¡Œ
        
        # åˆå§‹åŒ–éŸ³è½¨
        track_length = int(duration_minutes * 60 * self.sample_rate)
        track = np.zeros(track_length)
        
        # ç”Ÿæˆæ—‹å¾‹
        melody = self.theory_engine.generate_melody(scale_notes, num_bars=total_beats//4)
        
        # åˆæˆéŸ³ç¬¦
        current_pos = 0
        for i, note_info in enumerate(melody):
            if current_pos >= track_length:
                break
            
            # åˆæˆéŸ³ç¬¦
            note_duration = note_info['duration'] * beat_duration
            note_signal = self.synthesize_note(
                note_info['note'], 
                note_duration,
                octave=4 + (i % 2)  # éŸ³é«˜å˜åŒ–
            )
            
            # è°ƒæ•´éŸ³é‡
            note_signal *= note_info['velocity'] * 0.3
            
            # æ·»åŠ åˆ°éŸ³è½¨
            end_pos = min(current_pos + len(note_signal), track_length)
            track[current_pos:end_pos] += note_signal[:end_pos-current_pos]
            
            current_pos += int(note_duration * self.sample_rate * 0.9)  # è½»å¾®é‡å 
        
        # æ·»åŠ å’Œå¼¦å«åº•
        chord_track = self.generate_chord_pad(progression, duration_minutes, bpm, key)
        track += chord_track * 0.2
        
        # åå¤„ç†
        track = self.add_reverb(track)
        track = self.apply_fade(track, fade_in=5, fade_out=10)
        
        # å½’ä¸€åŒ–
        track = track / (np.max(np.abs(track)) + 1e-6) * 0.8
        
        return track
    
    def generate_chord_pad(self, progression, duration_minutes, bpm, key):
        """ç”Ÿæˆå’Œå¼¦å«åº•"""
        track_length = int(duration_minutes * 60 * self.sample_rate)
        pad = np.zeros(track_length)
        
        # æ¯ä¸ªå’Œå¼¦çš„æŒç»­æ—¶é—´
        chord_duration = 60.0 / bpm * 4  # 4æ‹ä¸€ä¸ªå’Œå¼¦
        samples_per_chord = int(chord_duration * self.sample_rate)
        
        current_pos = 0
        chord_idx = 0
        
        while current_pos < track_length:
            # è·å–å½“å‰å’Œå¼¦
            chord_name = progression[chord_idx % len(progression)]
            
            # ç”Ÿæˆå’Œå¼¦éŸ³ç¬¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            if 'm' in chord_name:
                chord_type = 'minor'
                root = chord_name.replace('m', '')
            else:
                chord_type = 'major'
                root = chord_name
            
            # ç”Ÿæˆå’Œå¼¦
            chord_signal = np.zeros(samples_per_chord)
            
            # æ ¹éŸ³
            root_freq = self.theory_engine.note_frequencies.get(root + '3', 261.63)
            chord_signal += self.generate_sine_wave(root_freq, chord_duration, 0.5)
            
            # ä¸‰éŸ³
            third_freq = root_freq * (1.25 if chord_type == 'major' else 1.2)
            chord_signal += self.generate_sine_wave(third_freq, chord_duration, 0.3)
            
            # äº”éŸ³
            fifth_freq = root_freq * 1.5
            chord_signal += self.generate_sine_wave(fifth_freq, chord_duration, 0.3)
            
            # åº”ç”¨åŒ…ç»œ
            chord_signal = self.apply_envelope(chord_signal, attack=0.5, release=0.5)
            
            # æ·»åŠ åˆ°å«åº•è½¨é“
            end_pos = min(current_pos + len(chord_signal), track_length)
            pad[current_pos:end_pos] += chord_signal[:end_pos-current_pos]
            
            current_pos += samples_per_chord
            chord_idx += 1
        
        return pad
    
    def apply_fade(self, signal, fade_in=2, fade_out=5):
        """åº”ç”¨æ·¡å…¥æ·¡å‡º"""
        fade_in_samples = int(fade_in * self.sample_rate)
        fade_out_samples = int(fade_out * self.sample_rate)
        
        # æ·¡å…¥
        if fade_in_samples > 0:
            signal[:fade_in_samples] *= np.linspace(0, 1, fade_in_samples)
        
        # æ·¡å‡º
        if fade_out_samples > 0:
            signal[-fade_out_samples:] *= np.linspace(1, 0, fade_out_samples)
        
        return signal
    
    def save_audio(self, signal, filename):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        # è½¬æ¢ä¸º16ä½æ•´æ•°
        signal_int = np.int16(signal * 32767)
        
        # å†™å…¥WAVæ–‡ä»¶
        with wave.open(filename, 'w') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(signal_int.tobytes())
    
    def visualize_waveform(self, signal, title="Waveform", output_path=None):
        """å¯è§†åŒ–æ³¢å½¢"""
        plt.figure(figsize=(12, 4))
        
        # é™é‡‡æ ·ä»¥ä¾¿æ˜¾ç¤º
        downsample = max(1, len(signal) // 10000)
        time_axis = np.arange(0, len(signal), downsample) / self.sample_rate
        signal_display = signal[::downsample]
        
        plt.plot(time_axis, signal_display, linewidth=0.5)
        plt.xlabel('Time (seconds)')
        plt.ylabel('Amplitude')
        plt.title(title)
        plt.grid(True, alpha=0.3)
        
        if output_path:
            plt.savefig(output_path)
        plt.close()

def run_music_workshop():
    """è¿è¡ŒéŸ³ä¹ç”Ÿæˆå·¥ä½œåŠ"""
    print("ã€Šå¿ƒå¢ƒæµè½¬ã€‹éŸ³ä¹ç”Ÿæˆå·¥ä½œåŠ")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = SleepMusicGenerator()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("outputs/music")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æµ‹è¯•ä¸åŒå‚æ•°çš„éŸ³ä¹ç”Ÿæˆ
    test_configs = [
        {
            "name": "æ·±åº¦æ”¾æ¾",
            "duration": 1,  # 1åˆ†é’Ÿæ¼”ç¤º
            "bpm": 50,
            "key": "C",
            "mode": "major",
            "description": "ææ…¢é€Ÿåº¦ï¼ŒCå¤§è°ƒï¼Œé€‚åˆæ·±åº¦æ”¾æ¾"
        },
        {
            "name": "æ¸©æŸ”å…¥çœ ",
            "duration": 1,
            "bpm": 60,
            "key": "F",
            "mode": "major",
            "description": "ç¼“æ…¢èŠ‚å¥ï¼ŒFå¤§è°ƒï¼Œè¥é€ æ¸©æš–æ°›å›´"
        },
        {
            "name": "å®é™å†¥æƒ³",
            "duration": 1,
            "bpm": 55,
            "key": "A",
            "mode": "minor",
            "description": "ä¸­æ…¢é€Ÿåº¦ï¼ŒAå°è°ƒï¼Œé€‚åˆå†¥æƒ³"
        }
    ]
    
    results = []
    
    for config in test_configs:
        print(f"\n{'='*40}")
        print(f"ğŸ¼ ç”Ÿæˆ: {config['name']}")
        print(f"è¯´æ˜: {config['description']}")
        
        # ç”ŸæˆéŸ³ä¹
        track = generator.generate_sleep_track(
            duration_minutes=config['duration'],
            bpm=config['bpm'],
            key=config['key'],
            mode=config['mode']
        )
        
        # ä¿å­˜éŸ³é¢‘
        audio_file = output_dir / f"{config['name'].replace(' ', '_')}.wav"
        generator.save_audio(track, str(audio_file))
        print(f"âœ… éŸ³é¢‘å·²ä¿å­˜: {audio_file}")
        
        # ç”Ÿæˆæ³¢å½¢å›¾
        waveform_file = output_dir / f"{config['name'].replace(' ', '_')}_waveform.png"
        generator.visualize_waveform(
            track[:int(10 * generator.sample_rate)],  # å‰10ç§’
            title=f"{config['name']} - Waveform",
            output_path=str(waveform_file)
        )
        print(f"âœ… æ³¢å½¢å›¾å·²ä¿å­˜: {waveform_file}")
        
        # åˆ†æéŸ³é¢‘ç‰¹å¾
        features = analyze_audio_features(track, generator.sample_rate)
        
        # è®°å½•ç»“æœ
        results.append({
            "name": config['name'],
            "config": config,
            "audio_file": str(audio_file),
            "waveform_file": str(waveform_file),
            "features": features
        })
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print_audio_analysis(results)
    
    # ä¿å­˜å·¥ä½œåŠç»“æœ
    save_workshop_results(results)
    
    return results

def analyze_audio_features(signal, sample_rate):
    """åˆ†æéŸ³é¢‘ç‰¹å¾"""
    # è®¡ç®—RMSèƒ½é‡
    rms = np.sqrt(np.mean(signal**2))
    
    # è®¡ç®—é¢‘è°±è´¨å¿ƒ
    fft = np.fft.fft(signal)
    magnitude = np.abs(fft[:len(fft)//2])
    frequencies = np.fft.fftfreq(len(signal), 1/sample_rate)[:len(magnitude)]
    spectral_centroid = np.sum(frequencies * magnitude) / np.sum(magnitude)
    
    # è®¡ç®—åŠ¨æ€èŒƒå›´
    dynamic_range = 20 * np.log10(np.max(np.abs(signal)) / (rms + 1e-6))
    
    return {
        "rms_energy": float(rms),
        "spectral_centroid": float(spectral_centroid),
        "dynamic_range_db": float(dynamic_range),
        "duration_seconds": len(signal) / sample_rate
    }

def print_audio_analysis(results):
    """æ‰“å°éŸ³é¢‘åˆ†æç»“æœ"""
    print("\nğŸ“Š éŸ³é¢‘ç‰¹å¾åˆ†æ")
    print("=" * 50)
    
    for result in results:
        print(f"\n{result['name']}:")
        features = result['features']
        print(f"  RMSèƒ½é‡: {features['rms_energy']:.4f}")
        print(f"  é¢‘è°±è´¨å¿ƒ: {features['spectral_centroid']:.1f} Hz")
        print(f"  åŠ¨æ€èŒƒå›´: {features['dynamic_range_db']:.1f} dB")
        print(f"  æ—¶é•¿: {features['duration_seconds']:.1f} ç§’")

def save_workshop_results(results):
    """ä¿å­˜å·¥ä½œåŠç»“æœ"""
    output_file = Path("outputs/music/workshop_results.json")
    
    # å‡†å¤‡æ•°æ®
    workshop_data = {
        "timestamp": datetime.now().isoformat(),
        "total_tracks": len(results),
        "tracks": results,
        "summary": {
            "formats": ["WAV 16-bit 44.1kHz"],
            "visualizations": ["Waveform plots"],
            "features_analyzed": ["RMS Energy", "Spectral Centroid", "Dynamic Range"]
        }
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(workshop_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ å·¥ä½œåŠç»“æœå·²ä¿å­˜: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œå·¥ä½œåŠ
        results = run_music_workshop()
        
        # ç”Ÿæˆå»ºè®®
        print("\nğŸ’¡ éŸ³ä¹æ²»ç–—å»ºè®®")
        print("-" * 40)
        print("1. æ ¹æ®ç”¨æˆ·æƒ…ç»ªçŠ¶æ€åŠ¨æ€è°ƒæ•´BPM")
        print("2. ä½¿ç”¨è‡ªç„¶éŸ³è‰²å¢å¼ºæ”¾æ¾æ•ˆæœ")
        print("3. åŠ å…¥åŒè€³èŠ‚æ‹æŠ€æœ¯ä¿ƒè¿›ç¡çœ ")
        print("4. ç»“åˆç”¨æˆ·éŸ³ä¹åå¥½ä¸ªæ€§åŒ–ç”Ÿæˆ")
        
        print("\nğŸµ éŸ³é¢‘å¤„ç†æŠ€å·§")
        print("-" * 40)
        print("1. ä½¿ç”¨æ›´å¤æ‚çš„åˆæˆæŠ€æœ¯æå‡éŸ³è´¨")
        print("2. æ·»åŠ ç¯å¢ƒéŸ³æ•ˆï¼ˆé›¨å£°ã€æµ·æµªç­‰ï¼‰")
        print("3. å®ç°å®æ—¶å‚æ•°è°ƒæ•´")
        print("4. æ”¯æŒå¤šå£°é“ç©ºé—´éŸ³é¢‘")
        
        print("\n" + "=" * 50)
        print("éŸ³ä¹ç”Ÿæˆå·¥ä½œåŠå®Œæˆ")
        print("=" * 50)
        print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print("\nğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œ 07_video_generation_workshop.py")
        
    except Exception as e:
        print(f"\nâŒ å·¥ä½œåŠå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()