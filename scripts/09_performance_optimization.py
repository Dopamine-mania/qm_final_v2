#!/usr/bin/env python3
"""
09 - æ€§èƒ½ä¼˜åŒ–æµ‹è¯•
æµ‹è¯•å’Œä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼ŒåŒ…æ‹¬å†…å­˜ç®¡ç†ã€GPUåŠ é€Ÿç­‰
"""

import time
import psutil
import torch
import numpy as np
from datetime import datetime
from pathlib import Path
import json
import gc
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            "cpu_usage": [],
            "memory_usage": [],
            "gpu_usage": [],
            "gpu_memory": [],
            "timestamps": []
        }
        self.start_time = time.time()
    
    def record_metrics(self):
        """è®°å½•å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=0.1)
        self.metrics["cpu_usage"].append(cpu_percent)
        
        # å†…å­˜ä½¿ç”¨
        memory = psutil.virtual_memory()
        self.metrics["memory_usage"].append(memory.percent)
        
        # GPUä½¿ç”¨ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            gpu_usage = torch.cuda.utilization()
            gpu_memory = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() * 100
            self.metrics["gpu_usage"].append(gpu_usage)
            self.metrics["gpu_memory"].append(gpu_memory)
        else:
            self.metrics["gpu_usage"].append(0)
            self.metrics["gpu_memory"].append(0)
        
        # æ—¶é—´æˆ³
        self.metrics["timestamps"].append(time.time() - self.start_time)
    
    def get_summary(self):
        """è·å–æ€§èƒ½æ€»ç»“"""
        return {
            "avg_cpu": np.mean(self.metrics["cpu_usage"]),
            "max_cpu": np.max(self.metrics["cpu_usage"]),
            "avg_memory": np.mean(self.metrics["memory_usage"]),
            "max_memory": np.max(self.metrics["memory_usage"]),
            "avg_gpu": np.mean(self.metrics["gpu_usage"]),
            "max_gpu": np.max(self.metrics["gpu_usage"]),
            "duration": self.metrics["timestamps"][-1] if self.metrics["timestamps"] else 0
        }

class OptimizationBenchmark:
    """ä¼˜åŒ–åŸºå‡†æµ‹è¯•"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.monitor = PerformanceMonitor()
    
    def benchmark_tensor_operations(self, size=(1000, 1000)):
        """æµ‹è¯•å¼ é‡è¿ç®—æ€§èƒ½"""
        print(f"\nğŸ”§ å¼ é‡è¿ç®—åŸºå‡†æµ‹è¯•")
        print(f"è®¾å¤‡: {self.device}")
        print(f"çŸ©é˜µå¤§å°: {size}")
        
        results = {}
        
        # æµ‹è¯•ä¸åŒç²¾åº¦
        for dtype in [torch.float32, torch.float16]:
            print(f"\næ•°æ®ç±»å‹: {dtype}")
            
            # åˆ›å»ºéšæœºå¼ é‡
            a = torch.randn(size, dtype=dtype, device=self.device)
            b = torch.randn(size, dtype=dtype, device=self.device)
            
            # é¢„çƒ­
            for _ in range(5):
                _ = torch.matmul(a, b)
            
            if self.device.type == 'cuda':
                torch.cuda.synchronize()
            
            # æµ‹è¯•çŸ©é˜µä¹˜æ³•
            start = time.time()
            for _ in range(100):
                c = torch.matmul(a, b)
            
            if self.device.type == 'cuda':
                torch.cuda.synchronize()
            
            duration = time.time() - start
            ops_per_sec = 100 / duration
            
            results[str(dtype)] = {
                "duration": duration,
                "ops_per_sec": ops_per_sec,
                "memory_mb": a.element_size() * a.nelement() * 2 / (1024**2)
            }
            
            print(f"  é€Ÿåº¦: {ops_per_sec:.2f} ops/ç§’")
            print(f"  å†…å­˜: {results[str(dtype)]['memory_mb']:.1f} MB")
            
            # æ¸…ç†
            del a, b, c
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
            gc.collect()
        
        return results
    
    def test_memory_optimization(self):
        """æµ‹è¯•å†…å­˜ä¼˜åŒ–æŠ€æœ¯"""
        print(f"\nğŸ’¾ å†…å­˜ä¼˜åŒ–æµ‹è¯•")
        
        strategies = {}
        
        # 1. æ¢¯åº¦ç´¯ç§¯ vs å¤§æ‰¹é‡
        print("\n1. æ‰¹é‡å¤§å°ä¼˜åŒ–")
        
        # å¤§æ‰¹é‡ï¼ˆå¯èƒ½OOMï¼‰
        try:
            batch_size = 128
            model = self._create_dummy_model()
            data = torch.randn(batch_size, 3, 224, 224, device=self.device)
            
            start_mem = self._get_memory_usage()
            start_time = time.time()
            
            output = model(data)
            loss = output.mean()
            loss.backward()
            
            end_time = time.time()
            end_mem = self._get_memory_usage()
            
            strategies["large_batch"] = {
                "batch_size": batch_size,
                "memory_used": end_mem - start_mem,
                "time": end_time - start_time,
                "success": True
            }
            
            del model, data, output, loss
            
        except RuntimeError as e:
            strategies["large_batch"] = {
                "batch_size": batch_size,
                "error": str(e),
                "success": False
            }
        
        # æ¢¯åº¦ç´¯ç§¯
        accumulation_steps = 4
        micro_batch = 32
        model = self._create_dummy_model()
        
        start_mem = self._get_memory_usage()
        start_time = time.time()
        
        model.zero_grad()
        for i in range(accumulation_steps):
            data = torch.randn(micro_batch, 3, 224, 224, device=self.device)
            output = model(data)
            loss = output.mean() / accumulation_steps
            loss.backward()
        
        end_time = time.time()
        end_mem = self._get_memory_usage()
        
        strategies["gradient_accumulation"] = {
            "micro_batch": micro_batch,
            "accumulation_steps": accumulation_steps,
            "effective_batch": micro_batch * accumulation_steps,
            "memory_used": end_mem - start_mem,
            "time": end_time - start_time,
            "success": True
        }
        
        # 2. æ··åˆç²¾åº¦è®­ç»ƒ
        print("\n2. æ··åˆç²¾åº¦ä¼˜åŒ–")
        
        if self.device.type == 'cuda':
            from torch.cuda.amp import autocast, GradScaler
            
            model = self._create_dummy_model()
            scaler = GradScaler()
            
            start_mem = self._get_memory_usage()
            start_time = time.time()
            
            data = torch.randn(64, 3, 224, 224, device=self.device)
            
            with autocast():
                output = model(data)
                loss = output.mean()
            
            scaler.scale(loss).backward()
            scaler.step(torch.optim.Adam(model.parameters()))
            scaler.update()
            
            end_time = time.time()
            end_mem = self._get_memory_usage()
            
            strategies["mixed_precision"] = {
                "memory_used": end_mem - start_mem,
                "time": end_time - start_time,
                "speedup": "~2x expected",
                "success": True
            }
        
        # æ¸…ç†
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()
        gc.collect()
        
        return strategies
    
    def test_parallel_processing(self):
        """æµ‹è¯•å¹¶è¡Œå¤„ç†"""
        print(f"\nâš¡ å¹¶è¡Œå¤„ç†æµ‹è¯•")
        
        # æµ‹è¯•æ•°æ®
        n_tasks = 100
        data = [np.random.randn(1000, 1000) for _ in range(n_tasks)]
        
        results = {}
        
        # 1. ä¸²è¡Œå¤„ç†
        print("\n1. ä¸²è¡Œå¤„ç†")
        start = time.time()
        serial_results = []
        for d in data:
            result = self._process_data(d)
            serial_results.append(result)
        serial_time = time.time() - start
        
        results["serial"] = {
            "time": serial_time,
            "tasks_per_sec": n_tasks / serial_time
        }
        print(f"  æ—¶é—´: {serial_time:.2f}ç§’")
        
        # 2. çº¿ç¨‹å¹¶è¡Œ
        print("\n2. çº¿ç¨‹å¹¶è¡Œ")
        start = time.time()
        with ThreadPoolExecutor(max_workers=4) as executor:
            thread_results = list(executor.map(self._process_data, data))
        thread_time = time.time() - start
        
        results["thread_parallel"] = {
            "time": thread_time,
            "tasks_per_sec": n_tasks / thread_time,
            "speedup": serial_time / thread_time
        }
        print(f"  æ—¶é—´: {thread_time:.2f}ç§’")
        print(f"  åŠ é€Ÿ: {results['thread_parallel']['speedup']:.2f}x")
        
        # 3. è¿›ç¨‹å¹¶è¡Œ
        print("\n3. è¿›ç¨‹å¹¶è¡Œ")
        start = time.time()
        with ProcessPoolExecutor(max_workers=4) as executor:
            process_results = list(executor.map(self._process_data, data))
        process_time = time.time() - start
        
        results["process_parallel"] = {
            "time": process_time,
            "tasks_per_sec": n_tasks / process_time,
            "speedup": serial_time / process_time
        }
        print(f"  æ—¶é—´: {process_time:.2f}ç§’")
        print(f"  åŠ é€Ÿ: {results['process_parallel']['speedup']:.2f}x")
        
        return results
    
    def _create_dummy_model(self):
        """åˆ›å»ºæµ‹è¯•æ¨¡å‹"""
        return torch.nn.Sequential(
            torch.nn.Conv2d(3, 64, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(64, 128, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.AdaptiveAvgPool2d(1),
            torch.nn.Flatten(),
            torch.nn.Linear(128, 10)
        ).to(self.device)
    
    def _get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨"""
        if self.device.type == 'cuda':
            return torch.cuda.memory_allocated() / (1024**2)  # MB
        else:
            return psutil.Process().memory_info().rss / (1024**2)  # MB
    
    def _process_data(self, data):
        """æ¨¡æ‹Ÿæ•°æ®å¤„ç†"""
        # æ‰§è¡Œä¸€äº›è®¡ç®—å¯†é›†å‹æ“ä½œ
        result = np.fft.fft2(data)
        result = np.abs(result)
        result = np.log(result + 1)
        return result.mean()

def visualize_performance(monitor_data, output_dir):
    """å¯è§†åŒ–æ€§èƒ½æ•°æ®"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    # CPUä½¿ç”¨ç‡
    ax = axes[0, 0]
    ax.plot(monitor_data["timestamps"], monitor_data["cpu_usage"])
    ax.set_title("CPU Usage")
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Usage (%)")
    ax.grid(True, alpha=0.3)
    
    # å†…å­˜ä½¿ç”¨ç‡
    ax = axes[0, 1]
    ax.plot(monitor_data["timestamps"], monitor_data["memory_usage"])
    ax.set_title("Memory Usage")
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Usage (%)")
    ax.grid(True, alpha=0.3)
    
    # GPUä½¿ç”¨ç‡
    ax = axes[1, 0]
    ax.plot(monitor_data["timestamps"], monitor_data["gpu_usage"])
    ax.set_title("GPU Usage")
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Usage (%)")
    ax.grid(True, alpha=0.3)
    
    # GPUå†…å­˜
    ax = axes[1, 1]
    ax.plot(monitor_data["timestamps"], monitor_data["gpu_memory"])
    ax.set_title("GPU Memory")
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Usage (%)")
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    chart_path = output_dir / "performance_metrics.png"
    plt.savefig(chart_path, dpi=150)
    plt.close()
    
    print(f"\nâœ… æ€§èƒ½å›¾è¡¨å·²ä¿å­˜: {chart_path}")

def run_optimization_tests():
    """è¿è¡Œä¼˜åŒ–æµ‹è¯•"""
    print("ã€Šå¿ƒå¢ƒæµè½¬ã€‹æ€§èƒ½ä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
    benchmark = OptimizationBenchmark()
    
    # å¼€å§‹ç›‘æ§
    monitor = benchmark.monitor
    
    # å®šæœŸè®°å½•æ€§èƒ½
    import threading
    stop_monitoring = threading.Event()
    
    def monitor_loop():
        while not stop_monitoring.is_set():
            monitor.record_metrics()
            time.sleep(0.5)
    
    monitor_thread = threading.Thread(target=monitor_loop)
    monitor_thread.start()
    
    results = {
        "timestamp": datetime.now().isoformat(),
        "device": str(benchmark.device),
        "tests": {}
    }
    
    try:
        # 1. å¼ é‡è¿ç®—åŸºå‡†æµ‹è¯•
        tensor_results = benchmark.benchmark_tensor_operations()
        results["tests"]["tensor_operations"] = tensor_results
        
        # 2. å†…å­˜ä¼˜åŒ–æµ‹è¯•
        memory_results = benchmark.test_memory_optimization()
        results["tests"]["memory_optimization"] = memory_results
        
        # 3. å¹¶è¡Œå¤„ç†æµ‹è¯•
        parallel_results = benchmark.test_parallel_processing()
        results["tests"]["parallel_processing"] = parallel_results
        
    finally:
        # åœæ­¢ç›‘æ§
        stop_monitoring.set()
        monitor_thread.join()
    
    # è·å–æ€§èƒ½æ€»ç»“
    performance_summary = monitor.get_summary()
    results["performance_summary"] = performance_summary
    
    # æ˜¾ç¤ºç»“æœ
    display_optimization_results(results)
    
    # å¯è§†åŒ–æ€§èƒ½
    output_dir = Path("outputs/optimization")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    visualize_performance(monitor.metrics, output_dir)
    
    # ä¿å­˜ç»“æœ
    save_optimization_results(results, output_dir)
    
    return results

def display_optimization_results(results):
    """æ˜¾ç¤ºä¼˜åŒ–ç»“æœ"""
    print("\nğŸ“Š ä¼˜åŒ–æµ‹è¯•ç»“æœ")
    print("=" * 50)
    
    # å¼ é‡è¿ç®—ç»“æœ
    print("\n1. å¼ é‡è¿ç®—æ€§èƒ½:")
    for dtype, metrics in results["tests"]["tensor_operations"].items():
        print(f"  {dtype}:")
        print(f"    é€Ÿåº¦: {metrics['ops_per_sec']:.2f} ops/ç§’")
        print(f"    å†…å­˜: {metrics['memory_mb']:.1f} MB")
    
    # å†…å­˜ä¼˜åŒ–ç»“æœ
    print("\n2. å†…å­˜ä¼˜åŒ–:")
    for strategy, metrics in results["tests"]["memory_optimization"].items():
        if metrics.get("success"):
            print(f"  {strategy}:")
            print(f"    å†…å­˜ä½¿ç”¨: {metrics.get('memory_used', 0):.1f} MB")
            print(f"    æ‰§è¡Œæ—¶é—´: {metrics.get('time', 0):.3f}ç§’")
    
    # å¹¶è¡Œå¤„ç†ç»“æœ
    print("\n3. å¹¶è¡Œå¤„ç†:")
    for method, metrics in results["tests"]["parallel_processing"].items():
        print(f"  {method}:")
        print(f"    æ—¶é—´: {metrics['time']:.2f}ç§’")
        if "speedup" in metrics:
            print(f"    åŠ é€Ÿæ¯”: {metrics['speedup']:.2f}x")
    
    # æ€§èƒ½æ€»ç»“
    summary = results["performance_summary"]
    print("\nğŸ“ˆ æ€§èƒ½ç›‘æ§æ€»ç»“:")
    print(f"  å¹³å‡CPU: {summary['avg_cpu']:.1f}%")
    print(f"  å³°å€¼CPU: {summary['max_cpu']:.1f}%")
    print(f"  å¹³å‡å†…å­˜: {summary['avg_memory']:.1f}%")
    print(f"  å³°å€¼å†…å­˜: {summary['max_memory']:.1f}%")
    if summary['avg_gpu'] > 0:
        print(f"  å¹³å‡GPU: {summary['avg_gpu']:.1f}%")
        print(f"  å³°å€¼GPU: {summary['max_gpu']:.1f}%")

def save_optimization_results(results, output_dir):
    """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
    output_file = output_dir / f"optimization_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        # å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        def default(obj):
            if isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            else:
                return str(obj)
        
        json.dump(results, f, indent=2, ensure_ascii=False, default=default)
    
    print(f"\nğŸ’¾ ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œä¼˜åŒ–æµ‹è¯•
        results = run_optimization_tests()
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®")
        print("-" * 40)
        
        device = results["device"]
        if "cuda" in device:
            print("GPUä¼˜åŒ–:")
            print("1. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰å¯èŠ‚çœ50%æ˜¾å­˜")
            print("2. å¯ç”¨æ¢¯åº¦ç´¯ç§¯å¤„ç†å¤§æ‰¹é‡æ•°æ®")
            print("3. ä½¿ç”¨CUDAæµå®ç°å¼‚æ­¥å¤„ç†")
            print("4. å®šæœŸæ¸…ç†GPUç¼“å­˜é¿å…å†…å­˜æ³„æ¼")
        else:
            print("CPUä¼˜åŒ–:")
            print("1. ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡ŒåŠ é€Ÿè®¡ç®—å¯†é›†å‹ä»»åŠ¡")
            print("2. è€ƒè™‘ä½¿ç”¨é‡åŒ–æŠ€æœ¯å‡å°‘å†…å­˜å ç”¨")
            print("3. ä¼˜åŒ–æ•°æ®åŠ è½½é¿å…IOç“¶é¢ˆ")
            print("4. ä½¿ç”¨å†…å­˜æ˜ å°„å¤„ç†å¤§æ–‡ä»¶")
        
        print("\nğŸ”§ é€šç”¨ä¼˜åŒ–:")
        print("1. æ‰¹å¤„ç†ï¼šåˆå¹¶å°ä»»åŠ¡å‡å°‘å¼€é”€")
        print("2. ç¼“å­˜ï¼šå¤ç”¨è®¡ç®—ç»“æœé¿å…é‡å¤")
        print("3. æ‡’åŠ è½½ï¼šæŒ‰éœ€åŠ è½½æ¨¡å‹å’Œæ•°æ®")
        print("4. ç›‘æ§ï¼šæŒç»­è¿½è¸ªæ€§èƒ½æŒ‡æ ‡")
        
        print("\n" + "=" * 50)
        print("æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
        print("=" * 50)
        print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print("\nğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œ 10_complete_system_demo.py")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()