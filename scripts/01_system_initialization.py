#!/usr/bin/env python3
"""
01 - ç³»ç»Ÿåˆå§‹åŒ–æ£€æŸ¥
æ£€æŸ¥ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿçš„è¿è¡Œç¯å¢ƒå’Œä¾èµ–
"""

import sys
import platform
from datetime import datetime
import subprocess
import warnings
warnings.filterwarnings('ignore')

def print_header():
    """æ‰“å°å¤´éƒ¨ä¿¡æ¯"""
    print("ã€Šå¿ƒå¢ƒæµè½¬ã€‹ç³»ç»Ÿåˆå§‹åŒ–æ£€æŸ¥")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

def check_python():
    """æ£€æŸ¥Pythonç¯å¢ƒ"""
    print("1. Pythonç¯å¢ƒæ£€æŸ¥")
    print("-" * 30)
    
    version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    print(f"Pythonè·¯å¾„: {sys.executable}")
    
    if version.major >= 3 and version.minor >= 8:
        print("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.8)")
    else:
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ >= 3.8")
    
    print()

def check_platform():
    """æ£€æŸ¥ç³»ç»Ÿå¹³å°"""
    print("2. ç³»ç»Ÿå¹³å°æ£€æŸ¥")
    print("-" * 30)
    
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()}")
    print(f"ç³»ç»Ÿç‰ˆæœ¬: {platform.version()}")
    print(f"æœºå™¨ç±»å‹: {platform.machine()}")
    print(f"å¤„ç†å™¨: {platform.processor()}")
    
    print()

def check_gpu():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print("3. GPUç¯å¢ƒæ£€æŸ¥")
    print("-" * 30)
    
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨")
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"GPU {i}: {props.name}")
                print(f"  æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB")
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
    
    print()

def check_dependencies():
    """æ£€æŸ¥ä¸»è¦ä¾èµ–"""
    print("4. æ ¸å¿ƒä¾èµ–æ£€æŸ¥")
    print("-" * 30)
    
    dependencies = {
        'numpy': 'NumPy',
        'pandas': 'Pandas',
        'matplotlib': 'Matplotlib',
        'transformers': 'Transformers',
        'torch': 'PyTorch',
        'torchaudio': 'TorchAudio',
        'torchvision': 'TorchVision',
        'diffusers': 'Diffusers',
        'datasets': 'Datasets',
        'accelerate': 'Accelerate',
        'safetensors': 'SafeTensors',
        'scipy': 'SciPy',
        'librosa': 'Librosa',
        'moviepy': 'MoviePy',
        'opencv-cv2': 'OpenCV',
        'gradio': 'Gradio',
        'fastapi': 'FastAPI',
        'uvicorn': 'Uvicorn'
    }
    
    installed = []
    missing = []
    
    for package, name in dependencies.items():
        try:
            if package == 'opencv-cv2':
                __import__('cv2')
            else:
                __import__(package)
            installed.append(name)
        except ImportError:
            missing.append(name)
    
    print(f"âœ… å·²å®‰è£…: {len(installed)}ä¸ª")
    for pkg in installed[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {pkg}")
    if len(installed) > 5:
        print(f"  ... è¿˜æœ‰{len(installed)-5}ä¸ª")
    
    if missing:
        print(f"\nâŒ ç¼ºå¤±: {len(missing)}ä¸ª")
        for pkg in missing:
            print(f"  - {pkg}")
    
    print()

def check_models():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("5. æ¨¡å‹æ–‡ä»¶æ£€æŸ¥")
    print("-" * 30)
    
    import os
    from pathlib import Path
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹ç›®å½•
    model_dir = Path("../data/pretrained_models")
    
    if model_dir.exists():
        print(f"âœ… æ¨¡å‹ç›®å½•å­˜åœ¨: {model_dir}")
        
        # åˆ—å‡ºæ¨¡å‹æ–‡ä»¶
        model_files = list(model_dir.glob("**/*.safetensors")) + \
                      list(model_dir.glob("**/*.bin")) + \
                      list(model_dir.glob("**/*.pt"))
        
        if model_files:
            print(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
            for f in model_files[:3]:
                size_mb = f.stat().st_size / (1024 * 1024)
                print(f"  - {f.name} ({size_mb:.1f} MB)")
            if len(model_files) > 3:
                print(f"  ... è¿˜æœ‰{len(model_files)-3}ä¸ª")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
    else:
        print("âš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        print("  å»ºè®®åˆ›å»º: data/pretrained_models/")
    
    print()

def check_outputs():
    """æ£€æŸ¥è¾“å‡ºç›®å½•"""
    print("6. è¾“å‡ºç›®å½•æ£€æŸ¥")
    print("-" * 30)
    
    from pathlib import Path
    
    output_dirs = [
        "outputs",
        "outputs/validation",
        "outputs/generation",
        "outputs/evaluation"
    ]
    
    for dir_path in output_dirs:
        dir_obj = Path(dir_path)
        if not dir_obj.exists():
            dir_obj.mkdir(parents=True, exist_ok=True)
            print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")
        else:
            print(f"âœ… ç›®å½•å­˜åœ¨: {dir_path}")
    
    print()

def generate_summary():
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("=" * 50)
    print("åˆå§‹åŒ–æ£€æŸ¥å®Œæˆï¼")
    print("=" * 50)
    
    import json
    from pathlib import Path
    
    # ä¿å­˜æ£€æŸ¥ç»“æœ
    results = {
        "timestamp": datetime.now().isoformat(),
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
        "platform": platform.system(),
        "status": "ready"
    }
    
    output_file = Path("outputs/system_check_results.json")
    output_file.parent.mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ æ£€æŸ¥ç»“æœå·²ä¿å­˜: {output_file}")
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œ 02_theory_models_demo.py")
    print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")

def main():
    """ä¸»å‡½æ•°"""
    print_header()
    check_python()
    check_platform()
    check_gpu()
    check_dependencies()
    check_models()
    check_outputs()
    generate_summary()

if __name__ == "__main__":
    main()